{"meta":{"title":"cloud_fly blog","subtitle":"","description":"Know the loom. Be the stone","author":"cloud_fly","url":"https://www.cdfy.top","root":"/"},"pages":[{"title":"Hello World","date":"2025-01-14T07:58:49.603Z","updated":"2025-01-10T09:54:50.000Z","comments":true,"path":"categories/hello-world.html","permalink":"https://www.cdfy.top/categories/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment"},{"title":"categories","date":"2025-01-11T14:00:00.000Z","updated":"2025-01-31T09:11:29.051Z","comments":true,"path":"categories/index.html","permalink":"https://www.cdfy.top/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2025-01-11T06:20:31.000Z","updated":"2025-01-11T06:20:30.000Z","comments":true,"path":"about/index.html","permalink":"https://www.cdfy.top/about/index.html","excerpt":"","text":""},{"title":"","date":"2025-01-14T07:58:49.635Z","updated":"2025-01-12T07:11:32.000Z","comments":true,"path":"css/modify.js","permalink":"https://www.cdfy.top/css/modify.js","excerpt":"","text":"'use strict'; const cheerio = require('cheerio'); /** * 在页面插入新顶部图 * @param {cheerio.Root} $ Root */ function insertTopImg($) { let header = $('#page-header'); if (header.length === 0) return; let background = header.css('background-image'); if (!background) return; $('#post, #page, #archive, #tag, #category').prepend(``); } hexo.extend.filter.register('after_render:html', function(str, data) { let $ = cheerio.load(str, { decodeEntities: false }); insertTopImg($); return $.html(); });"},{"title":"links","date":"2025-01-13T10:49:38.000Z","updated":"2025-01-13T10:57:12.000Z","comments":true,"path":"links/index.html","permalink":"https://www.cdfy.top/links/index.html","excerpt":"","text":"P19E99: https://www.zhihu.com/people/luo-ling-21-91 66uan99: https://backupenable.github.io/"},{"title":"shuoshuo","date":"2025-01-11T06:19:02.000Z","updated":"2025-01-11T06:19:02.000Z","comments":true,"path":"shuoshuo/index.html","permalink":"https://www.cdfy.top/shuoshuo/index.html","excerpt":"","text":""},{"title":"","date":"2025-01-14T07:58:49.651Z","updated":"2025-01-12T09:54:36.000Z","comments":true,"path":"css/modify.css","permalink":"https://www.cdfy.top/css/modify.css","excerpt":"","text":"#page-header, #page-header:before { background: transparent !important; } #page-header.post-bg, #page-header.not-home-page { height: 280px !important; } #page-header #post-info { bottom: 40px !important; } #page-header #page-site-info { top: 140px !important; } @media screen and (max-width: 768px) { #page-header.not-home-page { height: 200px !important; } #page-header #post-info { bottom: 10px !important; } #page-header #page-site-info { top: 100px !important; } } .top-img { height: 250px; margin: -50px -40px 50px; border-top-left-radius: inherit; border-top-right-radius: inherit; background-position: center center; background-size: cover; -webkit-transition: all 0.3s; -moz-transition: all 0.3s; -o-transition: all 0.3s; -ms-transition: all 0.3s; transition: all 0.3s; } @media screen and (max-width: 768px) { .top-img { height: 230px; margin: -36px -14px 36px; } } [data-theme='dark'] .top-img { filter: brightness(0.8); } #footer:before { background-color: rgba(255,255,255,0.5); } [data-theme='dark'] #footer:before { background-color: rgba(0,0,0,0.5); } #footer-wrap, #footer-wrap a { color: #111; -webkit-transition: unset; -moz-transition: unset; -o-transition: unset; -ms-transition: unset; transition: unset; } [data-theme='dark'] #footer-wrap, [data-theme='dark'] #footer-wrap a { color: var(--light-grey); }"},{"title":"photos","date":"2025-01-11T06:19:55.000Z","updated":"2025-01-11T06:19:54.000Z","comments":true,"path":"photos/index.html","permalink":"https://www.cdfy.top/photos/index.html","excerpt":"","text":""},{"title":"tags","date":"2025-01-10T16:29:42.000Z","updated":"2025-01-10T16:40:14.000Z","comments":true,"path":"tags/index.html","permalink":"https://www.cdfy.top/tags/index.html","excerpt":"","text":"title: categories date: 2025-01-11 22:00:00"}],"posts":[{"title":"Kafka应用场景","slug":"Kafka应用场景","date":"2025-01-31T08:24:56.000Z","updated":"2025-01-31T09:25:05.048Z","comments":true,"path":"posts/Kafka应用场景.html","permalink":"https://www.cdfy.top/posts/Kafka%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.html","excerpt":"","text":"消息队列Kafka入门","categories":[{"name":"Kafka","slug":"Kafka","permalink":"https://www.cdfy.top/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://www.cdfy.top/tags/Kafka/"}]},{"title":"限流策略","slug":"限流策略","date":"2025-01-25T06:47:33.000Z","updated":"2025-01-25T07:49:22.023Z","comments":true,"path":"posts/限流策略.html","permalink":"https://www.cdfy.top/posts/%E9%99%90%E6%B5%81%E7%AD%96%E7%95%A5.html","excerpt":"","text":"固定窗口 对一段时间固定内的请求进行计数，如果请求数量超过阈值就抛弃，如果没有达到这个阈值就接受这个请求 算法简单，但是有流量突刺现象 滑动窗口 在一个固定窗口的基础上，将一个计时窗口分成了若干个小窗口，然后每个小窗口维护一个独立的计时器，当请求的时候大于当前窗口的最大时间，则会将计时窗口向前平移一个小窗口，平移的时候会将第一个小窗口的数据丢弃，然后将第二个小窗口设置成第一个小窗口并在最前面新增一个小窗口。 同时也需要满足所有小窗口的请求数量不能超过阈值 相比固定窗口，可以有效的平衡流量突刺 漏桶 请求来了之后会首先进入漏桶中，然后漏桶以恒定的速率将请求流出以处理，从而去起到一个平滑流量的作用，当请求流量过大的时候，漏桶达到最大容量就会溢出 可以应对突发流量，但是不能应对短时间的大流量 令牌桶 对漏桶算法的一种改进，除了可以起到限流作用以外，还允许一定程序上的流量突发。在令牌桶的算法中有一个令牌桶，算法中存在一个机制，可以恒定地向令牌桶中放入令牌，令牌桶也有一定的容量，如果满了令牌就放不进去。当请求来的时候，首先会去令牌桶拿令牌。如果可以拿到令牌说明请求可以被处理并消耗拿到的令牌数量。否则被丢弃 允许一定程序的突发流量，当有大量的请求流入的时候，可以使用堆积的令牌去处理 与滑动窗口算法的区别： 滑动窗口关注的是单位时间内的总请求量 令牌桶算法关注的是请求的平均速率 令牌桶可以应对短时间内的突发流量，而滑动窗口只是对突发流量进行一个限制 如果系统对突刺的容忍度较高，选择令牌桶算法；如果希望更加平滑选择滑动窗口算法 漏桶能够强行限制数据的传输速率，而令牌桶在能够限制数据的平均传输速率外，还允许某种程度的突发传输。 在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量","categories":[{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/categories/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}]},{"title":"幂等性","slug":"幂等性","date":"2025-01-25T05:20:36.000Z","updated":"2025-01-25T06:19:14.852Z","comments":true,"path":"posts/幂等性.html","permalink":"https://www.cdfy.top/posts/%E5%B9%82%E7%AD%89%E6%80%A7.html","excerpt":"","text":"什么是接口幂等性 接口幂等性是指一个接口在被调用一次和被调用多次后的结果是一样的 为什么需要接口幂等性 用户的重复提交或者用户的恶意攻击 网络波动导致的超时重传可能会导致接口重复调用 比如你在购买商品下单成功后需要支付，如果你付了钱但是由于网络波动，你没有收到支付成功，因此你多点击了几下，如果没有幂等性就会导致多次扣钱 常见的重复请求场景 前端表单的重复提交 黑客恶意攻击 接口超时重传 消息队列中的消息重复消费 哪些接口需要幂等 本身幂等的： 查询操作和删除操作不需要幂等保证，因为本身就是幂等 更新操作的赋值操作本身也是幂等，不需要幂等保证 本身不是幂等需要幂等保证： 新增操作 更新操作如果是将某个字段增量更新需要幂等 幂等性如何保证 数据库唯一性约束，需要生成全局唯一性ID，适用于新增操作 防重表，要生成全局唯一性ID，以及还要考虑数据量大的情况下的分库分表或者过期数据清理情况，适用于新增操作。好处是如果有两个业务场景,A场景不允许重复，B场景允许重复，通过防重表将唯一键和业务分离开，降低耦合 数据库乐观锁，通过版本号法，在记录字段上加上version，update的时候需要满足where version = #{version}，适用于更新操作 防重token令牌 客户端会先去向服务端发送一个请求去得到一个token，服务端生成一个token并存在redis中设置ttl 客户端第二次调用业务请求的时候必须要携带这一个token，然后服务端校验 检验成功后去查看redis中有没有token，如果有则执行业务并且删除redis中的token，如果没有则说明redis中没有对应的token，表示重复操作 防重token令牌的问题 假设某个客户端第一次发起请求，服务端收到请求后将token从redis中删除，接着去执行业务逻辑。但是业务逻辑执行失败，有两种可能： 服务端向客户端返回执行失败，客户端收到后会请求重新生成一个token，这里没有幂等性问题 服务端向客户端返回执行失败，但是由于网络问题导致了丢包，此时客户端会超时重传，但是服务端返回的却是重复请求或者执行成功（有的业务鉴别出重复请求当作执行成功处理） 因此我们可以结合业务场景，在防重token令牌的基础上，再在db层加上前三种方案作为兜底 可以用分布式锁做幂等性吗 不可以 如果用于连续发了两次请求，第一次请求先到底去执行，第二次请求由于一些原因过了一会才能执行，如果第一次请求执行完了并且释放锁，第二次请求也拿到了锁，那么不能保证幂等性 客户端第一次发起请求，服务端执行完成并且释放了锁，但由于网络原因客户端没有收到，于是客户端再次发起请求，但是如果ttl过期了第二次请求也能获取到锁并执行，不能保证幂等性","categories":[{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/categories/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}]},{"title":"Redis切片集群哈希槽为什么是16384个","slug":"Redis切片集群哈希槽为什么是16384个","date":"2025-01-25T04:25:42.000Z","updated":"2025-01-25T05:20:55.800Z","comments":true,"path":"posts/Redis切片集群哈希槽为什么是16384个.html","permalink":"https://www.cdfy.top/posts/Redis%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E5%93%88%E5%B8%8C%E6%A7%BD%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF16384%E4%B8%AA.html","excerpt":"","text":"CRC16算法产生的hash值有16bit，该算法可以产生2^16-=65536个值。换句话说，值是分布在0~65535之间。那作者在做mod运算的时候，为什么不mod65536，而选择mod16384？ 如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。在消息头中，最占空间的是myslots[CLUSTER_SLOTS/8]。 当槽位为65536时，这块的大小是:65536÷8÷1024=8kb。因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽 redis的集群主节点数量基本不可能超过1000个。 集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个 槽位越小，节点少的情况下，压缩比高。Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低 综上所述，Redis作者决定取16384个槽，不多不少","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"HashMap的环形链表问题","slug":"HashMap的环形链表问题","date":"2025-01-24T10:23:35.000Z","updated":"2025-01-24T10:44:59.471Z","comments":true,"path":"posts/HashMap的环形链表问题.html","permalink":"https://www.cdfy.top/posts/HashMap%E7%9A%84%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8%E9%97%AE%E9%A2%98.html","excerpt":"","text":"在JDK1.7的时候，插入链表采用的是头插法，会先将一个需要迁移节点的next指向新位置，然后再将新位置设置成迁移节点。因此在多线程扩容的情况下，一个线程完成了两个节点的迁移，但是被调度到另一个还未完成的线程，就会出现循环链表的情况 在JDK1.8，采用了尾插法，只需要遍历一个个节点，挂在tail节点的后面即可，即使迁移过程有并发情况，指针也最多被复制两次","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"CopyOnWriteArrayList","slug":"CopyOnWriteArrayList","date":"2025-01-24T09:26:11.000Z","updated":"2025-01-31T09:28:15.528Z","comments":true,"path":"posts/CopyOnWriteArrayList.html","permalink":"https://www.cdfy.top/posts/CopyOnWriteArrayList.html","excerpt":"","text":"CopyOnWriteArrayList底层原理","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"堆排序","slug":"堆排序","date":"2025-01-24T04:01:01.000Z","updated":"2025-01-24T05:23:11.027Z","comments":true,"path":"posts/堆排序.html","permalink":"https://www.cdfy.top/posts/%E5%A0%86%E6%8E%92%E5%BA%8F.html","excerpt":"","text":"从最后一个非叶子节点（n / 2）开始递归向下调整（down） 在排序阶段，每次从堆顶取出最大（或最小）元素，将其放到已排序部分的末尾（交换a[1]与a[n]），然后对剩余未排序的部分进行堆调整 堆的大小-1，然后从根节点开始递归调整 由完全二叉树的性质，每次调整都是log的复杂度 不稳定排序，因为建堆和排序调整阶段导致的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;bits/stdc++.h&gt;using namespace std;const int N = 1e5 + 10;int a[N];int n = 5;void down(int u) &#123; int t = u; if (2 * u &lt;= n &amp;&amp; a[2 * u] &lt; a[t]) t = 2 * u; if (2 * u + 1 &lt;= n &amp;&amp; a[2 * u + 1] &lt; a[t]) t = 2 * u + 1; if (t != u) &#123; swap(a[u], a[t]); down(t); &#125; return;&#125;void heap_sort() &#123; for (int i = n / 2; i &gt;= 1; i--) &#123; down(i); &#125; int sz = n; for (int i = 1; i &lt;= sz; i++) &#123; cout &lt;&lt; a[1] &lt;&lt; &#x27; &#x27;; swap(a[1], a[n]); n--; down(1); &#125;&#125;int main() &#123; a[1] = 3; a[2] = 4; a[3] = 2; a[4] = 0; a[5] = 7; heap_sort(); return 0;&#125;//输出：0 2 3 4 7","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Redis集群","slug":"Redis集群","date":"2025-01-23T10:37:50.000Z","updated":"2025-01-23T14:42:24.501Z","comments":true,"path":"posts/Redis集群.html","permalink":"https://www.cdfy.top/posts/Redis%E9%9B%86%E7%BE%A4.html","excerpt":"","text":"Redis集群架构有哪些 主从架构：选择一台作为主服务器，将数据同步多台到从服务器上，构建一主多从的的模式，主从之间读写分离。主服务器可读可写，发生写操作会同步给从服务器，而从服务器一般是只读，且主从之间同步是异步的，所以无法实现强一致性保证 哨兵集群：当Redis的主服务器出现故障的时候，需要手动进行恢复，为了解决这个问题，Redis增加了哨兵模式，哨兵监控主从服务器，如果主服务器宕机了，会选择一个从服务器作为主服务器，并通知给其他从服务器和客户端 切片集群：当数据量大到一定程序的时候，需要使用Redis切片集群方案，将数据分布在不同服务器上，以此来降低系统对单节点的依赖 切片集群 过程： 根据键值对的key，按照CRC16算法计算出一个16bit 再用16bit值对16384取模得到一个模数，每个模数代表一个相应编号的哈希槽 哈希槽分配： 平均分配：使用cluster create命令创建Redis集群的时候，Redis会自动把所有哈希槽平均分布到集群节点上，比如有9个节点，就是16834/9 手动分配：使用cluster meet命令手动建立节点之间的连接，组成集群，再使用cluster addslots命令，指定每个节点上的哈希槽个数 Redis主从复制过程 全量同步 slave获取master所有的数据： 从服务器发送sync命令到主服务器，链接主服务 主服务器收到sync命令，进行存盘的操作，并继续收集后续的写命令，存储缓冲区 存盘结束后，将对应数据的文件写到slave中，完成一次全量同步 主服务器数据发送完毕后，将进行增量的缓冲区数据同步 slave加载数据文件和缓冲区文件，开始接受命令操作，提供操作 增量同步 从节点完成全量同步后，就可以开启增量同步。当master节点有写操作的时候，会自动同步到slave节点上。master节点每执行一个任务，都会写入到缓冲区中，随后将缓存区中的命令发给从节点执行 哨兵机制的工作原理 判断节点是否存活：哨兵会周期性地给主从库发送PING命令来判断节点是否下线。如果主库没有在规定时间返回响应，则将该节点标记为主观下线，然后该哨兵节点会向其他哨兵节点发出投票命令，当投票命令到达一定阈值后该节点会标记为客观下线 投票：哨兵集群中会重新选择一个从leader来负责主从切换，选举是一个投票过程：判断主节点为客观下线的是候选者，候选者向其他节点发送命令表示要成为leader，其他哨兵会进行投票，每个哨兵只有一票，但是只有哨兵节点会自己投给自己。候选者拿到半数以上的赞成票并且达到了阈值会成为leader 选择出新的主节点：进行三轮考察，哪些节点胜出就进行下一轮，直到选出主节点 根据从节点的优先级来排序，优先级的值越小排名越靠前 如果优先级相同，则查看复制的下标，哪个接受的复制数据多就选哪个 如果优先级和下标都相同，选择id最小的那个 哨兵leader让已下线主节点属下的所有从节点指向新主节点 通知客户端的主节点已更换 将旧主节点变成从节点 哨兵模式的优缺点 优点：保证系统的高可用，各个节点可以做故障转移 缺点：主节点单点风险高，主从切换过程可能会出现数据丢失的问题。此外主从模式无法水平扩容（因为主节点和从节点数据要一样）","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"SQL语法","slug":"SQL语法","date":"2025-01-23T08:21:02.000Z","updated":"2025-01-23T08:33:16.438Z","comments":true,"path":"posts/SQL语法.html","permalink":"https://www.cdfy.top/posts/SQL%E8%AF%AD%E6%B3%95.html","excerpt":"","text":"count主键和非主键的结果有什么不同？ count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个 123select count(name) from t_order; 统计t_order表中，name不为null的字段有多少个 123select count(1) from t_order;统计t_order 表中，1 这个表达式不为 NULL 的记录有多少个t_order 表中，1 这个表达式不为 NULL 的记录 主键是不能存NULL值，因此会统计表中所有行数据的数量 非主键可以存NULL值，因此会统计表中这个列的非NULL值得数量 MySQL内连接，外连接有什么区别 内连接（INNER JOIN）和外连接(LEFT JOIN和RIGHT JOIN)都是连表查询 内连接是返回两个表的匹配行，外连接可以返回匹配和不匹配的行，外连接主要分为左连接和右连接： 左连接：返回左表中的所有行和右表中的匹配行，如果右表没有，用NULL值替代 右连接：返回右表中的所有行和左表中的匹配行，如果左表没有，用NULL值替代 ON和WHERE过滤条件的区别 对于内连接查询，WHERE和ON过滤条件等效 对于外连接查询，ON中的过滤条件在执行时进行，WHERE中的过滤条件在连接操作后进行。用ON如果匹配不上会用NULL填充 WHERE和HAVING的区别 WHERE是在GROUP BY分组和聚集函数之前对数据行进行过滤 HAVING是在GROUP BY分组和聚集函数之后对分组之后的数据过滤 语法错误，因为WHERE是在分组和聚集函数之前进行过滤，WHERE执行的时候还没有分组函数 EXISTS和IN的区别是什么 12345A是外表，B是内表seletct * from A where id in (selectt id from B) select * from A where exists (select 1 from B where A.id = B.id) 工作原理区别： in先遍历内表，会把查询到的数据缓存在内存中，然后遍历内表的数据再去查询外表 exists先遍历外表将数据缓存到内存中，然后遍历外表的数据再去查询内表 性能区别： 如果两个表的记录大小相当，in和exists区别不大 如果两个表，其中一个是大表，另外一个是小表，IN适合外表大内表小的情况，EXISTS适合外表小内表大的情况，遵循小表驱动大表 假设B有10000条记录，A有100条，如果用IN, 那么与数据库交互的次数是10000 * log100次（log是因为在数据库中根据连接条件走的是B+树索引），而用EXISTS交互次数是100 * log10000次.差异体现在和数据库交互的次数 MySQL的约束有哪些 数据库有六大约束： 主键约束：作用标识唯一一条记录，不能为NULL，也不能重复，一般设置id为主键 外键约束：确保表之间记录的完整性 唯一性约束：保证字段在表中的记录是唯一的，如果插入重复的字段，会出现唯一性约束错误 非空约束：不允许字段为空 默认约束：给字段设置默认值，如果插入字段时没有设置初值则有默认值 检查约束：用于检查字段的取值是不是在取值范围内 但是MySQL只支持前5种 union和union all的区别 union在结果集合并后去重 union all在结果集合并后不去重 count(*)比coun(1)性能好吗 不会， 因为MySQL会将*当作0来处理，所以二者性能一样 除此之外，在性能上：count（*）= count（1）&gt; count（主键）&gt; count（子段） MySQL 会对 count(*) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。只有当没有二级索引的时候，才会采用主键索引来进行统计","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL高可用","slug":"MySQL高可用","date":"2025-01-22T06:48:38.000Z","updated":"2025-01-22T07:34:46.372Z","comments":true,"path":"posts/MySQL高可用.html","permalink":"https://www.cdfy.top/posts/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8.html","excerpt":"","text":"MySQL主从复制的过程是怎么样的 分为3个阶段： 写入binlog：主库修改数据后，会写入binlog日志，从库连接到主库后，主库会创建一个log dump线程，用于发送bin log的内容 同步binlog：从库会专门创建一个I/O线程来连接主库的log dump线程，来接受主库的binlog日志，再把binlog信息写入relay log的中继日志里，再返回给主库“复制成功”的响应 回放binlog：从库会专门创建一个用于回放binlog的SQL线程，去读relay log中继日志，然后回放binlog更新存储引擎的数据，实现主从的数据一致性 MySQL提高了哪些复制策略 主要有三种复制策略：同步复制、异步复制、半同步复制，MySQL默认的复制模型是异步复制 同步复制：主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。性能最差，但是安全性最好 异步复制：主库提交事务的线程不会等待binlog同步到从库，就返回客户端结果。性能最好但是安全性最差 半同步复制：主库提交事务的线程不用等待所有的从库复制成功响应，只需要等待一部分复制成功响应回来就可以。优点是出现主库宕机，至少还有一个从库有最新的数据，不会出现数据丢失的风险 MySQL主从复制的数据延迟怎么解决 使用缓存解决：可以在写入数据主库的同时，把数据写到R edis中，这样其他线程再获取数据时会先到Redis中查，也可以保证数据的一致性，不过这种方式会带来缓存和数据库的一致性问题 直接查询主库：对于数据延迟铭感的业务，可以强制读取主库，但是查询数据量不能太大，不然会出现主库写请求锁行，影响读请求的执行 MySQL主从架构中，读写分离怎么实现 一种简单的做法：提前将所有数据源配置在工程中，每一个数据源对应一个主库或者从库，然后改造代码，将某一个SQL语句交给其中一个数据源来处理。但是SQL路由规则侵入代码逻辑，不利用代码的维护 另一种做法：独立部署的代理中间件，如MyCat，这一类中间件独立部署在独立的服务器上，一般用标准的MySQL通信协议，可以代理多个数据库。优点是隔离底层数据库与上层应用访问的复杂度，比较适合有独立运维团队的公司；缺点是所有的SQL语句都要跨两次网络传输，有一点的性能损耗，再就是运维中间件是一个专业且复杂的工作，需要技术沉淀 MySQL主库挂了怎么办 MySQL没有实现主服务器宕机和处理故障的功能，要实现自动主从故障迁移的功能，可以使用开源的MySQL高可用套件MHA,MHA可以在主数据库发生宕机的时候，剔除原有主机，选出新的主机，然后对外服务 什么是分库分表，什么时候需要分库，什么时候需要分表 分库分表是把原本存储于单个数据库上的数据拆分到多个数据库，把原来存储在单张表的数据拆分到多张表中 分库：当单台MySQL扛不住高并发流量的时候，就需要分库 分表：当单张表数据量太大的时候，经验值是500W以上的时候，就需要分表，通过减少每次查询数据总量来解决查询慢的问题 分库分表后，会产生什么问题 分布式事务问题： 对业务进行分库之后，一次大的操作由多个小操作组成，这些小的操作分布在不同的服务器上，分布式事务需要保证这些小操作要么全部成功，要么全部失败。金融类的服务，可以使用分布式中间件实现TCC事务模型；互联网业务通常对一致性要求比较低，可以用本地消息表来实现分布式事务。 全局唯一性问题：在单库单表的情况下，业务ID可以依赖数据库的自增来实现。但在分库。分表后，如果还是这样，会导致主键重复。我们可以使用雪花算法或者美团leaf算法来生成全局唯一性主键ID 跨库跨表关联问题：分库分表后，跨库和跨表的查询操作实现起来比较复杂。可以通过冗余额外字段避免跨库跨表。或者交给数据库分库分表中间件来实现，也可以将数据全量存到ES中，在ES中查询。 跨库跨表COUNT查询问题：数据在不同的库不同的表，进行COUNT查询比较复杂。可以将计数的数据单独存到一张表中，或者将聚合查询的数据同步到ES中，交给ES去处理","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Spring事务","slug":"Spring事务","date":"2025-01-21T05:06:56.000Z","updated":"2025-01-21T06:23:29.727Z","comments":true,"path":"posts/Spring事务.html","permalink":"https://www.cdfy.top/posts/Spring%E4%BA%8B%E5%8A%A1.html","excerpt":"","text":"Spring事务传播级别 事务的传播机制定义了一个方法被另一个事务方法调用的时候，这个事务的方法行为该如何，定义了事务的边界和事务上下文在方法调用链中传播 Spring事务隔离级别 ISOLATION_DEFAULT: 使用后端默认的事务隔离级别，MySQL是可重复读，Oracle是读已提交 ISOLATION_READ_UNCOMMIT: 读未提交 ISOLATION_READ_COMMIT: 读已提交 ISOLATION_REPEATABLE_READ: 可重复读 ISOLATION_SERIALIZABLE: 串行化 声明式事务失效的场景 MySQL存储引擎是MyISAM，不支持事务 Spring的声明式事务是基于代理模式的。由于java继承时, 不能重写 private , final , static 修饰的方法，所以private 方法, final 方法 和 static 方法都没有事务支持 如果在开启事务的方法，事务try-catch捕获异常但没有抛出异常，事务不会起效 在不同类的方法调用，如果A方法开启了事务，B方法没有开启事务，B方法调用A 如果B方法发生异常，但不是调用的A产生的，事务失效 如果B方法发生异常，但是调用的A产生的，事务有效 在B方法上加上@Trasactional，一定会生效 同类方法调用，会失效。这是因为内部方法调用不会通过 Spring 生成的代理类进行调用，而是直接在当前对象中执行，因此 Spring 无法介入处理事务 如果使用了Spring+MVC，context：component-scan 重复扫描问题可能会引起事务失效。 如果spring和mvc的配置文件中都扫描了service层，那么事务就会失效 原因：因为spring ioc中子容器可以加载父容器，父容器不能加载子容器。这里springmvc相当于子容器。按照spring配置文件的加载顺序来讲，先加载springmvc配置文件，再加载spring配置文件，我们的事务一般都在spring配置文件中进行配置，如果此时在加载springMVC配置文件的时候，把service也给注册了，但是此时事务还没加载，也就导致后面的事务无法成功注入到service中。所以把对service的扫描放在spring配置文件","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"}]},{"title":"SpringBoot启动流程","slug":"SpringBoot启动流程","date":"2025-01-20T16:41:17.000Z","updated":"2025-01-20T16:46:13.205Z","comments":true,"path":"posts/SpringBoot启动流程.html","permalink":"https://www.cdfy.top/posts/SpringBoot%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.html","excerpt":"","text":"基础流程： Java程序由启动主类调用main()方法开始 根据@SpringBootApplication注解以及调用SpringApplication的构造方法，实例一个Spirng应用对象。在构造方法里主要完成启动环境初始化工作，如推断主类，spring应用类型，加载配置文件，读取spring.factories文件等 调用run方法，所有的启动工作在该方法内完成，主要完成加载配置资源，准备上下文，创建上下文，刷新上下文，过程事件发布等","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"}]},{"title":"Bean的生命周期以及IoC的实现原理","slug":"Bean的生命周期以及IoC的实现原理","date":"2025-01-20T16:02:42.000Z","updated":"2025-01-31T09:27:24.600Z","comments":true,"path":"posts/Bean的生命周期以及IoC的实现原理.html","permalink":"https://www.cdfy.top/posts/Bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%BB%A5%E5%8F%8AIoC%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html","excerpt":"","text":"Bean的生命周期以及IoC的实现原理","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"}]},{"title":"Java信号量——Semaphore","slug":"Java信号量——Semaphore","date":"2025-01-20T13:20:42.000Z","updated":"2025-01-20T13:43:44.802Z","comments":true,"path":"posts/Java信号量——Semaphore.html","permalink":"https://www.cdfy.top/posts/Java%E4%BF%A1%E5%8F%B7%E9%87%8F%E2%80%94%E2%80%94Semaphore.html","excerpt":"","text":"基本概念 Semaphore是一个计数信号量，它可以用来控制对某一资源的访问数量。在Java中，Semaphore位于java.util.concurrent包中 Semaphore的用途 流量控制：Semaphore可以用来控制同时访问特定资源的线程数量，例如数据库连接、文件句柄等 分配资源：Semaphore可以用来分配有限数量的资源，例如线程池、线程队列等 Semaphore的使用技巧 创建Semaphore 1Semaphore semaphore = new Semaphore(5); 获取信号量 1semaphore.acquire(); 请求一个信号量，这时候的信号量个数-1（是尝试获取，如果是&gt;0就减去, 否则阻塞等待信号量&gt;0） 释放信号量 1semaphore.release(); 信号量+1 使用tryAcquire方法 1boolean acquired = semaphore.tryAcquire(); 上述代码尝试获取信号量，如果成功则返回true，否则返回false 使用tryAcquire(long timeout, TimeUnit unit)方法 1boolean acquired = semaphore.tryAcquire(1000, TimeUnit.MILLISECONDS); 上述代码尝试获取信号量，如果成功则返回true，否则在指定的时间内返回false 力扣1116 打印零与奇偶数 https://leetcode.cn/problems/print-zero-even-odd/description/ 123456789101112131415161718192021222324252627282930313233343536class ZeroEvenOdd &#123; private int n; public ZeroEvenOdd(int n) &#123; this.n = n; &#125; // printNumber.accept(x) outputs &quot;x&quot;, where x is an integer. private Semaphore s0 = new Semaphore(1); private Semaphore s1 = new Semaphore(0); private Semaphore s2 = new Semaphore(0); public void zero(IntConsumer printNumber) throws InterruptedException &#123; for (int i = 1; i &lt;= n; i++) &#123; s0.acquire(); printNumber.accept(0); if (i % 2 == 1) s1.release(); else s2.release(); &#125; &#125; public void odd(IntConsumer printNumber) throws InterruptedException &#123; for (int i = 1; i &lt;= n; i += 2) &#123; s1.acquire(); printNumber.accept(i); s0.release(); &#125; &#125; public void even(IntConsumer printNumber) throws InterruptedException &#123; for (int i = 2; i &lt;= n; i += 2) &#123; s2.acquire(); printNumber.accept(i); s0.release(); &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"深入AQS底层源码","slug":"深入AQS底层源码","date":"2025-01-20T10:22:52.000Z","updated":"2025-01-20T10:56:40.553Z","comments":true,"path":"posts/深入AQS底层源码.html","permalink":"https://www.cdfy.top/posts/%E6%B7%B1%E5%85%A5AQS%E5%BA%95%E5%B1%82%E6%BA%90%E7%A0%81.html","excerpt":"","text":"AQS概述 AQS是juc包下的一个抽象类，很多juc包下的工具类都是根据AQS是实现的，比如ThreadPoolExecutor、CountDownLatch、ReetrantLock、ReetrantWriteLock、Semaphore AQS的核心内容 核心属性state 1234/** * The synchronization state. */private volatile int state; 不同的实现，state的意义不同。以ReetrantLock为例： state为0，没有线程持有这个lock锁 state &gt; 0，当前lock锁被某个线程持有 不存在state小于0的情况 同步队列 12345678910111213/** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */private transient volatile Node tail; Node 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor&#x27;s thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn&#x27;t need to * signal. So, most code doesn&#x27;t need to check for particular * values, just for sign. * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; /** * Link to predecessor node that current node/thread relies on * for checking waitStatus. Assigned during enqueuing, and nulled * out (for sake of GC) only upon dequeuing. Also, upon * cancellation of a predecessor, we short-circuit while * finding a non-cancelled one, which will always exist * because the head node is never cancelled: A node becomes * head only as a result of successful acquire. A * cancelled thread never succeeds in acquiring, and a thread only * cancels itself, not any other node. */ volatile Node prev; /** * Link to the successor node that the current node/thread * unparks upon release. Assigned during enqueuing, adjusted * when bypassing cancelled predecessors, and nulled out (for * sake of GC) when dequeued. The enq operation does not * assign next field of a predecessor until after attachment, * so seeing a null next field does not necessarily mean that * node is at end of queue. However, if a next field appears * to be null, we can scan prev&#x27;s from the tail to * double-check. The next field of cancelled nodes is set to * point to the node itself instead of null, to make life * easier for isOnSyncQueue. */ volatile Node next; /** * The thread that enqueued this node. Initialized on * construction and nulled out after use. */ volatile Thread thread; /** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */ Node nextWaiter; //用于Condition，因此Condition是单向链表（不用prev和next） /** * Returns true if node is waiting in shared mode. */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * * @return the predecessor of this node */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 以ReetrantLock为例，如果A线程想获取锁，但是发现锁资源被其他线程占用，A线程需要被封装成一个Node对象，进入到同步队列尾部排队，并挂起线程等待锁资源 Condition的单向链表 123456789101112131415161718192021222324252627282930313233public class ConditionObject implements Condition, java.io.Serializable &#123; private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; /** * Creates a new &#123;@code ConditionObject&#125; instance. */ public ConditionObject() &#123; &#125; // Internal methods /** * Adds a new waiter to wait queue. * @return its new wait node */ private Node addConditionWaiter() &#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125; 当持有lock锁的线程，执行了await方法，会将当前线程封装成Node，插入到Condition单向链表。等到其他线程执行singal唤醒，进入同步队列等到竞争锁资源 lock锁和AQS的继承关系 基本关系 非公平锁的逻辑 基于CAS操作，尝试将state从0变成1（在lock方法，非公平锁才有步骤1） 1.1 成功拿到锁，执行 1.2 竞争锁资源失败，进行后续的竞争 （进入2） 执行tryAcquire的逻辑 2.1 查看state是否为0，如果为0就再次执行cas尝试拿锁 2.2 查看是否是锁重入的逻辑，直接对state+1，锁重入成功 2.3 再次尝试拿锁的操作失败 （进入3） 执行addWaiter，准备进入同步队列排队 3.1 将当前线程封装为Node对象 3.2 将当前Node添加到同步队列的末尾 执行accquireQueued的逻辑，要做的不只是单纯的阻塞线程，还有被唤醒或者自旋获取锁后出队列 4.1 获取node节点的前驱节点，判断其是否是head,是则继续抢锁（可能刚入队列就排在head后面，也有可能自旋后，有其他节点获取锁出队列，而使得node排在head后面），抢锁成功则出队换头 4.2 node的前驱节点不是head或者抢锁失败，进入阻塞判断shouldParkAfterFailedAcquire 4.3 判断应该放心阻塞，调用parkAndCheckInterrupt阻塞当前线程 accquireQueued 12345678910111213141516171819202122232425262728final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //拿node的前一个节点 final Node p = node.predecessor(); //若p是头节点，，说明自己排在队列的第一个尝试抢锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //node成为新的head setHead(node); p.next = null; // help GC failed = false; //拿到锁了返回false return interrupted; &#125; //1.应该阻塞，调用parkAndCheckInterrupt阻塞线程 //2.不应该阻塞，再给一次抢锁的机会 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) //基本不可能走到这一步，除非是系统级别的异常导致获取锁失败for循环意外退出， cancelAcquire(node); &#125;&#125; 非公平锁和公平锁的直观体现 从源码上来看，公平和非公平的直观体现是lock方法和tryAcquire方法 lock方法一般是获取锁资源的入口方法，非公平锁会直接抢一次锁资源，而公平锁不会 acquire的底层逻辑 12345678910111213141516171819/** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once &#123;@link #tryAcquire&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquire&#125; until success. This method can be used * to implement method &#123;@link Lock#lock&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. */ // arg = 1public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 就是之前提到的逻辑： 先走tryAcquire，再次抢锁，抢到了就结束 没抢到执行addWaiter方法准备排队，被封装成Node，进入同步队列 再走acquireQueued方法，获取锁还是挂起线程，基于内部细粒度的逻辑 tryAcquire的底层逻辑 有公平锁和非公平锁两种实现 非公平锁实现 12345678910111213141516171819202122232425262728293031/** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ // final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 步骤2.1 if (c == 0) &#123; // 执行CAS，尝试将state从0修改成1 if (compareAndSetState(0, acquires)) &#123; //修改成功 setExclusiveOwnerThread(current); return true; &#125; &#125; // 步骤2.2 // 判断是不是锁重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); // 锁重入成功 return true; &#125; return false;&#125; 公平锁实现 12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 如果当前锁资源没被占用，需要满足一定的条件才能通过CAS抢锁 // 1. 如果AQS的同步队列没有排队的Node，可以抢锁 // 2. 如果AQS的同步队列有排队的Node，并且排在“第一名”的是当前线程，可以抢锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; hasQueuedPredecessors方法 12345678910public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; addWaiter的底层逻辑 1234567891011121314151617181920/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 通过CAS保证将tali指向自己，从而保证了原子性 如果CAS失败，会不断死循环，不断指向1，2操作 accquireQueued的底层逻辑 源码补充 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) //当前线程挂起 /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&#x27;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; /* 在park中： 只要permit为1或者中断状态为true，那么执行park就不能够阻塞线程。park只可能消耗掉permit， 但不会去消耗掉中断状态。 因此需要interrupt()去消耗掉，并将这个中断状态暂时保存到一个局部变量interrupted中 在selfInterrupt中： 当parkAndCheckInterrupt()方法返回true后又调用了 selfInterrupt()方法重 新设置中断标记，这样做的目的是为了让用户代码（同步代码块）能够通过 Thread.isInterrupted()等方法 感知到线程在获取同步状态的过程中被中断过。*/ AQS的Condition支持 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; /* Node只要在Condition单向链表中，状态就是上面的-2 waitStatus简写wt */ volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; /* 单向链表的下一个节点 */ Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; Condition是基于Node对象组成的单向链表 在Condition中，Node状态必须是-2，如果不是-2，就可以从中移除掉了 Condition的Node是利用nextWaiter属性连接下一个节点 Condition中还有指向头尾的两个属性，分别是firstWaiter和lastWaiter Condition的挂起操作流程 当持有lock锁的线程，执行以下4个流程： 将当前对象封装成Node对象，加入单向链表中 释放锁资源 确认当前线程的Node，没有在AQS的同步队列中。如果在，说明执行了signal方法，那个线程已经进入了同步队列。不需要挂起 没有在同步队列，直接挂起 Condition的signal唤醒操作流程 确保执行signal的线程持有锁资源 将第一个Node从单向链表中断开 将Node的状态从-2改成0 将Node移到同步队列 确保Node在同步队列中可以被唤醒。直接唤醒线程和将prev指向的Node状态设置为-1 Condition在await被唤醒后的逻辑 Condition在await被唤醒后的逻辑 1、确认被唤醒的方式： 单纯地被signal方法唤醒 被interrupt中断唤醒 被signal唤醒后，然后执行了interrupt（保留中断标记位） 确保Node在同步队列后，就可以跳出while循环 执行acquireQueued方法后，等待获取锁资源 在获取锁资源的同时，如果被中断过，需要确认是否保留中断标记位 如果是中断唤醒，需要将当前Node断开单向链表连接 根据中断模型，执行抛出异常、方法","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"JUC同步工具CountDownLatch源码解析，与CyclicBarrier的对比","slug":"JUC同步工具CountDownLatch源码解析","date":"2025-01-20T08:55:42.000Z","updated":"2025-01-20T10:18:47.671Z","comments":true,"path":"posts/JUC同步工具CountDownLatch源码解析.html","permalink":"https://www.cdfy.top/posts/JUC%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7CountDownLatch%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90.html","excerpt":"","text":"基本使用 CountDownLatch典型用法: 某一线程在开始运行前等待n个任务线程数执行完毕。将CountDownLatch的计数器初始化为new CountDownLatch(n)，每当一个任务线程数执行完毕，就将计数器减1 countdownLatch.countDown()，当计数器的值变为0时，在CountDownLatch上await()的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行 自定义任务类 1234567891011121314151617181920212223242526package org.example; import java.util.Random;import java.util.concurrent.CountDownLatch; public class Task implements Runnable&#123; private final static Random random = new Random(); private Integer id; private CountDownLatch latch; public Task(Integer id, CountDownLatch latch) &#123; this.id = id; this.latch = latch; &#125; @Override public void run() &#123; System.out.println(&quot;开始寻找&quot; + id + &quot;号龙珠&quot;); int seconds = random.nextInt(10); try &#123; Thread.sleep(seconds * 1000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; System.out.println(&quot;花费&quot; + seconds + &quot;s， 找到了&quot; + id + &quot;号龙珠&quot;); latch.countDown(); &#125;&#125; 测试类 12345678910111213141516171819202122package org.example; import java.util.Arrays;import java.util.List;import java.util.concurrent.CountDownLatch; public class Main &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7); CountDownLatch latch = new CountDownLatch(list.size()); for (Integer id: list) &#123; Thread thread = new Thread(new Task(id, latch)); thread.start(); &#125; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; System.out.println(&quot;over&quot;); &#125;&#125; 底层源码实现 基本架构 由上图中的等待队列唤醒变化可以发现，独占模式唤醒阻塞队列的头节点，共享模式唤醒阻塞队列所有的头节点 这里是特殊的，一般情况下await调用后Node是会进入condition单向链表，但是countdownLatch这里是直接进入AQS同步队列 在countdownlatch中sync实现的AQS采用的是共享模式 底层源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206public class CountDownLatch &#123; /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; /* * 如果state为0（锁被完全释放）则返回1，否则返回-1 * state为0，表示锁空闲。 * tryAcquireShared返回值是1，此时没有子任务持有锁，直接跳出等待，主线程不会被阻塞 * 为什么不返回0？ * 主任务不只有一个，假如有两个主任务都在等待两个子任务的完成。 * 一旦子任务全部完成，两个主任务都需要被唤醒。 */ return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; /* * 每次通过一个CAS操作将AQS内部的state自减1 * 若不需要释放锁，或未完全释放锁，则返回false * 若锁完全释放，返回true */ for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; &#125; private final Sync sync; public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); &#125; public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; public void countDown() &#123; sync.releaseShared(1); &#125; public long getCount() &#123; return sync.getCount(); &#125; public String toString() &#123; return super.toString() + &quot;[Count = &quot; + sync.getCount() + &quot;]&quot;; &#125;&#125; /* * public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; */ public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; /* * 如果线程中断则抛出异常 */ if (Thread.interrupted()) throw new InterruptedException(); /* * */ if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; /* * 如果返回的值是负数，则获取锁失败 * 如果返回的是0，获取锁成功，但不唤醒后续节点 * 如果返回正数，获取锁成功，唤醒后续节点 */protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); /* * tryAcquireShared返回值（传播值）大于等于0，锁已经是空闲的 * 说明子任务已经全部执行完，当前节点不必在等待，可以出队 */ if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; private void setHeadAndPropagate(Node node, int propagate) &#123; /* * 将当前节点设置为head，表示退出（head实际上是一个虚节点 * 也意味着当前节点封装的线程已经完成了同步，可以继续自由执行 */ Node h = head; setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) /* * 如果传播值是正数，就需要找到当前节点的后置节点，如果该节点也是共享模式需要将其唤醒 * 唤醒等待队列头部的线程，也就是主任务所在的线程 */ doReleaseShared(); &#125;&#125; /* * public void countDown() &#123; sync.releaseShared(1); &#125; */public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; protected boolean tryReleaseShared(int releases) &#123; /* * 通过自旋的方式保证了state的值的自减 * 一旦state减到0，就返回true，锁已经释放完 */ for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; private void doReleaseShared() &#123; /* * 对等待队列的节点从后往前搜索（AQS），将head的后置节点唤醒 */ for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; /* * doReleaseShared(); * 上面已经提及 */ 一些问题 state是0的时候，会唤醒阻塞队列的Node，这里唤醒是唤醒Head下的第一个，还是都唤醒？ CountDownLatch基于aqs共享模式，会唤醒sync queue的所有node，详细源码看doReleaseShared 其他线程被唤醒后，会先执行哪里的代码呢 主线程会在这里被阻塞 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 可知，调用了park方法，主线程被阻塞 所以for循环那里的目的何在？ 被唤醒后，需要看一下r值，如果r值不符合逻辑，那么会接着阻塞 与CyclicBarrier的对比 初始化 1234567// 初始化值为5的栅栏CyclicBarrier cyclicBarrier = new CyclicBarrier(5);// 每个线程调用 await()cyclicBarrier.await();// 等到有 5 个线程都执行了 await() 之后，继续执行。// 并且 栅栏的 计数器会自动重置为 5 ，可以接着用 测试类 1234567891011121314151617181920212223242526public class CyclicBarrierTest &#123; private final static ExecutorService EXECUTOR_SERVICE = Executors.newFixedThreadPool(5); private final static CyclicBarrier BARRIER = new CyclicBarrier(10); public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; final String name = &quot;玩家&quot; + i; EXECUTOR_SERVICE.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println(name + &quot;已准备,等待其他玩家准备...&quot;); BARRIER.await(); Thread.sleep(1000); System.out.println(name + &quot;已加入游戏&quot;); &#125; catch (InterruptedException e) &#123; System.out.println(name + &quot;离开游戏&quot;); &#125; catch (BrokenBarrierException e) &#123; System.out.println(name + &quot;离开游戏&quot;); &#125; &#125; &#125;); &#125; EXECUTOR_SERVICE.shutdown(); &#125;&#125; CountDownLatch 操作的是事件，阻塞足够多的次数即可，不管几个线程；而 CyclicBarrier 侧重点是线程，强调多个线程间互相等待，同时结束 CountDownLatch：面向任务数、不可重用、不指定线程 CyclicBarrier: 面向线程、可重用、指定线程 CountDownLatch调用countDown计数器-1，CyclicBarrier调用await计数器-1 都是计数器为0的时候，唤醒同步队列的所有线程，让所有的被阻塞的线程一起运行 不管什么线程调用await都是让谁暂停，只不过CountDownLatch是主线程暂停等待任务都完成，CyclicBarrier是所有任务线程都暂停后同时就绪，测试并行性","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"跳表节点层数的确定方法","slug":"跳表节点层数的确定方法","date":"2025-01-19T14:12:58.000Z","updated":"2025-01-19T14:18:23.838Z","comments":true,"path":"posts/跳表节点层数的确定方法.html","permalink":"https://www.cdfy.top/posts/%E8%B7%B3%E8%A1%A8%E8%8A%82%E7%82%B9%E5%B1%82%E6%95%B0%E7%9A%84%E7%A1%AE%E5%AE%9A%E6%96%B9%E6%B3%95.html","excerpt":"","text":"初始化节点层数为1，这是跳表中所有节点的初始层数 对每个节点，通过随机数生成器生成一个介于0和1之间的随机数p 将p与固定的概率因子P进行比较，如果p小于P，则将节点的层数加1 重复步骤2和步骤3，直到p大于或等于P为止 产生越高的节点层数，概率越低。定量的分析如下： 假设概率因子是p，节点层数至少为 1。 而大于 1 的节点层数，满足一个概率分布： 节点层数恰好等于 1 的概率为 1-p 节点层数大于等于 2 的概率为 p，而节点层数恰好等于 2 的概率为 p(1-p) 节点层数大于等于 3 的概率为 p^2，而节点层数恰好等于 3 的概率为 p^2*(1-p) 节点层数大于等于 4 的概率为 p^3，而节点层数恰好等于 4 的概率为 p^3*(1-p) …… 一个节点的平均层数（也即包含的平均指针数目）（期望）： 现在很容易计算出： 当 p=1/2 时，每个节点所包含的平均指针数目为 2 当 p=1/4 时，每个节点所包含的平均指针数目为 1.33","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"IOC的三级缓存以及循环依赖问题","slug":"IOC的三级缓存以及循环依赖问题","date":"2025-01-19T13:46:39.000Z","updated":"2025-01-19T14:09:46.302Z","comments":true,"path":"posts/IOC的三级缓存以及循环依赖问题.html","permalink":"https://www.cdfy.top/posts/IOC%E7%9A%84%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E4%BB%A5%E5%8F%8A%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98.html","excerpt":"","text":"三级缓存 一级缓存&lt;Map, String&gt;singletonObjects：储存最终的完整bean的容器 二级缓存&lt;Map, String&gt;earlySingletonObjects：储存实例化但未初始化的半成品bean 三级缓存&lt;Map, ObjectFactory&lt;?&gt;&gt;singletonFactories：存放用于生成代理对象的临时代理工厂（ObjectFactory），当出现循环依赖的时候，如果有bean生成需要生成代理，则会从此获取代理对象，然后放入二级缓存中并在三级缓存中移除 循环依赖 A和B循环依赖 初始化对象过程： A先去一级缓存中找，如果没有找到去二级缓存，否则去三级缓存生成一个工厂对象。接着去初始化B，最终也会在三级缓存生成一个对象B，然后再装填A。出现了循环依赖，再生成A的时候发现三级缓存中存在，于是会生成一个半成品对象A放入二级缓存中并在三级缓存中移除（如果需要生成代理就会获取代理对象） 接着B已经完成创建完毕，所以将B放入一级缓存同时将二级缓存和三级缓存中的B移除。然后A对象装填B后也创建完成，将A放入一级缓存同时将二级缓存和三级缓存中的A移除 为什么需要三级缓存 由于Spring的代理发生在Bean初始化后，当存在循环依赖的时候，由于进行依赖注入的Bean尚未初始化，因此被依赖注入的Bean实际上获得的是未代理的原始Bean，因此AOP会失效 为了解决这个问题，必须让未初始化的Bean在进行依赖注入的时候也能被代理，需尽可能早的指定其代理","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}]},{"title":"Autowired注解注入的对象是单例吗","slug":"Autowired注解注入的对象是单例吗","date":"2025-01-19T13:10:05.000Z","updated":"2025-01-31T09:27:03.300Z","comments":true,"path":"posts/Autowired注解注入的对象是单例吗.html","permalink":"https://www.cdfy.top/posts/Autowired%E6%B3%A8%E8%A7%A3%E6%B3%A8%E5%85%A5%E7%9A%84%E5%AF%B9%E8%B1%A1%E6%98%AF%E5%8D%95%E4%BE%8B%E5%90%97.html","excerpt":"","text":"Autowired注解注入的对象是单例","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"}]},{"title":"JVM堆的大小参数应该怎么设置","slug":"JVM堆的大小参数应该怎么设置","date":"2025-01-19T12:27:18.000Z","updated":"2025-01-19T12:32:15.938Z","comments":true,"path":"posts/JVM堆的大小参数应该怎么设置.html","permalink":"https://www.cdfy.top/posts/JVM%E5%A0%86%E7%9A%84%E5%A4%A7%E5%B0%8F%E5%8F%82%E6%95%B0%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E8%AE%BE%E7%BD%AE.html","excerpt":"","text":"JVM堆大小参数的设置需要根据应用程序的需求、可用内存以及性能目标来确定。 可以通过-Xms（初始堆大小）和-Xmx（最大堆大小）参数进行设置。例如，-Xms512m -Xmx2g表示初始堆大小为512MB，最大堆大小为2GB 还有其他一些与堆相关的参数，如-XX:NewRatio用于设置年轻代和老年代的比例，默认值是2，表示年轻代占堆的1/3。比如-XX:NewRatio=2 -XX:SurvivorRatio用于设置Eden区和一个Survivor区的比例，默认值是8，表示Eden区占年轻代的8/10。比如-XX:Survivor=8 此外，还有-XX:+UseG1GC等参数用于选择不同的垃圾收集器，不同的垃圾收集器对堆大小的设置有不同的要求。比如-XX:+UseSerialGC、-XX:+UseG1GC","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cdfy.top/tags/JVM/"}]},{"title":"为什么堆的空间不连续","slug":"为什么堆的空间不连续","date":"2025-01-19T12:18:40.000Z","updated":"2025-01-19T12:22:06.611Z","comments":true,"path":"posts/为什么堆的空间不连续.html","permalink":"https://www.cdfy.top/posts/%E4%B8%BA%E4%BB%80%E4%B9%88%E5%A0%86%E7%9A%84%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%BF%9E%E7%BB%AD.html","excerpt":"","text":"由于堆内存的分配和释放是动态的，其空间的分布是不规则的，因此堆的空间是不连续的。 当程序向堆中申请内存时，堆可能会在已分配的内存块之间留下一些未使用的“碎片”，这些碎片可能太小，无法满足程序对更大内存块的申请。 这就是堆内存碎片问题，它可能会导致堆空间的利用效率下降。 总之，堆空间是不连续的，它的分配和释放是动态的，可能会产生内存碎片问题 因此hashMap扩容要重新创建哈希表，采用复制算法，因为Entry类型的hashTable数组必须是连续的（不然直接向后添加可能后面没有连续空间了）","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"大端存储和小端存储的区别","slug":"大端存储和小端存储的区别","date":"2025-01-19T10:46:26.000Z","updated":"2025-01-19T12:12:06.306Z","comments":true,"path":"posts/大端存储和小端存储的区别.html","permalink":"https://www.cdfy.top/posts/%E5%A4%A7%E7%AB%AF%E5%AD%98%E5%82%A8%E5%92%8C%E5%B0%8F%E7%AB%AF%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"前言 首先要记住：读数据永远是从低地址开始的！！！ 什么是低地址、高地址？ 地址编号小的是低地址，地址编号大的是高地址 什么是数据的低位、高位？ 权值低的位是低位，权重高的位是高位 小端模式 数据的低位放在低地址空间，数据的高位放在高地址空间 简记：小端就是低位对应低地址，高位对应高地址 存放二进制数：1011-0100-1111-0110-1000-1100-0001-0101 从地址0到地址3分别是：0001-0101 1000-1100 1111-0110 1011-0100 读取数据：永远从低地址开始读，从低位放起，因此是这个方向存放：&lt;- 得到 1011-0100-1111-0110-1000-1100-0001-0101 大端模式 数据的高位放在低地址空间，数据的低位放在高地址空间 存放二进制数：1011-0100-1111-0110-1000-1100-0001-0101 从地址0到地址3分别是：1011-0100 1111-0110 1000-1100 0001-0101 读取数据：从低地址开始读，从高位放起，因此是这个方向存放：-&gt; 得到 1011-0100-1111-0110-1000-1100-0001-0101","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"深入理解synchronzied以及底层源码剖析","slug":"深入理解synchronzied以及底层源码剖析","date":"2025-01-19T09:42:53.000Z","updated":"2025-01-19T10:25:47.191Z","comments":true,"path":"posts/深入理解synchronzied以及底层源码剖析.html","permalink":"https://www.cdfy.top/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3synchronzied%E4%BB%A5%E5%8F%8A%E5%BA%95%E5%B1%82%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90.html","excerpt":"","text":"synchronized 保证三大特性 保证原子性：保证只有一个线程可以拿到锁，进入同步代码块 保证可见性：执行时会定义lock原子操作，会刷新工作内存共享变量的值 保证有序性：加synchronized后，依然会发生重排序，只不过因为加了同步代码块，可以保证只有一个线程执行同步代码块中的代码 synchronizd 的特性 可重入特性 什么是可重入？ 一个线程可以多次执行synchronized，重复获取同一把锁 可重入性原理： synchronized的锁对象有一个计数器（recurisons变量）会记录线程获得几次锁，当计数器为0时，就释放锁 好处： 避免死锁 可以让我们更好的封装代码 不可中断特性 一个线程获得锁后，另一个线程也要获得锁，那么这个线程处于阻塞或等待状态，如果第一个线程不释放锁第二个线程将会一直阻塞或等待（不可中断） 与此对比，lock可以调用lock方法（不可中断）和trylock方法（可中断） synchronized 原理 monitor监视器锁 monitorenter： synchronized的锁对象会关联一个monitor，这个monitor不是我们主动创建的，是jvm线程执行到这个同步代码块，发现锁对象没有monitor就会主动创建（是c++代码创建），其内部有两个重要的成员变量owner：拥有这把锁的线程。recursion：记录线程拥有锁的次数，当减到0次会释放锁 monitorexit： recursion -1 在方法结束处和异常处，jvm保证每个monitorenter都有一个对应的monitorexit 对于同步方法，在反汇编后，会增加ACC_SYNCHRONIZED修饰，会隐式调用monitorenter和monitorexit monitor竞争 执行monitorenter时，最终会调用ObjectMonitor::enter(c++代码): 通过CAS尝试把monitor的owner字段设置为当前线程 如果之前设置的owner指向当前线程，说明是重入锁，执行recursion++，记录当前重入的次数 如果是第一次进入该monitor，设置recursion为1，_owner为当前线程，获得成功则返回 如果获取锁失败，则等待锁的释放（对应ObjectMonitor对象的EnterI方法） monitor等待 进入EnterI方法： 先尝试获得两次，如果还是不能则当前线程被封装成ObjectWaiter对象node，状态设置为ObjectWaiter::TS_CXQ 在for循环中，通过CAS把node节点push到_cxq列表中，同一时刻可能有多个线程把自己的node节点push到_cxq列表中 node节点被push之后，通过尝试自旋获取到锁，如果还是没有获取到锁，通过park将当前线程挂起，等待被唤醒 当该线程被唤醒时，会从挂起的点继续执行，通过ObjectWaiter::TryLock尝试获取到锁 monitor释放 具体实现位于ObjectWaiter的exit方法，实现锁的释放： 退出同步代码块让_recurison -1，当_recurison减到0时，说明锁释放了 根据不同的策略（QMode指定），从cxq或EntryList中获取头节点，通过ObjectMonitor::ExitEpilog方法唤醒该节点包装的线程，唤醒操作最终由unpark完成 monitor是重量级锁 因为函数调用涉及到操作系统用户态和内核态的切换，比如park和unpark等内核函数（在内核态运行），这样切换就会消耗大量的系统资源 JDK6 synchronized做的优化 CAS CAS全称：Compare And Swap（比较相同再交换），是现代cpu对内存中的共享数据进行操作的特殊指令 作用：CAS可以将比较和交换转换为原子操作，这个原子操作由cpu保证。CAS可以保证共享变量赋值的原子操作 CAS依赖3个值，内存中的值V，旧的预估值X，要修改的值B。如果旧的预估值X等于内存中的值V，就将新的值B保存到内存中 比如AtomicInteger的源码中，由Unsafe类提供原子操作。其中，Unsafe类使Java拥有了像C语言指针一样操作内存空间的能力，但是由于出错概率大，因此不能直接调用，只能通过反射获得 CAS获取变量时，为了保证变量的可见性，需要用volatile修饰。结合CAS和volatile可以实现无锁并发，适用于竞争不激烈，多核cpu的场景 因为没有使用synchronized，所以线程不会陷入阻塞，提高了效率 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 为什么value要使用volatile修饰？ 因为要保证每个线程读取value内存中的值都是最新值（可见性），然后每次操作的时候再通过CAS判断此时有没有“落后可见性” java对象头 其中hashCode在使用时才生成，并且整个存储采用大端存储 锁升级 jdk6实现了锁升级 无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁 偏向锁 原理： 执行到一个线程访问同步块时，虚拟机看对象头mark word标志位是否是01，如果是将偏向锁标志位设置为1，表示偏向锁 通过CAS将mark word 前54位设置成当前线程ID，如果CAS操作成功，下次持有该偏向锁的线程再次进入这个锁相关的同步块时，虚拟机可以不用再进行任何同步操作，效率变高 撤销： 必须等到全局安全点 判断锁对象是不是偏向锁 如果是，恢复到无锁或者升级成轻量级锁 优点： 偏向锁在一个线程执行同步代码块时提高效率，适用于一个线程反复获得锁的情况，提高带有同步但无竞争的程序性能 如果是被多个线程访问比如线程池，就是多余的 在jkd5默认关闭，jdk6默认开启，但是在应用程序启动几秒后才开启。可以通过-XX:BiasedLockingStartupDelay=0关闭延迟 轻量级锁 轻量级锁是相当于monitor的传统锁而言，因此传统的锁机制称为重量级锁。但是，轻量级锁不能够代替重量级锁，因为只有在特定情况下开销小 适合多线程交替执行同步块的情况，但是不适合多线程同一时刻竞争的情况 原理： 判断当前对象是否处于无锁状态（hashcode，0，01），如果是，则jvm在当前栈帧创建一个锁记录（lock record）的空间，用于存储锁对象目前的mark word的拷贝（官方把这个拷贝加了一个前缀 displaced），将当前对象的mark word赋值到那里，并将lock record的owner指向当前对象 jvm利用cas操作尝试将当前对象的mark word中的指针更新为指向lock record的指针，如果成功表示竞争到了锁，将锁标记置为00，执行同步操作 如果失败判断当前锁对象的mark word中的指针是否指向当前栈帧，如果是表示当前线程已经持有此对象，直接执行同步代码块。否则说明该锁对象被其他前程占用了，该锁升级为重量级锁。锁标志设置成10，后面等待的线程会进入阻塞状态 自旋锁 由于实现重量级锁，线程的阻塞和唤醒需要cpu从用户态转换为内核态，对cpu开销大。并且开发者注意到在许多应用上，共享数据的锁定只会持续很短，为了这点短暂时间阻塞和唤醒线程并不值得。因此我们可以让线程执行一个忙循环（自旋），不放弃处理器的执行时间，这就是自旋锁 在jdk6时引入了自适应自旋锁，意味着自旋的次数不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定 锁消除 虚拟机即时编译（JIT）运行时，根据逃逸分析，判断在一段代码中，堆上的所有数据都不可能会逃逸出去被其他线程访问到，那么可以把他们当做栈上数据来对待，认为他们是线程私有的，同步加锁自然无须进行 锁粗化 jvm会探测到一连串细小的操作都由同一个对象加锁，将同步代码块的范围放大，放到这串操作的外面，这就是锁粗化 平时写代码如何对synchronized做优化 减少synchronized的范围 尽量让synchronized同步的代码尽量短，减少同步代码块的执行时间，减少锁的竞争 降低synchronized锁的粒度 将一个锁拆分为多个锁提高并发度 例如：Hashtable 和 ConcurrentHashMap 读写分离 读时不加锁，写入和删除时加锁 比如ConcurrentHashMap,CopyOnWriteArrayList,CopyOnWriteSet","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"https://www.cdfy.top/tags/%E9%94%81/"}]},{"title":"MySQL日志","slug":"MySQL日志","date":"2025-01-18T15:51:30.000Z","updated":"2025-01-18T16:00:52.354Z","comments":true,"path":"posts/MySQL日志.html","permalink":"https://www.cdfy.top/posts/MySQL%E6%97%A5%E5%BF%97.html","excerpt":"","text":"MySQL三大日志是什么 undo log是Innodb存储引擎生成的日志，实现了事务的原子性，主要用于事务回滚和MVCC。在事务没提交之前，在事务没提交之前，Innodb会将更新前的记录记录在undo log中，需要回滚的时候根据undo log做原先相反操作 redo log也是Innodb存储引擎的日志，属于物理日志，记录了某个数据页做了什么修改，实现了事务的持久性，主要用于断电等故障恢复。比如某个事务提交了，脏页数据还没刷盘，但是断电了。下次重启的时候可以通过redo log恢复数据 binlog是Server层生成的日志，主要用于数据备份和主从复制，在完成一条更新操作后，Server层会生成一条binlog，等之后事务提交时，会将该事务执行过程产生的所有binlog统一写入binlog文件中。binlog文件记录了所有数据库表结构和表数据修改的日志，不会记录查询类的操作 binlog日志有哪些格式 STATEMENT（默认格式）：每一条修改的SQL都会被记录在binlog中（逻辑日志），主从复制中slave端再根据SQL语句重现。但STATEMENT有动态函数的问题，比如你用uuid或者now这些函数，你在主库上执行的结果并不是你在从库上执行的结果，因此会导致数据不一致 ROW：记录行数据最终被修改成什么样（不是逻辑日志），不会出现STATEMENT的动态函数问题。但是也有缺点是每行数据的变化记录都会被修改，比如批量执行update语句，更新多少行就产生多少行记录，会导致binlog文件过大，而在STATEMENT下只会记录update语句而已 MIXED：包含了STATEMENT和ROW模式，它会根据不同的情况使用不同的模式 redo log和binlog的区别和应用场景 适用对象不同： binlog是MySQL Server层的日志，适用于所有引擎 redo log是Innodb存储引擎的日志 文件格式不同： binlog有三种格式： STATEMENT（默认格式）：每一条修改的SQL都会被记录在binlog中（逻辑日志），主从复制中slave端再根据SQL语句重现。但STATEMENT有动态函数的问题，比如你用uuid或者now这些函数，你在主库上执行的结果并不是你在从库上执行的结果，因此会导致数据不一致 ROW：记录行数据最终被修改成什么样（不是逻辑日志），不会出现STATEMENT的动态函数问题。但是也有缺点是每行数据的变化记录都会被修改，比如批量执行update语句，更新多少行就产生多少行记录，会导致binlog文件过大，而在STATEMENT下只会记录update语句而已 MIXED：包含了STATEMENT和ROW模式，它会根据不同的情况使用不同的模式 redo log: 物理日志，记录的是某个数据页做了什么修改，比如对XX表空间中的YY数据页做了ZZ偏移量的AA更新 写入方式不同： binlog是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志 redo log是循环写，日志空间大小是固定的，全部写满就重头开始，保存未被刷入磁盘的脏页数据 用途不同： binlog用于备份恢复、主从复制 redo log用于掉电等故障恢复 为什么崩溃恢复不用binlog而用redo log binlog是server层的日志，不会记录innodb存储引擎中有哪些数据没被刷盘，redo log是innodb存储引擎的日志，会记录哪些脏页没被刷盘，崩溃恢复的时候，恢复的粒度更细，可以精确到恢复的页。而binlog保存的是全量日志，因此效率比redo log恢复效率低 redo log是怎么实现持久化 事务执行过程中更新的数据，不是在事务提交的时候，刷新到磁盘，而是修改buffer pool中的数据页为脏页，然后后台再找时机刷盘 如果事务提交了，脏页还没有刷盘，就会造成事务修改的数据丢失 因此引入了redo log，主要记录了Innodb对某个页做的修改操作，当事务提交时，redo log会先刷入磁盘，因为redo log保存了数据页的修改操作，即使脏页数据没有刷盘，下次MySQL启动时，可以通过重放redo log保持数据的持久化 redo log有什么功能 实现事务的持久性，让MySQL有crash-safe的能力，能够保证MySQL在任何时候突然崩溃，重启之后之前提交的记录不会丢失 将写操作从随机写变成顺序写，提升MySQL写入磁盘的性能。先写redo log是一个顺序写的过程，同时真正的数据写磁盘由MySQL在最合适的时机写入，肯定比每次随机写都要快 为什么需要两阶段提交 两阶段提交是为了保证redo log和binlog逻辑一致，从而保证主从复制的时候不会出现数据不一致的情况 事务提交后，redo log和binlog都要持久化到磁盘，但是这是两个独立的逻辑，可能出现半成功的状态。比如在主从复制的场景下，如果将redo log刷入到磁盘，MySQL突然宕机了，而binlog还没有来得及写入到磁盘，这时候主库是最新的数据，从库是旧数据，就造成了主从不一致 两阶段提交的过程 两阶段提交将事务分成了两个阶段，准备阶段和提交阶段： prepare阶段：将XID（内部XA事务的ID）写入到redo log中，同时将redo log刷入到磁盘。然后将redo log状态设置为prepare commit阶段：将XID写入到binlog中，同时将binlog写入磁盘。然后将redo log设置为commit状态，两阶段提交完成 两阶段提交，是以binlog写入磁盘为成功标志： 如果在写入redo log之前崩溃，此时redo log和bin log是没有数据的，那么数据是满足一致性 如果在写入redo log prepare阶段后立马崩溃，之后在崩溃恢复的时候，由于redo log没有被标记为commit，于是拿着redo log中的XID去binlog中查找，一定找不到。于是就执行回滚操作 如果写入binlog到磁盘后立马崩溃，即使redo log没有设置commit状态，但是由于redo log中的XID在binlog中找得到，说明都完成了刷盘，直接提交事务即可 Redo log刷盘策略是什么 主要有三种： 当刷盘策略参数配置为0的时候，每次提交事务，将redo log留在redo log buffer中，该模式下事务不会主动触发写入到磁盘的操作，后续由innodb后台线程把缓存在redo log buffer中的redo log写入到操作系统的page cache缓存并持久化到磁盘 当刷盘策略参数配置为1的时候，每次事务提交，都将缓存在redo log buffer中的刷入到磁盘 当刷盘策略参数配置为2的时候，每次事务提交的时候，都只是将redo log buffer中的redo log写入到操作系统的page cache缓存，但并不会执行刷盘，后续有innodb的后台线程执行刷盘 三种策略，参数为1的安全性最高，但也是写入性能最差的。参数为0的安全性最差，写入性能最好","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL锁","slug":"MySQL锁","date":"2025-01-18T15:34:02.000Z","updated":"2025-01-18T15:42:45.734Z","comments":true,"path":"posts/MySQL锁.html","permalink":"https://www.cdfy.top/posts/MySQL%E9%94%81.html","excerpt":"","text":"MySQL锁 全局锁： 通过flush talbe with read lock语句可以将整个数据库变成只读状态，这时候线程执行增删改或者表结构被修改都会阻塞，适用于全库备份逻辑。这样在备份数据库期间，不会因为表结构和数据的更新，使得备份文件的数据和预期不一样 表级锁： 表锁： 通过lock tables语句对表加表锁，表锁除了会限制其他线程的读写，还会限制本线程的读写 元数据锁：当我们对数据库表做操作，会自动给这个表加上MDL，对一张表做CRUD操作时，加的是MDL读锁；对一张表做结构更改时，加的是MDL写锁。这样对一张表执行CRUD操作时，防止其他线程对表做结构变更 意向锁：当执行插入、更新、删除操作时，需要先对表加上意向独占锁，然后对该记录加上独占锁。意向锁的目的是快速判断表里是否有记录被加锁 行级锁(只有InnoDB引擎有行级锁)： 记录锁（Recode Lock）：锁住的是一条记录。而且记录锁有S锁和X锁之分，满足读写互斥、写写互斥 间隙锁（Gap Lock）：只存在于可重复读隔离级别，此外间隙锁是兼容的，不会出现互斥关系，目的是解决可重复读隔离级别下幻读的现象 临键锁(next-key Lock)：是记录锁+间隙锁的组合, 锁定一个范围，并且锁定记录本身 插入意向锁：当插入位置的下一条记录上有间隙锁，就会生成插入意向锁，然后进入阻塞状态。但是它不是意向锁，它是一种特殊的间隙锁，因为只锁住一个点 MySQL怎么实现乐观锁 可以在数据库表增加一个版本号字段，利用这个版本号字段实现乐观锁 具体的实现是每次更新数据的时候，都要带上版本号，同时将版本号+1。比如现在要更新id = 1，版本号为2的记录。这时候要先获取版本号为1的记录，只有版本号一致的情况下才能做出修改，如果不相等就不更新，需要重新获取该记录的最新版本号再次尝试 在线上修改表结构，会发生什么 线上环境可能有很多事务都在读写这张表，会对这张表加上MDL读锁。修改表结构会对表加上MDL写锁，会发生读写冲突，所以修改表结构的操作就会阻塞，并对后续事务的增删改操作都会阻塞 创建索引的时候会锁表吗 会的，创建索引会加MDL写锁，如果这时候其他事务对这张表进行增删查改的话，会产生MDL写锁，因为读写冲突，就会阻塞 间隙锁的工作原理是什么 间隙锁防止其他事务往间隙插入新记录，从而避免幻读。具体的原理是其他事务插入一条记录时，发现插入位置的下一条记录有间隙锁，就会生成插入意向锁，然后锁设置为阻塞状态，目的是告诉用户插入的位置存在间隙锁 一条update语句不带where，加的是什么锁 可重复读级别下，没有带where，会进行全盘扫描，每一条记录加上next-key锁 读已提交级别下，没有带where，也会全盘扫描，每条记录加上记录锁 带了where条件没有命中索引，加的是什么锁 可重复读级别下，会进行全盘扫描，每一条记录加上next-key锁 读已提交级别下，也会全盘扫描，每条记录加上记录锁 两条更新语句更新同一条记录的不同字段，加的是什么锁 可重复读隔离级别下，可能有这些情况： 如果更新的字段是唯一索引，还要看更新的记录是否存在： 如果存在，那么这条记录加的是记录锁，只会锁住该记录 如果不存在，会加间隙锁 如果更新的字段是非唯一索引，也要看更新的记录是否存在： 如果存在，由于非唯一索引会有相同的值，所以实际上非唯一索引等值查询是一个扫描的过程，会对扫描到的符合条件的记录都加上next-key锁，最后扫描到第一个不符合的条件记录停止扫描，并且加上间隙锁。同时，在符合条件的主键索引上加上记录锁 如果不存在，会对第一个不符合更新条件的二级索引记录加上间隙锁 可重复读隔离场景下，下面的场景会发生什么 事务A和事务B在执行完更新语句后，由于记录不存在并且间隙锁兼容，都会加上(20,30）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都会等待对方的间隙锁释放，就会造成死锁 了解过MySQL死锁问题吗 在并发事务中，两个事务出现了循环资源依赖，这两个事务都在等待另一方释放资源，从而进入了无限等待的状态，就有了死锁 比如一个例子： 一张表有一个id为20和id为30的记录，事务A和事务B在执行完更新id = 25的语句后，由于记录不存在并且间隙锁兼容，都会加上(20,30）的间隙锁，而接下来的插入操作为了获取到插入意向锁，都会等待对方的间隙锁释放，就会造成死锁 MySQL怎么避免死锁 通过show engine innodb status命令获取死锁信息 日志上半部分说明了事务1在等待什么锁，下半部分说明了事务持有的锁和等待的锁 因此通过阅读日志就可以找到死锁发生的原因，可以进一步处理 MySQL怎么避免死锁 实际上死锁是无法避免的，但我们可以通过一些手段，降低死锁发生的概率 MySQL的锁是在事务提交后才被释放，所以我们可以缩短锁持有的时间，降低死锁的概率，比如： 如果事务中需要锁定多个行，要把最可能发生锁冲突的申请时机往后放，这样事务锁的持续时间就比较短 避免大事务，尽量讲大事务拆分成几个小事务，这个锁持有的时间就比较短 可以通过减少间隙锁，降低死锁的概率： 如果能确定幻读和不可重复读对应用的影响不大，可以将隔离级别改成读提交，这样就没有了间隙锁，降低了死锁的概率 可以通过减少锁的范围，降低死锁的概率： 给表添加合理的索引，如果不走索引表的每一行记录都会加上行级锁，发生死锁的概率大 通过设置MySQL参数，降低死锁的概率： 设置锁等待超时阈值&quot;innodb_lock_wait_timeout&quot;，当一个事务的等待时间超过该值后，事务将被回滚，使用“innodb_rollback_on_timeout”开启值为ON，开启这个参数后，锁超时后就会回滚 开启主动死锁检测&quot;innodb_deadlock_detect&quot;，主动死锁检测在发生死锁后，主动回滚死锁链条中的某一个事务，让其他事务继续执行","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"SpringBoot核心注解以及自动装配","slug":"SpringBoot核心注解以及自动装配","date":"2025-01-18T14:01:21.000Z","updated":"2025-01-18T14:33:12.765Z","comments":true,"path":"posts/SpringBoot核心注解以及自动装配.html","permalink":"https://www.cdfy.top/posts/SpringBoot%E6%A0%B8%E5%BF%83%E6%B3%A8%E8%A7%A3%E4%BB%A5%E5%8F%8A%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D.html","excerpt":"","text":"核心注解 @SpringBootApplication: 标识一个类作为SpringBoot的启动类，是@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan的组合 @SpringBootConfiguration：配置类，用于定义一个Bean，是一个特殊的@Configuration注解，用于加载配置 @EnableAutoConfiguration：用于启动自动配置的功能，可以自动引入相关的配置，减少开发成本 @ComponentScan：定义Spring扫描包的路径，用于发现应用程序中的bean、组件、配置类和服务等，可以自动扫描并注册包路径下的带有@Component、@Service等注解的类 自动装配是什么 自动装配可以根据项目中添加的依赖和其他因素，自动创建和配置Spring应用所需要的Bean，开发者不需要书写大量的XML配置或者Java配置类来设置Spring容器 自动化配置原理 自动化配置首先从组件说起，@SpringBootApplication是@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan的组合 其中@EnableAutoConfiguration通过@Import注解将AutoConfigurationImportSelector.class这个类引入进来 AutoConfigurationImportSelector.class会加载jar包的META-INF下面的spring-factories配置文件，其实用到了SPI机制 spring-factories配置文件是一个key-value的形式，key是EnableAutoConfiguration的全路径名，value是各个需要配置的类，然后SpringBoot默认在这个配置类里面定义了100多个常用的配置类，然后再根据Condition按需加载我们的配置类，比如在配置文件中增加了对应的类才会生效 SPI 当接口存在于调用方这边，就是SPI。由调用方设计接口，然后由不同的厂商去根据这个规则接口进行实现，从而提供服务 API接口实现在厂商，调用方去获得服务 @ComponentScan默认扫描路径 默认扫描 在SpringBoot中使用@ComponentScan()注解进行组件扫描加载类时，默认的扫描范围是启动类([ProjectName]Application)所在包(直接父包)的子包。也即需要被扫描的包下的类要位于启动类所在路径下 正确扫描： 1234567src main java com.cdfy.test testApplication controller testController * 分析： testController位于testApplication所在包com.cdfy.test下 * 启动类所在路径： com/cdfy/test/ 错误扫描: 123456789src main java com.cdfy.test application testApplication controller testController * 分析：此时testApplication所在包为application,而controller和application无包含关系，则扫描不到controller下面的包，会造成bean创建失败。 * 启动类所在路径： com/cdfy/test/application 自定义扫描 若当前情况下，其他类不在application类所在包的子包中，但还需扫描作为bean供创建对象，则可以手动添加扫描的包。 使用@ComponentScan(&quot;包路径&quot;)。注意是添加，不是更新 解决上面的错误示范： 12345@ComponentScan(&quot;com.cdfy&quot;)@SpringBootApplicationpublic class testApplication &#123;//1.创建log日志 private static final Logger LOG = LoggerFactory.getLogger(testApplication.class);","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"}]},{"title":"volatile原理","slug":"volatile原理","date":"2025-01-18T13:39:56.000Z","updated":"2025-01-19T10:00:07.450Z","comments":true,"path":"posts/volatile原理.html","permalink":"https://www.cdfy.top/posts/volatile%E5%8E%9F%E7%90%86.html","excerpt":"","text":"volatile可以解决可见性和有序性问题 volatile不能保证原子性问题 vloatile可以保证可见性 volatile可以防止指令重排序操作 为什么volatile不能保证原子性 比如一个变量i被volatile修饰，两个线程都对这个变量进行修改，都对其进行i操作，i可以分为三步：先获取到变量i的值，其次对i的值+1，最后将新值写到缓存中。线程A首先得到变量i的值100，还没来得及修改就阻塞了，这时线程B也得到了i，并且做完了i++，然后写回到主内存。由于volatile主内存这时候的值是101。但是线程A已经读到了i的值100，也就是说这个原子操作已经结束了，所以这个可见性来的有点晚，所以线程A做完操作后刷新到主内存，i的值在主内存还是10 volatile内存可见性实现原理 volatile 内存可见性主要通过 lock 前缀指令实现的，它会锁定当前内存区域的缓存（缓存行），并且立即将当前缓存行数据写入主内存（耗时非常短），回写主内存的时候会通过 MESI 协议使其他线程缓存了该变量的地址失效，从而导致其他线程需要重新去主内存中重新读取数据到其工作线程中 什么 MESI 协议？ MESI 协议，全称为 Modified, Exclusive, Shared, Invalid，是一种高速缓存一致性协议。它是为了解决多处理器（CPU）在并发环境下，多个 CPU 缓存不一致问题而提出的 MESI 协议定义了高速缓存中数据的四种状态： Modified（M）：表示缓存行已经被修改，但还没有被写回主存储器。在这种状态下，只有一个 CPU 能独占这个修改状态 Exclusive（E）：表示缓存行与主存储器相同，并且是主存储器的唯一拷贝。这种状态下，只有一个 CPU 能独占这个状态 Shared（S）：表示此高速缓存行可能存储在计算机的其他高速缓存中，并且与主存储器匹配。在这种状态下，各个 CPU 可以并发的对这个数据进行读取，但都不能进行写操作 Invalid（I）：表示此缓存行无效或已过期，不能使用 MESI 协议的主要用途是确保在多个 CPU 共享内存时，各个 CPU 的缓存数据能够保持一致性。当某个 CPU 对共享数据进行修改时，它会将这个数据的状态从 S（共享）或 E（独占）状态转变为 M（修改）状态，并等待适当的时机将这个修改写回主存储器。同时，它会向其他 CPU 广播一个“无效消息”，使得其他 CPU 将自己缓存中对应的数据状态转变为I（无效）状态，从而在下次访问这个数据时能够从主存储器或其他 CPU 的缓存中重新获取正确的数据 volatile有序性实现原理 volatile 的有序性是通过插入内存屏障（Memory Barrier），在内存屏障前后禁止重排序优化，以此实现有序性的 什么是内存屏障？ 内存屏障（Memory Barrier 或 Memory Fence）是一种硬件级别的同步操作，它强制处理器按照特定顺序执行内存访问操作，确保内存操作的顺序性，阻止编译器和 CPU 对内存操作进行不必要的重排序。内存屏障可以确保跨越屏障的读写操作不会交叉进行，以此维持程序的内存一致性模型 在 Java 内存模型（JMM）中，volatile 关键字用于修饰变量时，能够保证该变量的可见性和有序性。关于有序性，volatile 通过内存屏障的插入来实现： 写内存屏障（Store Barrier / Write Barrier）： 当线程写入 volatile 变量时，JMM 会在写操作前插入 StoreStore 屏障，确保在这次写操作之前的所有普通写操作刷新到主内存中，接着在写操作后插入 StoreLoad 屏障，强制所有后来的读写操作都在此次写操作完成之后执行，这就确保了其他线程能立即看到volatile变量的最新值 读内存屏障（Load Barrier / Read Barrier）： 当线程读取 volatile 变量时，JMM 会在读操作前插入 LoadLoad 屏障，确保在此次读操作之前的所有读操作都是从本地内存中读到了。而在读操作后插入 LoadStore 屏障，防止在此次读操作之后的写操作被重排序到读操作之前，这样就确保了对 volatile 变量的读取总是能看到之前对同一变量或其他相关变量的写入结果","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"项目中你是怎么排查哪里出错了，比如是线程池的问题还是MySQL连接池的问题","slug":"项目中你是怎么排查哪里出错了，比如是线程池的问题还是MySQL连接池的问题","date":"2025-01-18T13:26:34.000Z","updated":"2025-01-18T13:54:31.235Z","comments":true,"path":"posts/项目中你是怎么排查哪里出错了，比如是线程池的问题还是MySQL连接池的问题.html","permalink":"https://www.cdfy.top/posts/%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%A0%E6%98%AF%E6%80%8E%E4%B9%88%E6%8E%92%E6%9F%A5%E5%93%AA%E9%87%8C%E5%87%BA%E9%94%99%E4%BA%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%98%AF%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%98%E6%98%AFMySQL%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E9%97%AE%E9%A2%98.html","excerpt":"","text":"首先查看项目的整体日志，确定是否有明显的异常堆栈信息指向某个特定模块（如线程池相关操作或者数据库操作） 例如，如果看到大量关于获取数据库连接超时的异常信息，很可能是MySQL连接池的问题；如果有大量关于任务提交失败或者线程阻塞的异常信息，则可能是线程池的问题 查看系统监控指标。如果是线程池问题，可以关注CPU使用率、线程数等指标。比如当线程池中线程数达到最大值并且有大量任务在等待执行时，CPU使用率可能并不高但响应时间变长，这表明线程池可能配置不合理或者存在死锁等问题。对于MySQL连接池，要关注数据库连接数、慢查询数量等指标。如果连接数接近最大连接数且有大量的慢查询，那么很可能是连接池配置不当或者数据库性能存在问题 如果初步判断是线程池问题，可以通过分析线程池的任务队列长度、活跃线程数等参数进一步确认。例如，在Java中可以通过查看ThreadPoolExecutor的相关方法获取这些信息。如果是MySQL连接池问题，检查连接池的配置参数是否合理，如最大连接数、最小空闲连接数等，并且查看是否存在未关闭的数据库连接导致连接泄漏的情况 除了上述提到的日志和监控指标外，还可以使用调试工具来排查问题。例如，在Java开发中，可以使用JProfiler等工具来分析线程的状态、堆栈信息等，帮助定位线程池中的死锁或者其他线程相关的问题。对于MySQL连接池问题，可以使用MySQL自带的一些诊断命令或者第三方工具来查看当前连接的状态、查询执行计划等信息 在分布式系统中，由于涉及多个服务之间的交互，问题排查更加复杂。此时还需要考虑服务之间的调用链路、网络延迟等因素对线程池和数据库连接池的影响","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Java线程安全问题","slug":"Java线程安全问题","date":"2025-01-18T13:11:01.000Z","updated":"2025-01-18T13:32:33.271Z","comments":true,"path":"posts/Java线程安全问题.html","permalink":"https://www.cdfy.top/posts/Java%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98.html","excerpt":"","text":"Java线程安全性问题 原子性：一个或多个线程操作 CPU 执行的过程中被中断，互斥性称为操作的原子性 可见性：一个线程对共享变量的修改，其他线程不能立刻看到。要保证一个线程对主内存的修改可以及时的被其他线程观察到 有序性：程序执行的顺序没有按照代码的先后顺序执行 原子性安全 JDK 里面提供了很多 atomic 类，比如 AtomicInteger、AtomicLong、AtomicBoolean 等等，这些类本身可以通过 CAS 来保证操作的原子性。另外 Java 也提供了各种锁机制，来保证锁内的代码块在同一时刻只能有一个线程执行，比如使用 synchronized 加锁，保证一个线程在对资源进行读、写时，其他线程不可对此资源进行操作，从而保证了线程的安全性 可见性安全 同样可以通过 synchronized 关键字加锁来解决，与此同时，java 还提供了 volatile 关键字，要优于 synchronized 的性能，同样可以保证修改对其他线程的可见性。volatile 一般用于对变量的写操作不依赖于当前值的场景中，比如状态标记量等 有序性问题 主要来自指令重排序带来的有序性问题。可以通过 synchronized 关键字定义同步代码块或者同步方法保障有序性，另外也可以通过 Lock 接口来保障有序性 有序性-happens-before原则 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于写在后面的操作(虽然虚拟机可能进行了重排序，但是程序执行的顺序看起来是按照在代码书写的样式执行的。只会对数据不存在依赖性的指令进行重排序)；这条规则只能保障单线程中保持正 确性，而无法在多线程中保持正确性 锁定规则：一个unlock操作先行发生于后面对同一个资源lock的操作(对一段代码或一个变量，只有锁定了资源的锁先执行了unlock操作，下一个线程才有可能执行lock操作。这里需要注意，当一个锁再一次进入同一个锁的时，这时候是否先执行unlock还是怎样？？不会，这是可重入锁，不会进行释放，而是计数量会-1) volatile变量规则：对一个变量的写操作先行发生于后面这个变量的读操作 传递规则：如果操作A先发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作 线程终结规则: 线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回手段检测到线程已经终止执行","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"如何排查Java项目中事务出现异常的情况","slug":"如何排查Java项目中事务出现异常的情况","date":"2025-01-18T13:07:46.000Z","updated":"2025-01-18T13:54:36.517Z","comments":true,"path":"posts/如何排查Java项目中事务出现异常的情况.html","permalink":"https://www.cdfy.top/posts/%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5Java%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BA%8B%E5%8A%A1%E5%87%BA%E7%8E%B0%E5%BC%82%E5%B8%B8%E7%9A%84%E6%83%85%E5%86%B5.html","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL事务","slug":"MySQL事务","date":"2025-01-18T12:54:35.000Z","updated":"2025-01-18T13:03:43.827Z","comments":true,"path":"posts/MySQL事务.html","permalink":"https://www.cdfy.top/posts/MySQL%E4%BA%8B%E5%8A%A1.html","excerpt":"","text":"MySQL事务的特性 MySQL事务有四大特性 ACID: 原子性、一致性、隔离性、持久性 原子性：一个事务中的操作要么全部完成，要么全部不完成，由undo log日志保证 一致性：事务完成后，数据库的状态必须保持一致。通过持久性+原子性+隔离性来保证 隔离性：一个事务不能被另外一个事务干扰，可以防止多个事务并发读写同一个数据库，导致数据不一致的情况发生，由MVCC和锁保证。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账 持久性：事务完成后对数据库的修改是永久的，不会因为系统故障而丢失，由redo log日志保证 MySQL事务隔离有哪些，解决了什么问题 四个事务隔离级别： 读未提交：一个事务还没提交时，它做的变更可以被其他事务看到 读提交：一个事务提交后，它做的变更才可以被其他事务看到 可重复读：一个事务执行过程看到的数据，一直跟这个事务启动时看到的数据是一样的，也是MySQL InnoDB默认的事务隔离级别 串行化：会对记录加读写锁，在多个事务对这条记录读写操作时，如果发生了读写冲突，后访问的事务必须等待前一个事务提交才能执行 有这么一些问题： 脏读：一个事务读取了另一个事务还未提交的数据，如果另一个事务回滚， 则读取的数据是无效的。可能导致数据的不一致性 不可重复读：一个事务多次读取同一条记录，但是在此期间另一个事务修改了该记录，导致前后读取数据的不一致性。可能导致数据的不一致性 幻读：一个事务多次执行同一次查询，但是在此期间另一个事务插入了符号该条件的新纪录，就会导致前后的查询结果不一致。可能导致数据的不完整性 事务隔离解决： 读未提交什么都没有解决 读提交解决了脏读 可重复读解决了脏读和不可重复读，但是幻读很大情况下可以避免，没有完全避免 串行化解决了所有问题，但是事务的并发性能最差 这四种隔离级别具体是如何实现的 对于读未提交，直接读取到最新的数据就可以 对于读提交和可重复读，都是通过MVCC来实现，它们的区别在于创建Read View的时机不同，读提交在事务开启后，每次执行select都会生成一个新的Read View，所以每次select都可以看到其他事务最近提交的数据。可重复读在事务开启后，执行第一条select时生成一个Read View，然后整个事务都在使用这个Reda View，所以整个事务看到的数据是保持不变的 串行化通过加读写锁的方式来避免读写冲突 串行化隔离级别怎么实现的 串行化隔离级别对所有的SQL都会加锁，包括普通的select查询，都会加S型的next-key锁。其他事务就没法对这些已加锁的记录进行增删改操作，从而避免了脏读、不可重复读、幻读问题。当然性能也是隔离级别最差的 MySQL默认隔离级别是什么，怎么实现的 默认隔离级别是可重复度，通过MVCC实现的 MVCC: MVCC是多版本并发控制，是通过记录历史版本数据，解决读写并发冲突问题，避免了读写时加锁，提高了事务的并发性能。 MySQL将历史数据存储在undo log日志中，结构逻辑上类似链表，数据行有两个隐藏列，一个是事务ID，一个是指向undo log的指针 事务开启后，执行第一条select语句的时候，会创建Read View，记录开启事务时当前未提交的事务，通过与历史数据的事务ID比较，就可以根据可见性规则判断这条记录是否可见。如果可见就返回给客户端，否则根据undo log版本链查找到第一个可见的数据。 需要展开说说可见性规则吗？ MVCC如何判断行记录对一个事务可见 每一条记录都有两个隐藏列，一个是事务ID，另一个是指向历史数据undo log的指针。Reda View有四个字段，分别是创建Read View的事务ID、活跃事务ID的列表、活跃事务ID列表中的最小ID、下一个事务ID（活跃事务ID列表中的最大值+1） 有以下判断规则： 如果记录中的事务ID小于活跃事务ID列表中的最小ID，说明在创建事务之前就已经生成好了，对该事务可见 如果记录中的事务ID大于等于下一个事务ID，说明该记录是在创建Read View后才生成的，该记录对该事务不可见 如果记录中的事务ID在活跃事务ID列表的最小ID和下一个事务ID之前，要两种情况： 如果记录的事务ID在活跃事务ID列表中，说明修改该记录的事务还没提交，因此不可见 如果记录的事务ID不在活跃事务ID列表中，说明修改该记录的事务已经提交，因此可见 为什么一般用读提交隔离级别 读提交并发性能更好，读提交没有间隙锁，只有记录锁，发生死锁的概率更低。然后互联网业务对于幻读和不可重复读的问题都是可以接受的，所以为了降低死锁的概率，提高事务的并发性能，都会选择读提交隔离级别 可重复读如何解决不可重复读问题 MySQL提供了两种查询方式。一种是快照读，就是普通的select语句；另一种是当前读，比如select for update语句。不同的查询方式，解决不可重读问题的方式不一样 针对快照读，通过MVCC机制来实现，在可重复读隔离级别下，第一次select查询的时候，会生成一个Read View。第二次查询的时候，会复用这个Read View，根据可见性规则，这样前后两次查询的记录是一样的，就不会发生不可重复读问题 针对当前读，是靠行级锁中的记录锁来实现，在可重复读隔离级别下，第一次select for update语句查询的时候，会对记录加上next-key锁，这个锁包含记录锁，这时候如果其他事务加了锁的记录，都会被阻塞住，也不会发生不可重复读的问题 可重复读解决了什么问题，有没有解决幻读 可重复读解决了脏读、不可重复读的问题。幻读在很大程度上避免了，但没有完全解决，需要我展开说一下吗 可重复读为什么不能解决幻读，什么情况下还是会发生幻读 在可重复读隔离场景下，先快照读再当前读会出现幻读的情况 比如事务A通过快照读的方式查询id = 5的记录，此时数据库没有记录，然后事务B向这张表中插入了一条id = 5的记录。接着事务A对这条记录做了更新操作，在这个时刻，这条记录隐藏列的事务ID变成了事务A的事务ID，这时事务A再去读这条记录就会被看见。于是发生了幻读 还有一种情况，事务A首先快照读查询id &gt; 100的记录，假设这时候有一条记录，然后事务B又插入了一条id = 200的记录，然后事务A使用当前读查询id &gt; 100的记录，这时候就查询到了两条记录，出现了幻读。 当前，幻读是可以避免的。就是在开启事务后，马上实现select for update语句，因为他会对记录加上next-key锁，这样就可以避免其他事务插入记录，避免了幻读 可重复度隔离级别完全解决了不可重复读问题了吗 并没有，如果前后两次查询都是快照读的话，不会产生不可重复读的问题。但是如果第一次查询是快照读，第二次查询是当前读，就有可能出现不可重复读问题 一个事务有特别多的SQL的弊端（长事务的影响） 锁是事务提交的时候才释放，那么长事务会导致锁持久的时间变长，容量造成死锁和锁超时的问题 执行事务中每条增删查改语句会产生undo log，那么长事务会导致undo log堆积，占用存储空间，也会导致回滚的时间过长 长事务执行时间长，容易造成主从延迟，如果一个主库上的语句执行10分钟，那么事务就会导致从库延迟10分钟 长事务中，连续会被持续打开，会占用数据库连接池的资源，可能导致数据库连接池被占满","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL存储引擎","slug":"MySQL存储引擎","date":"2025-01-18T12:34:58.000Z","updated":"2025-01-18T12:43:35.001Z","comments":true,"path":"posts/MySQL存储引擎.html","permalink":"https://www.cdfy.top/posts/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E.html","excerpt":"","text":"说一说执行一条查询SQL查询语句的过程 会经过连接器、查询缓存、解析器、优化器、执行器、存储引擎这些模块 连接器负责建立连接、校验用户身份、接受客户端的SQL语句 在查询缓存中，如果命中缓存，直接返回 分析器对SQL语句进行语法分析、词法分析 优化器会基于查询成本的考虑，对每个索引进行成本分析，从中选择查询成本最小的执行计划。同时缓存记录给查询缓存 执行器会根据执行计划来执行查询语句，从存储引擎中读取记录，返回给客户端 MySQL存储引擎有哪些 有InnoDB、MyISAM、Memory InnoDB是MySQL默认的存储引擎，支持事务、行级锁，具有事务提交、回滚和崩溃恢复功能 MyISAM和InnoDB有什么区别 从数据存储、B+树结构、锁粒度、事务这四个角度来分析 数据存储：InnoDB存储数据采取的是索引组织表，在索引组织表中，索引即数据，数据即索引，因此表数据和索引数据在同一个文件中。MyISAN存储数据采用的是堆表，数据和索引分开存储，因此表数据和索引数据分别放在不同的两个文件中 索引组织表有两个优势：1. 在索引组织表中，索引和数据在同一个B+树，相比非聚簇索引每次查询都需要回表，因此聚簇索引中获取数据比非聚簇索引快。2. 在索引组织表中，如果记录的非索引记录发生了变化，则其他索引无须进行维护。而当堆表中的位置发生了变化，那么所有的索引地址都需要更新 B+树结构：InnoDB引擎B+树叶子节点存储索引+数据，MyISAM引擎叶子节点存储索引+数据地址 锁粒度：InnoDB引擎支持行级锁，MyISAM不支持行级锁，支持表锁。因为MyISAM引擎不支持聚簇索引，所以无法实现行锁，出现多条线程同时读写数据时，只能锁住整张表。而InnoDB由于支持聚簇索引，每个索引最终都会指向聚簇索引中的索引键，因此出现并发事务时，InnoDB只需要锁住聚簇索引的数据即可，而不需要锁住整张表，因此并发性能更高 事务：InnoDB支持事务，MyISAM不支持事务。使用InnoDB存储引擎的表，可以借助undo-log日志实现事务机制，支持多条SQL组成一个事务，可以保证发生异常的情况下，组成这个事务的SQL到底回滚还是提交。而MyISAM并未设计类似的技术，在启动时不会在内存中构建undo_log_buffer缓冲区，磁盘中也没有相应的日志文件，因此MyISAM并不支持事务机制 MySQL为什么选择InnoDB作为默认引擎 最主要原因是InnoDB支持事务，其他引擎不支持 事务支持：InnoDB支持事务，保证了ACID（原子性、一致性、隔离性、持久性），MyISAM是不支持事务的 并发性能：InnoDB因为支持聚簇索引，可以使用行级锁，在并发条件下只需要对行数据加锁，不需要对整张表加锁。而MyISAM只能对整张表加锁，并发效率低 崩溃恢复：InnoDB通过redolog日志实现了崩溃恢复，保证了数据了持久性和一致性。MyISAM不支持崩溃恢复 用count(*)哪个存储引擎会更快 在MyISAM中，每张数据表都有一个meta信息维护了row_count的值，由表级锁一致性，直接读取row_count的值就是count函数的执行结构。 因此如果查询语句中没有where查询条件，MyISAM更快。如果有where查询条件性能都差不多，都需要一行一行遍历地统计 NULL值是如何存储的？ MySQL行格式会用NULL值列表来标记值为NULL的列，每个列对应一个二进制位，如果列的值为NULL，就会标记二进制位为1，否则是0。所以NULL值并不会存储在数据格式中的真实数据部分 char和varchar有什么区别？哪个性能更好 区别: char是固定长度的字符串类型，它是数据库中占用固定的存储空间，无论存储的大小是多少，都会占用定义时的固定长度。如果存储的字符串长度小于定义的字符串长度，则会用空格填充。比如定义一个char（10）的字符串，但是只用了5字节，会自动填充5字节 varchar是变长长度的字符串类型，实际存储时占用实际字符串长度的大小。但是还需要额外1-2字节存储可变长字符串长度的空间 性能： 站在CPU角度来看，理论上CHAR比VARCHAR快，因为VACHAR有一个长度标识参与运算 但是在实际中，Innodb buffer pool 小于表大小时，磁盘读写成为了性能的关键因素。而VARCHAR更短，性能反而比CHAR高。但是当Innodb buffer pool足够大时，CHAR和VARCHAR性能差异不大 一个字段是VARCHAR(10)，但它实际上只有6个字节，那他在内存空间的大小是多少？在文件中的存储空间大小是多少？ varchar是可变长字符串长度，保存到文件中，只会存储实际使用的字符串大小。但是内存是按varchar最大值来固定分配大小。 因此在内存中会占用10字节。在文件中占用6字节，并且都会用1-2字节存储可变长字符串长度的空间 varchar可变长字符串长度的空间大小是1字节还是2字节取决什么？ 如果硬件内存特别大，MySQL缓存是否可以替代Redis 不能 bufferpool结构，日志技术，事务并发，存储模型等等模块，都是面向磁盘页而设计的，因此其首要目标不是减少内存代价，而是I/O代价。 其次，Mysql查询走的是B+树索引，时间复杂度是O（logN），Redis有Hash数据对象的时候，查询复杂度是O（1） 最后，MySQL在更新数据的时候，为了保证事务的隔离性，需要加锁，而Redis更新操作不需要加锁。还有MySQL为了保证数据的持久性，还需要刷盘redolog和binlog日志，Redis可以选择不持久化。因此即使buffer pool无限大，MySQL缓存的性能还是没有Redis好","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL索引应用","slug":"MySQL索引应用","date":"2025-01-18T12:13:43.000Z","updated":"2025-01-18T12:20:37.124Z","comments":true,"path":"posts/MySQL索引应用.html","permalink":"https://www.cdfy.top/posts/MySQL%E7%B4%A2%E5%BC%95%E5%BA%94%E7%94%A8.html","excerpt":"","text":"MySQL有哪些索引（按字段特性分类） MySQL有主键索引、唯一索引、普通索引、前缀索引、联合索引（tip：看建立在什么字段上面就是什么索引） 主键索引：就是建立在主键上的索引，通常与表一起创建，一张表最多只有一个主键索引，索引列的值不能为NULL 唯一索引：建立在UNIQUE字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值 普通索引：建立在普通字段上的索引，既不要求字段为主键，也不要求字段为UNIQUE 前缀索引：对字符类型字段的前几个字符建立的索引，而不是整个字段，目的是减少索引占用的空间，提升查询效率 联合索引：将多个字段组合成一个索引 MySQL主键是聚簇索引吗 是的。聚簇索引就是在定义索引时，将数据和索引放在同一课B+树上 每张表只有一个聚簇索引，会根据不同的情况选择不同的列作为索引 如果定义了主键，默认使用主键作为聚簇索引 如果没有主键，会选择第一个不包含NULL的唯一列作为聚簇索引的索引键 如果上述都没有，InnoDB将自动生成一个隐式自增id（row_id）作为聚簇索引的索引键 主键索引为什么不推荐有业务含义 首先业务具有变动的可能性，可能导致主键字段发生了变动，然而维护主键是成本很高的一件事 其次业务含义的主键可能不是顺序递增的，有可能发生页分裂的问题，从而影响性能 主键用自增还是UUID 用自增ID比较好，因为UUID是随机值，在数据插入的过程中，会导致页分裂的问题，性能下降 其次自增ID在分库分表的环境下不适用，因为没法保证全局唯一，需要使用雪花算法等来作为主键 普通索引和唯一索引有什么区别，哪个更好 普通索引的值可以是任意的，唯一索引的值必须是唯一的。 我认为普通索引性能更好，因为普通索引在更新的时候，如果更新的数据页不在内存的话，可以直接把更新操作缓存在change buffer中，更新操作就结束了 然而唯一索引因为需要有唯一性约束，如果更新的页不在内存中的话，需要从磁盘读取对应的数据页到内存中，判断是否发生唯一性冲突，会涉及到磁盘IO的访问，性能不如普通索引 介绍一下什么是外键约束 外键就是从表中用来引用主表中数据的那个字段，外键约束确保了数据的引用完整性，也就是从表中的外键必须存在于主表中的主键。如果发现要删除的主键记录，正在被从表的外键引用，就会发生外键约束错误，从而保证了两个表的数据一致性 外键有什么优劣势 优点： 一致性：如果一个表的键被另外一个表引用，外键可以保证这个字段一定存在于那个表中，从而保证了数据的一致性 完整性：外键可以防止在引用表中删除正在被其他表引用的记录，从而保证了数据的完整性 劣势： 性能问题：数据库的每次操作都要检查外键约束，硬性保证数据的一致性，会造成性能下降 锁竞争问题：在使用外键的情况下，每次修改数据库都要检查外键约束，这需要额外获取读锁，在高并发情况下很容易造成死锁 无法使用分库分表场景：因为外键难以跨越不同的库来建立关系，然而现在大部分项目为了应付高并发都会采用分库分表，因此外键也不适用了 为什么要建立索引 加快查询速度，在不加索引的情况下查询一条记录是O（n），有索引的情况下查询复杂度是O（logn） 避免外部排序和使用临时表等问题 在表数据量大的时候，为索引分配就不是按页，而是按区。每个区的大小是1MB,可以放下64个页，这样使得链表中相邻的页物理位置也相邻。可以将随机IO变成顺序IO 一般选择什么样的字段来建立索引 使用于索引的场景： 字段具有唯一性的建立唯一性索引 经常用于WHERE查询条件的字段，为了提高查询速度，可以建立索引 经常用于GROUP BY 和 ORDER BY的字段建立索引，这样查询的时候就不用再做一次排序了，因为索引在B+树中就是排序好的 不适合索引的场景： WHERE、GROUP BY、ORDER BY里用不到的字段，不需要建立索引 字段中存在大量重复数据的不需要建立索引，比如性别字段。就算建立了索引每次也可能搜索到一半的数据，在这种情况下，MySQL的优化器发现某个值在表中出现比例较高的时候，会忽略索引，进行全表扫描，这时候建立索引就没起到作用，反而还占用空间 经常更新的字段不需要建立索引，经常维护索引会影响数据库性能 索引越多越好吗 不是 因为索引需要占用空间，当索引过多的时候，占用空间很大 其次索引过多数据库维护成本过高，每次对表增删查改时，都需要维护B+树的各个索引 什么时候不用索引最好 建立了索引，空间上索引需要占用磁盘空间。其次时间上每次对数据库表增删查改时，需要维护B+树的各个索引，需要性能开销 首先如果一张表写多读少的情况下，不建议建立索引，因为维护索引的开销可能超过索引性能的提升 其次当一张表中某个列的值高度重复，那么建立了索引也没用，优化器会忽略索引，进行全表扫描，这样不仅占用了存储空间，还影响了增删查改的效率 字段为什么要定义成NOT NULL 如果查询的列包含NULL，对MySQL优化器来说，可能成本过高而使用全盘扫描 如果某列存在NULL的情况，可能导致count（）函数不准确，因为count（）函数不会统计值为NULL的列 NULL虽然是没有意义的值，但会占用物理空间，行格式中会至少用1字节来存储NULL值列表 索引怎么优化 对于只需要查询几个字段的SQL来说，对这些字段建立联合索引，这样查询方式就变成了覆盖索引，避免了回表，减少了大量的I/O操作 主键索引最好是递增的值，因为随机值，在数据插入的情况下可能会造成页分裂，而页分裂会产生内存碎片，导致索引结构不紧凑，影响查询效率 避免写出发生索引失效的SQL，比如不要对索引进行计算、函数、类型转换操作，联合索引要遵循最左匹配原则 对于一些大字符串的索引，我们可以用前缀索引只对索引列的前缀部分建立索引，节省索引的空间，提高查询效率 建立了索引，查询的时候一定用得到索引吗 索引失效：对索引字段进行左模糊匹配，对索引进行计算、函数、类型转换操作，联合索引不遵循最左匹配，就会造成索引失效，查询不会走索引 优化器成本：在使用二级索引的时候，优化器会计算回表的成本和全盘扫描的成本，如果回表的代价太大，优化器会选择走全盘扫描 一个VARCHAR类型的字段time，WHERE time = 20230922 会命中索引吗 不会，因为MySQL在遇到字符串类型和数字类型比较的时候，会自动把字符串转换成数字，这个过程会执行CAST函数 于是在执行过程中会索引字段使用了函数，会导致索引失效 但如果反过来，where id = ‘1’， 如果id是整数不会导致索引失效，因为字符串对象是‘1’，函数发生在它的身上，而不是索引身上 MySQL最新版本解决了索引失效的问题了吗 MySQL8.0新特性：函数索引和索引跳跃扫描机制 函数索引：可以针对函数计算后的值建立索引，可以解决对索引使用函数导致索引失效的问题 索引跳跃扫描：在使用联合索引扫描的场景下，即使不满足最左匹配原则，在部分场景下依然会使用联合索引 索引跳跃扫描的条件： 查询只能涉及一张表，多表关联不能使用该特性 查询SQL不能涉及GROUY BY 和 DISTINCT子句 查询字段必须是索引中的字段（不能发生回表） 满足一定的组合索引形式，比如对于联合索引（a，b，c）来说，a，c可以为空，但是b不能为空 什么是最左匹配原则 假设有一个联合索引（a，b，c），它的存储顺序是先按a排序，a相同的情况下再按b排序，b相同的情况下再按c排序。最左匹配原则： 从联合索引最左边的索引列开始匹配查询条件，然后依次从左到右的顺序匹配，如果查询条件右边没有用到某个列，那么该列右边的所有列都无法走索引 当查询条件中使用了某个列，但是该列的值包含范围查询，范围查询的字段可以走联合索引，但是该字段后面的所有字段不能走索引 建立联合索引需要注意什么 把区分度大的字段放在联合索引最左侧，有助于提高索引的过滤效果，比如UUID这类字段放最左边 区分度小的放在联合索引最左侧，优化器可能根据成本考虑会选择全盘扫描，不走索引 索引下推是什么 索引下推能够减少二级索引在查询时的回表操作，将Server层负责的事情交给存储引擎层去处理 比如联合索引（a，b，c），查询条件为a = ？和 c = ？ 时，由于最左匹配原则，c无法走索引。在没有索引下推之前，查询语句走二级索引的时候，会回表读取c的值，然后在server层进行过滤。如果有索引下推，由于二级索引中存在c，那么将server层的过滤交给存储引擎层，在二级索引中将c的值过滤，减少了回表的次数 查询条件 where a &gt; 100 and b = 100 and c = 100 order by d 怎么建立索引 建立（b，c，d，a）的联合索引，这样b，c字段都会走索引，然后d能利用索引的有序性，避免了filesort。order by d 相当于范围查询，最后的字段a无法用到索引，但是可以通过索引下推，避免了回表 select id, name from XX where age &gt; 10 and name like 'xx%', 有联合索引(name，age)，说一下查询过程 tip： 先说哪些能走索引，哪些不能走索引 再说哪个字段可以索引下推 最后说查询需不需要回表（发不发生索引覆盖） 联合索引先走name，再age。结构上是name先排序，然后age排序。查询的过程先匹配name，由于name是右模糊匹配，并不会发生索引失效，但是在右模糊匹配后（相当于范围查询），age并不是有序，因此age无法走索引 但是age在二级索引中，因此age可以索引下推 最后，id由于是主键，因此id和name都可以在二级索引中找到，会发生索引覆盖，不需要回表 where id not in （X, X, X）会走索引吗 要看查询成本，如果走某个索引花费的随机IO从聚簇索引查（顺序IO）的成本还要高，就不会走索引 比如，num字段（非唯一二级索引）只包含3个值，1，2，3。 然而1，2各有100W行，3只有几行，那么not in （1， 2）会走索引，not in （3）不会走索引 如果查询条件包括索引列和非索引列，查询过程是怎么样的 查询过程先根据二级索引拿到主键id，再回表过滤非索引列，查询过程会查两个B+树，涉及回表 比如select a from XX where a = ? and d = ? ，a是索引，d不是索引，会先按索引查询，再回表过滤d","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL索引结构","slug":"MySQL索引结构","date":"2025-01-18T11:58:48.000Z","updated":"2025-01-18T12:12:12.871Z","comments":true,"path":"posts/MySQL索引结构.html","permalink":"https://www.cdfy.top/posts/MySQL%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84.html","excerpt":"","text":"MySQL有哪些索引结构（按数据结构分类） B+树结构：B+树索引是一种平衡树数据结构，它将数据按照索引键值有序地存储在叶子节点上，非叶子节点只存储索引键值的范围和指向下一层结点的指针。因此查找、排序的效率很高。保存千万级别的数据，B+树一般只需要3-4层，也就是查询一条记录，只需要3-4次的磁盘IO 哈希索引：通过哈希表实现，查询时间复杂度是O（1），但不支持排序，模糊查询，范围查询等 全文索引：用于全文搜索的索引技术，可以对文本内容进行搜索，支持关键词的模糊匹配和搜索 InnoDB存储引擎支持的索引数据结构 支持B+树数据结构： 数据组织索引：B+树非叶子节点存储索引范围和指向下一层的节点，叶子节点存储索引键值和行数据，因此B+树索引属于聚簇索引 叶子节点链表：所有叶子节点通过指针相连，形成一个双向链表，支持快速的顺序访问和范围查询 平衡树结构：所有叶子节点在同一层上，数的高度平衡，即使是千万级数据，也只有3-4层，查询、排序的效率高 从数据页角度看B+树 InnoDB 的数据是按「数据页」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过双向链表的形式组织起来，物理上不连续，但是逻辑上连续 数据页内包含用户记录，每个记录之间用单向链表的方式组织起来。为了加快在数据页内高效查询记录，设计了一个页目录，页目录存储各个槽（分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率 为了高效查询数据页，InnoDB采用B+树作为索引，每个节点都是一个数据页 如果叶子节点存储的是实际数据的就是聚簇索引，一个表只能有一个聚簇索引；如果叶子节点存储的不是实际数据，而是主键值则就是二级索引，一个表中可以有多个二级索引 在使用二级索引进行查找数据时，如果查询的数据能在二级索引找到，那么就是「索引覆盖」操作，如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行，这个过程就叫作「回表」 B+树的特性是什么 数据组织索引：B+树非叶子节点存储索引范围和指向下一层的节点，叶子节点存储索引键值和行数据，因此B+树索引属于聚簇索引 叶子节点链表：所有叶子节点通过指针相连，形成一个双向链表，支持快速的顺序访问和范围查询 平衡树结构：所有叶子节点在同一层上，数的高度平衡，即使是千万级数据，也只有3-4层，查询、排序的效率高 B+树和B树的区别是什么 数据存储：B+树叶子节点才会存储数据，而B树非叶子节点也存储数据。因此存储数据量相同的情况下，B+树非叶子节点存储的索引数量大于B树，B+树比B树更矮胖，查询效率更高 范围查询：B+树叶子节点构成了双向链表，因此范围查询更有帮助。B树只能通过中序遍历来范围查询，需要更多的磁盘IO，范围查询效率不如B+树 查询效率：B树的优势是查找到的数据恰好在一个非叶子节点时，由于该节点也包含数据，可以直接返回，最快在O（1）就可以查到。而B+树相对来说更稳定，每次查询都是相同的IO延迟 MySQL为什么使用B+树 B+树是多叉树，平衡树、红黑树是二叉树，高度更高，磁盘IO更大，查询速度更慢 相比跳表,跳表在极端情况下会变成链表，平衡性差，而数据库需要一个可预期的查询时间，并且跳表需要更多的内存 B树的数据存储在全部节点中，由于存储在非叶子节点，导致内存可能放不下，如果内存放不下，就意味着查询非叶子节点的时候就需要磁盘IO。此外B+树叶子节点构成了双向链表，对范围查询很友好 为什么索引用B+树而不用红黑树 B+树是多叉树，红黑树是二叉树，高度更低，在查询大量数据时候，磁盘IO更少 B+树叶子节点采用了双向链表结构，范围查询很方便 为什么索引用B+树而不用B树 磁盘读写代价：B+树叶子节点才会存储数据，而B树非叶子节点也存储数据。因此存储数据量相同的情况下，B+树非叶子节点存储的索引数量大于B树，B+树比B树更矮胖，查询效率更高 范围查询：B+树叶子节点构成了双向链表，因此范围查询更有帮助。B树只能通过中序遍历来范围查询，需要更多的磁盘IO，范围查询效率不如B+树 B+树增删查改效率更加稳定：B+树有大量冗余节点（所有非叶子节点都是冗余索引），比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化,比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化。除此之外，B+树每次查找都需要走到最后一层，查询更稳定 为什么索引用B+树而不用哈希表 哈希表的数据是散列分布的，不具备有序性，不能进行范围查找和排序，不支持联合索引最左匹配原则 哈希表存储哈希冲突的问题，哈希冲突严重的情况下会降低查询效率 B+树有什么优点和缺点 优点： 叶子节点链表：所有叶子节点通过指针相连，形成一个双向链表，支持快速的顺序访问和范围查询 平衡树结构：所有叶子节点在同一层上，数的高度平衡，即使是千万级数据，也只有3-4层，查询、排序的效率高 缺点： 产生大量的随机IO：随着数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点物理上不连续，做范围查询时会产生大量随机读IO 聚簇索引和非聚簇索引（也叫二级索引）有什么区别 先说聚簇索引和非聚簇索引叶子节点存放内容的区别，再引出回表查询和覆盖索引查询 聚簇索引叶子节点存放的是主键值和完整的数据 非聚簇索引叶子节点存放的是索引值+主键值 什么是覆盖索引 当查询到的数据能在二级索引的叶子节点查询到，就不用回主键索引查了。这种不需要回表的过程，叫覆盖索引 什么情况下会回表 在使用二级索引进行查询时，如果查询的列，不能在二级索引中全部查询到，就会发生回表。先通过二级索引的值查询到主键索引（即主键id），再通过聚簇索引的值定位到行记录的数据，需要扫描两次B+树。 insert操作对B+树结构的改变是怎么样的 如果我们使用的主键是递增的，每次插入数据只会插入到叶子节点最右边的节点中，如果改页面满了，就会开辟一个新页面，将新数据插入到新页面中。因为每插入一条记录，不需要重新移动数据，因此这种插入方式高效 如果如果我们使用的主键不是递增的，就有可能插入到现有数据页的中间，为了保证B+树的有序性，要移动其他数据满足新数据的插入。如果页面满了，就会发生页分裂，这时候要从一个页面复制数据到另一个页面，目的是保证B+树的有序性，页分裂可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。 假如有一张两千万的数据，B+树的高度是多少？怎么算的？ 具体要看数据库字段多不多，以及字段的类型，假设一行记录是1kb大小，那么2000万的数据表，B+树大概是三层高度。其次MySQL数据页的大小是16KB，去掉一些头信息，大概有15KB可以存储数据 在索引页中，也就是非叶子节点，假设主键id类似是bigint，占8字节，页号固定为4字节，那么索引页的一条数据是12字节。一个索引页可以存储15*1024/12 ≈ 1280个页号 叶子节点存放的是真正的数据行，假设一个记录是1kb，那么一页可以存放15条记录。 由公式，x是1280，y 是 15，Total 是 2KW， 因此z = 3","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"SpringBoot注解","slug":"SpringBoot注解","date":"2025-01-18T09:17:31.000Z","updated":"2025-01-19T13:14:58.783Z","comments":true,"path":"posts/SpringBoot注解.html","permalink":"https://www.cdfy.top/posts/SpringBoot%E6%B3%A8%E8%A7%A3.html","excerpt":"","text":"Bean处理 依赖注入 @Autowired: 用在属性和方法上。依赖注入，把配置好的bean拿来用 @Resource：默认情况下@Resource按照名称注入，如果没有显式声明名称则按照变量名称或者方法中对应的参数名称进行注入 @Qualifier： 标注类被Spring容器管理 @Component：组件，当组件不好归类的时候使用 @Respository：持久层，用于DAO类 @Service：服务层，用于Service类，通常需要注入DAO层 @Controller：MVC控制层Bean，常需要注入Service层 @RestController：继承@Controller注解，用于开发REST服务，直接将返回值当作json格式，通过body来给他返回。在使用 @RestController 注解标记的类中，每个方法的返回值都会以 JSON 或 XML 的形式直接写入 HTTP 响应体中，相当于在每个方法上都添加了 @ResponseBody 注解 @Configuration：声明配置类 声明Bean的生命周期 @Scope：singleton（单例）、prototype（多例， 每次获取Bean的时候会有一个新的实例）、request（每一次HTTP请求都会产生一个新的bean）、session（每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效） HTTP请求 @GetMapping：GET请求，从服务器获取资源 @PostMapping: POST请求，创建资源 PutMapping：PUT请求，更新资源 DeleteMapping：DELETE请求，删除资源 12345678@RestController@RequestMapping(&quot;/api&quot;)public class MyController &#123; @GetMapping(&quot;/hello&quot;) public String hello() &#123; return &quot;Hello, world!&quot;; &#125;&#125; 前后端参数传递 @RequestParam：通过表单获取参数置，用在方法的参数前面，获取请求中表单类型的key=value格式的数据 @PathVariable：路径变量，参数与大括号里的名字一样 @RequestBody：获取请求Body中的数据，用于搭配@PostMaping请求来提交数据 @ResponseBody：表示该方法的返回结果直接写入HTTP response body中，格式为json 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Controller@RequestMapping(&quot;hello&quot;)public class HelloController2 &#123; /** * 接收普通请求参数 * http://localhost:8080/hello/show16?name=linuxsir * url参数中的name必须要和@RequestParam(&quot;name&quot;)一致 * @return */ @RequestMapping(&quot;show16&quot;) public ModelAndView test16(@RequestParam(&quot;name&quot;)String name)&#123; ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello2&quot;); mv.addObject(&quot;msg&quot;, &quot;接收普通的请求参数：&quot; + name); return mv; &#125; /** * 接收普通请求参数,required=false(默认是true) * http://localhost:8080/hello/show17 * url中没有name参数不会报错、有就显示出来 * @return */ @RequestMapping(&quot;show17&quot;) public ModelAndView test17(@RequestParam(value=&quot;name&quot;,required=false)String name)&#123; ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello2&quot;); mv.addObject(&quot;msg&quot;, &quot;接收普通请求参数：&quot; + name); return mv; &#125; /** * 接收普通请求参数 * http://localhost:8080/hello/show18?name=998 显示为998 * http://localhost:8080/hello/show18?name 显示为hello * @return */ @RequestMapping(&quot;show18&quot;) public ModelAndView test18(@RequestParam(value=&quot;name&quot;,required=true,defaultValue=&quot;hello&quot;)String name)&#123; ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;hello2&quot;); mv.addObject(&quot;msg&quot;, &quot;接收普通请求参数：&quot; + name); return mv; &#125;&#125; 读取配置 @PropertySource：指定加载自定义的配置类路径 @Value：直接读取各种配置源的属性名 @Configuration：用于类上，表示配置类并与Bean绑定, @Configuration注解通常与@ComponentScan注解一起使用，用于扫描指定包中的组件 12345678910@PropertySource(&#123;&quot;配置文件路径1&quot;,&quot;配置文件路径2&quot;...&#125;)@Value(&quot;$&#123;配置文件中的key:默认值&#125;&quot;)@Value(&quot;$&#123;配置文件中的key&#125;&quot;)@Configuration@ComponentScan(basePackages = &quot;com.example&quot;)public class AppConfig &#123; // Bean定义&#125; 参数校验 Bean字段验证注解：比如@Email @Valid：用于标注验证对象的级联属性 @Vliddated：标注方法参数需要检查 统一异常处理 ControllerAdvice：定义异常处理类，包括@Component，所以可以被Spring扫描到 ExceptionHandler：声明异常处理方法，表示遇到这个异常，就执行标注的方法 12345678910//@ControllerAdvice 配合 @ExceptionHandler 实现全局异常处理,@ExceptionHandler注解中可以添加参数，参数是某个异常类的class，代表这个方法专门处理该类异常@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(IllegalArgumentException.class) public ModelAndView handleException(IllegalArgumentException e)&#123; ModelAndView modelAndView = new ModelAndView(&quot;error&quot;); modelAndView.addObject(&quot;errorMessage&quot;, &quot;参数不符合规范!&quot;); return modelAndView; &#125;&#125; JPA数据持久化 @Entity：声明数据库实体类。class 名即数据库表中表名，class 字段名即表中的字段名 Table：当实体类与其映射的数据库表名不同名时需要使用 @Table注解说明，该标注与 @Entity 注解并列使用，置于实体类声明语句之前，可写于单独语句行，也可与声明语句同行 Id：声明一个字段为主键 GeneraterValue：声明主键的生成策略，比如IDENTITY表示主键自增长 Column：声明主段，表示Java属性与表字段的映射关系 123456789101112131415161718@Entity@Table(name = &quot;xwj_user&quot;, schema = &quot;test&quot;)public class UserEntity &#123; @Id @GeneratedValue(generator = &quot;system-uuid&quot;) @GenericGenerator(name = &quot;system-uuid&quot;, strategy = &quot;uuid&quot;) @Column(name = &quot;ID&quot;, unique = true, nullable = false, length = 32) private Integer id; @Column(name = &quot;last_name&quot;) private String lastName; @Column(name = &quot;email&quot;, length = 32) private String email; //TODO get和set方法略...&#125; JSON格式处理 JsonIgnoreProperties：作用在类上用于过滤特定字段不返回 JsonIgnore：用于属性上表示不返回 JsonFormat：格式化json JsonUnwrapped：扁平化对象 测试处理 @ActiveProfiles：用于测试类上 @Test：声明一个方法是测试方法 @Transactional：被声明的测试方法会回滚，避免污染测试 12345678//常见的使用方式：使用rollbackFor 属性来定义回滚的异常类型，使用 propagation 属性定义事务的传播行为@Transactional(rollbackFor = Exception.class,propagation = Propagation.REQUIRED)public void processPayment(Order order) throws Exception &#123; // 如果抛出 Exception 或其子类的异常，将回滚事务 if (paymentFailed()) &#123; throw new Exception(&quot;Payment failed&quot;); &#125;&#125; 配置启动 @SpringBootApplication:@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan的组合 @SpringBootConfiguration：SpringBoot的配置类 @EnableAutoConfiguration：用在类上，表示SpringBoot根据添加的jar依赖猜测你想如何配置Spring @ComponentScan：定义哪些路径下的jar包被扫描 @Conditional：比如@ConditionalOnBean是配置某个特定的Bean","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"}]},{"title":"从前序与中序遍历序列构造二叉树","slug":"从前序与中序遍历序列构造二叉树","date":"2025-01-17T10:13:23.000Z","updated":"2025-01-17T10:26:46.729Z","comments":true,"path":"posts/从前序与中序遍历序列构造二叉树.html","permalink":"https://www.cdfy.top/posts/%E4%BB%8E%E5%89%8D%E5%BA%8F%E4%B8%8E%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91.html","excerpt":"","text":"该题主要是通过前序和中序遍历来还原一颗二叉树，核心的思路：在前序中找到根节点，根据该节点在中序遍历数组中的位置，根据中序划分左右子树，递归这个过程，还原一颗二叉树 本质上就是前序遍历中依次拿，不断地从中序遍历数组中缩小范围，范围为空的时候代表该范围拿不到了，需要换一颗子树。二叉树遍历的特点保证了前序遍历拿的元素一定可以在范围内找到 123456789101112131415161718192021222324252627282930struct TreeNode &#123; int val; TreeNode* left; TreeNode* right; TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125;; TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125;; TreeNode(int x, TreeNode* left, TreeNode* right) : val(x), left(left), right(right) &#123;&#125;;&#125;;class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; inorder.size(); i++) &#123; mp[inorder[i]] = i; &#125; TreeNode* dummy = new TreeNode(); int k = 0; auto dfs = [&amp;](this auto&amp;&amp; dfs, int l, int r) -&gt; TreeNode* &#123; if (l &gt; r) return NULL; TreeNode* root = new TreeNode(preorder[k++]); root-&gt;left = dfs(l, mp[root-&gt;val] - 1); root-&gt;right = dfs(mp[root-&gt;val] + 1, r); return root; &#125;; return dfs(0, preorder.size() - 1); &#125;&#125;;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"LRU缓存","slug":"LRU缓存","date":"2025-01-17T09:24:46.000Z","updated":"2025-01-17T09:25:59.168Z","comments":true,"path":"posts/LRU缓存.html","permalink":"https://www.cdfy.top/posts/LRU%E7%BC%93%E5%AD%98.html","excerpt":"","text":"请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构 实现 LRUCache 类： LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class LRUCache &#123;public: unordered_map&lt;int, int&gt; mp; unordered_map&lt;int, int&gt; cnt; queue&lt;int&gt; q; int sz; int capacity; LRUCache(int capacity) &#123; this-&gt;capacity = capacity; sz = 0; &#125; int get(int key) &#123; if (cnt[key]) &#123; q.push(key); cnt[key]++; return mp[key]; &#125; return -1; &#125; void put(int key, int value) &#123; if (sz &lt; capacity) &#123; if (cnt[key]) &#123; cnt[key]++; mp[key] = value; &#125; else &#123; cnt[key]++; mp[key] = value; sz++; &#125; q.push(key); &#125; else &#123; if (!cnt[key]) &#123; while (q.size()) &#123; int k = q.front(); q.pop(); cnt[k]--; if (!cnt[k]) &#123; mp.erase(k); break; &#125; &#125; &#125; mp[key] = value; cnt[key]++; q.push(key); &#125; &#125;&#125;;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"最长回文子串——区间dp","slug":"最长回文子串——区间dp","date":"2025-01-17T08:35:35.000Z","updated":"2025-01-17T08:36:13.041Z","comments":true,"path":"posts/最长回文子串——区间dp.html","permalink":"https://www.cdfy.top/posts/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2%E2%80%94%E2%80%94%E5%8C%BA%E9%97%B4dp.html","excerpt":"","text":"12345678910111213141516171819202122232425262728class Solution &#123;public: string longestPalindrome(string s) &#123; int n = s.size(); vector&lt;vector&lt;int&gt;&gt; dp(n + 1, vector&lt;int&gt;(n + 1, 0)); // dp[i][j] = dp[i + 1][j - 1] string ans = &quot;&quot;; int idx = 0; int m = 0; for (int i = n - 1; i &gt;= 0; i--) &#123; for (int j = i; j &lt; n; j++) &#123; if (s[i] == s[j]) &#123; if (i + 1 &gt; j - 1) dp[i][j] = 1; else dp[i][j] = dp[i + 1][j - 1]; &#125; if (dp[i][j] &amp;&amp; m &lt; j - i + 1) &#123; m = j - i + 1; idx = i; &#125; &#125; &#125; for (int i = idx; i &lt;= idx + m - 1; i++) ans += s[i]; return ans; &#125;&#125;;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"ACM算法模板","slug":"ACM算法模板","date":"2025-01-17T08:17:03.000Z","updated":"2025-01-31T09:28:29.312Z","comments":true,"path":"posts/ACM算法模板.html","permalink":"https://www.cdfy.top/posts/ACM%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF.html","excerpt":"","text":"ACM算法模板","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"最小覆盖子串——滑动窗口","slug":"最小覆盖子串——滑动窗口","date":"2025-01-17T08:11:06.000Z","updated":"2025-01-17T08:16:11.874Z","comments":true,"path":"posts/最小覆盖子串——滑动窗口.html","permalink":"https://www.cdfy.top/posts/%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2%E2%80%94%E2%80%94%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.html","excerpt":"","text":"给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 &quot;&quot; 注意： 对于 t 中重复字符，我们寻找的子字符串中该字符数量必须不少于 t 中该字符数量 如果 s 中存在这样的子串，我们保证它是唯一的答案 滑动窗口区间[j, i] 初始i = j = 0, 直接添加第一个 i永远一步一步来，j根据条件改变，尽量让窗口变小，但是不能不满足条件 结束的时候是i越界 123456789101112131415161718192021222324class Solution &#123;public: string minWindow(string s, string t) &#123; string ans = &quot;&quot;; unordered_map&lt;char, int&gt; mp; for (auto ch : t) mp[ch]++; unordered_map&lt;char, int&gt; cnt; int tt = 0; for (int i = 0, j = 0; i &lt; s.size(); i++) &#123; cnt[s[i]]++; if (cnt[s[i]] &lt;= mp[s[i]]) tt++; while (cnt[s[j]] &gt; mp[s[j]]) &#123; cnt[s[j]]--; j++; &#125; if (tt == t.size()) &#123; if (!ans.size() || ans.size() &gt; i - j + 1) &#123; ans = s.substr(j, i - j + 1); &#125; &#125; &#125; return ans; &#125;&#125;;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"传输层协议","slug":"传输层协议","date":"2025-01-15T12:12:50.000Z","updated":"2025-01-15T16:40:31.948Z","comments":true,"path":"posts/传输层协议.html","permalink":"https://www.cdfy.top/posts/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE.html","excerpt":"","text":"以下部分图片节选自小林coding，有侵权问题必删 传输层概述 传输层的两个重要协议 TCP和UDP TCP： 面向连接 可靠连接 基于字节流 仅支持单播 UDP: 无连接 面向报文 支持单薄、广播、多播 不可靠 传输层复用、分用和端口 用户数据报协议（User Datagram Protocol， UDP） UDP概述 UDP格式 可靠传输原理 停止等待协议 连续ARQ协议 滑动窗口 回退N步（GBN）协议 对比停等协议和滑动窗口协议的基本概念，不难发现，停等协议实质上是发送窗口长度为1，接收窗口长度也为1的滑动窗口协议 GBN协议是发送窗口长度大于1，接收窗口长度等于1的滑动窗口协议 发送方行为： 接收方行为： GNB的信道利用率： 观察GBN协议的运行过程，可以发现流水线方式的传输使信道中不断有数据在传送，确实可以提高信道利用率 但由于接收窗口仅为1，造成丢失或差错的PDU之后到达的所有PDU均被发送方重传，即使这些失序到达的PDU都是正确的。这种处理方式造成了信道资源的浪费 从发送方角度来看，一旦发生超时重传事件，则需要回退N步，从超时的PDU开始重新发送所有后续PDU 选择重传（SR）协议 发送方行为： 接收方行为： 此外，还有否定应答NAK： 选择重传SR协议可以跟否定策略结合在一起使用，即当接收方检测到错误的PDU时，它就发送一个否定应答（Negative Acknowledgement，NAK） 在发送方，收到NAK可以触发该PDU的重传操作，而不需要等到对应的超时计时器超时，因此可以提高协议性能 传输控制协议（TCP） TCP概述 TCP连接是逻辑连接，TCP把连接作为最基本的抽象。 TCP连接的端点称为套接字（socket） RFC793中定义套接字由端口号拼接到IP地址构成： 套接字=（𝐈𝐏地址：端口号） 每一条TCP连接有且仅有两个端点，每一条TCP连接唯一地被通信两端的两个套接字确定 TCP连接两端的主机需要维护TCP连接状态 一旦建立连接，主机中的TCP进程将设置并维护发送缓存和接收缓存 TCP报文格式 紧急指针： 当URG标志位置1时才有效，因为只有一个紧急指针，这也意味着它只能标识一个字节的数据。这个指针指向了紧急数据最后一个字节的下一个字节 我们知道 TCP 在传输数据时是有顺序的，它有字节号，URG 配合紧急指针，就可以找到紧急数据的字节号。紧急数据的字节号公式如下： 紧急指针的作用： 一旦 TCP 知道了你要发送紧急数据，那么在接下来的数据发送中，TCP会将所有的TCP报文段中的URG标志置位，哪怕该报文段中不包含紧急数据，这个行为会持续到紧急数据被发送出去为止 一些坑： 如果发送方多次发送紧急数据，最后一个数据的紧急指针会将前面的覆盖。比方说你发送了一个字节的紧急数据 'X'，在 'X' 尚未被 TCP 发送前，你又发送了一个紧急数据 'Y'，那么在后面的 TCP 报文中，紧急指针都是指向了 'Y' 的 很多系统的实现，包括 Linux 将紧急数据称之为带外数据（out-of-band data, OOB），意为在连接之外传送的数据，实际上这是不对的（《TCP/IP 详解》一书称此不正确的）。即使是紧急数据，仍然会随着普通数据流一起发送，并不会单独为紧急数据开辟一条新的连接通道单独发送 选项字段： MSS和MTU TCP面向字节流 TCP三次握手 为什么TCP建立连接不能2次握手？ 为了避免历史连接：防止旧的重复连接初始化造成混乱。比如在网络拥堵的情况下连续发了2个SYN报文(旧的报文SYN是90，新的是100) 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文中的确认号是 91（90+1）。 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文 服务端收到 RST 报文后，就会释放连接。 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了 在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费 TCP四次挥手 注意客户端在进入TIME_WAIT状态后，需要等2MSL才能close 为什么需要等待2MSL? MSL，即 Maximum Segment Lifetime，一个数据分片(报文)在网络中能够生存的最长时间，在RFC 793中定义MSL通常为2分钟，即超过两分钟即认为这个报文已经在网络中被丢弃了。可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时 为什么需要 TIME_WAIT 状态 防止历史连接中的数据，被后面相同四元组的连接错误的接收 保证被动关闭连接的一方，能被正确的关闭 TCP可靠传输 TCP的可靠传输协议是以字节为单位的滑动窗口协议 TCP可靠传输的特点： TCP窗口内的序号不是以PDU为单位编号，而是以字节为单位编号 TCP的发送窗口和接收窗口均大于1 TCP的发送窗口和接收窗口长度不是固定的，而是动态变化的 TCP支持多种重传机制：超时重传、快重传和SACK重传 重传机制 超时重传 超时重传发生的情况： 数据包丢失 确认应答丢失 超时重传时间 RTO 的值应该略大于报文往返 RTT 的值 快速重传 不以时间为驱动，而是以数据驱动重传 连续收到三个相同的ACK序列号说明该Seq丢失 SACK 超时重传有一个缺点：就是重传的时候，是重传一个，还是重传所有的 SACK（ Selective Acknowledgment）， 选择性确认 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据 Duplicate SACK 主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了 好处： 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了; 可以知道是不是「发送方」的数据包被网络延迟了 可以知道网络中是不是把「发送方」的数据包给复制了 滑动窗口 流量控制 拥塞控制 慢启动 拥塞窗口cwnd，以MSS的个数做为cwnd的单位 慢启动门限ssthresh 初始化时：cwnd为1个MSS， ssthresh为65535个字节 连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个 慢启动阶段cwnd是以指数的形式增长的，直到拥塞窗口大小大于门限值为止 拥塞避免 当cwnd到达ssthresh，一般来说 ssthresh 的大小是 65535 字节 每当收到一个 ACK 时，cwnd 增加 1/cwnd 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长 拥塞发生 当网络出现拥塞，也就是会发生数据包重传，会启用拥塞发生算法 在超时重传和快速重传两种重传机制下，拥塞发生算法不同 超时重传： ssthresh 设为 cwnd/2 cwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1） 快速恢复： 快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈 cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd cwnd = ssthresh + 3 重传丢失的数据包 如果再收到重复的 ACK，那么 cwnd 增加 1 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态 为什么收到新的数据后，cwnd 设置回了 ssthresh ？ 首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变 其次cwnd+1的存在是为了尽快将丢失的数据包发给目标，从而解决阻塞的根本（三次相同的ACK会重传），所以这一过程cwnd是增大的","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"IP地址","slug":"IP地址","date":"2025-01-15T09:31:01.000Z","updated":"2025-01-15T11:21:29.763Z","comments":true,"path":"posts/IP地址.html","permalink":"https://www.cdfy.top/posts/IP%E5%9C%B0%E5%9D%80.html","excerpt":"","text":"IP地址概述 点分十进制记法 一个32位的二进制数，采用点分十进制记法表示 分层结构 IP地址采用分层结构，即IP地址由与互联网特定层结构对应的几部分构成 IP地址包括两部分：网络部分和主机部分 网络部分指明了主机所连网络，同一网络中所有主机的IP地址一样 主机部分标识了特定网络中的特定主机 采用分层结构的IP地址后，路由器可以仅根据IP地址的网络部分来转发分组，而无须考虑主机部分 编址方案的演进 编址方案之有类别编址 五类PI地址如何划分 A、B、C类IP地址的特殊地址 RFC1812规定，单播IP地址采用无类别编址方案。A类、B类和C类地址的区分已成为历史。 但由于传统的有类别编址方案，从概念的演进上更清晰，因此讨论IP地址，仍然需要从分类的IP地址讲起 最初互联网建议支持路由器转发定向广播，而且默认启用。但RFC2644变更了该策略，要求路由器默认禁止转发定向广播。 A、B、C类IP地址可指派的地址数量 由于B类和C类是1开头，所以网络号不可能全0 路由器和主机的IP地址 编址方案之子网划分 子网定义 子网或子网络是网络内部的网络。子网使网络更高效。通过子网划分，网络流量传播距离更短，无需通过不必要的路由器即可到达目的地 定长子网划分 这样网络地址有更加细分的能力了 可变长子网划分 编址方案之有无类别编址 网络前缀 路由聚合 特殊用途的IP地址","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络概述","slug":"计算机网络概述","date":"2025-01-15T08:32:29.000Z","updated":"2025-01-15T09:27:44.949Z","comments":true,"path":"posts/计算机网络概述.html","permalink":"https://www.cdfy.top/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0.html","excerpt":"","text":"网络边缘 由所有连接在互联网上的主机以及接入网组成： 主机：个人计算机、服务器、超级计算机、智能手机、摄像头以及各种网络传感器等 接入网：主机连接到其边界路由器的网络，边界路由器指进入互联网核心部分后的第一台路由器。接入网包括ASDL接入、光纤同轴混合网、FTTH接入、以太网接入、WiFi接入以及蜂窝移动接入等，不同的接入网使用了不同的传输介质（双绞线、同轴电缆、光纤以及自由空间等） 网络核心 网络核心概述： 网络核心由各种网络以及连接这些网络的路由器组成 网络核心为网络边缘部分的主机提供通信服务 计算机网络采用分组交换的方式，路由器是网络核心最重要的部分 通信网络的交换方式 电路交换 电路交换属于通信资源的预分配系统，传统的电话网络采用这种 建立连接 数据传输 释放连接 分组交换 计算机网络具有突发性，如果使用电路交换，通信资源的利用率会极低 分组交换属于通信资源的动态分配系统 特点： 分组 存储转发 逐段占用通信链路资源 虚电路或数据报 分组 将报文切分成较小的数据段，在每个数据段前面添加控制信息（叫做首部，也叫包头），构成分组。分组也称作包 存储转发 在互联网中，分组交换的节点也称为路由器 路由器收到一个分组后 先暂时存储起来 然后根据首部的控制信息，找到合适的接口将分组转发出去 逐段占用通信链路资源 虚电路方式 分组交换包括两种方式：虚电路和数据报 面向连接，虚电路连接，不是物理连接，只是一条逻辑连接 建立虚电路后，在数据通信阶段，路由器根据虚电路标识转发分组，属于相同虚电路的数据分组将沿着相同的路径，按序到达网络，到达目的结点 数据报方式 数据报方式是无连接的，发送之前不需要建立连接 数据报方式中，路由器为每个分组独立选择转发接口，从相同源结点发往相同的目的结点的数据分组，有可能沿着不同的路径，也有可能失序到达目的结点 分组交换的问题 增大了延迟：分组在路由器中存储转发的时候，需要在队列中排队 增大了开销：每一个分组的首部都包括一些控制信息，会增加一定的开销 报文交换 报文交换也采用存储转发方式 报文交换与分组交换的区域在于：报文交换传输的数据单元是一个完整的数据包，不进行分组 分组交换网的性能 带宽 单位时间内能传输的最大数据量, 单位是比特每秒(b/s) 吞吐量 单位时间内通过某个网络或者接口的实际数据量, 单位是比特每秒(b/s) 延迟 丢包率 丢包率=(Ns−Nr)/Ns丢包率 = (N_s - N_r) / N_s丢包率=(Ns​−Nr​)/Ns​ Ns代表发送的分组总数，Nr代表收到的分组总数N_s代表发送的分组总数，N_r代表收到的分组总数Ns​代表发送的分组总数，Nr​代表收到的分组总数 利用率 D=D0/(1−U)D = D_0 / (1 - U)D=D0​/(1−U) D代表网络当前的延迟，D0表示网络空闲时的延迟，U表示利用率D代表网络当前的延迟，D_0表示网络空闲时的延迟，U表示利用率D代表网络当前的延迟，D0​表示网络空闲时的延迟，U表示利用率 延迟带宽积 延迟带宽积=延迟∗带宽延迟带宽积 = 延迟 * 带宽延迟带宽积=延迟∗带宽 网络体系结构 控制平面和数据平面","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"DHCP简要概述","slug":"DHCP简要概述","date":"2025-01-15T07:47:39.000Z","updated":"2025-01-31T09:28:26.994Z","comments":true,"path":"posts/DHCP简要概述.html","permalink":"https://www.cdfy.top/posts/DHCP%E7%AE%80%E8%A6%81%E6%A6%82%E8%BF%B0.html","excerpt":"","text":"DHCP简要概述","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"HTTP协议","slug":"HTTP协议","date":"2025-01-15T05:49:06.000Z","updated":"2025-01-15T07:23:50.304Z","comments":true,"path":"posts/HTTP协议.html","permalink":"https://www.cdfy.top/posts/HTTP%E5%8D%8F%E8%AE%AE.html","excerpt":"","text":"HTTP报文格式 HTTP有两类报文：请求报文和响应报文 HTTP是面向文本的，在报文中的每一个字段都是一些ASCII串 HTTP请求报文和响应报文都是由三部分组成： 开始行：在请求报文中叫请求行，在响应报文中叫状态行 首部行：用来说明浏览器、服务器或者报文主体的一些信息 实体主体：在请求报文中叫请求主体，在响应报文中叫响应主体 HTTP请求报文中的方法 POST方法和PUT方法类似，区别在于POST是新增，PUT是更新，开发中用的比较多的是POST和GET HTTP响应报文中的状态码 什么时候会出现502错误码 502错误码是服务器在充当网关或者代理时，应用服务器发生故障，nginx无法从应用服务器那收到响应，就会返回502给客户端 什么时候会发现504错误码 504错误码是服务器在充当网关或者代理时，应用服务器接口超时，nginx无法从应用服务器那收到响应，就会返回504给客户端 永久重定向和临时重定向区别 永久重定向：会记忆重定向后的URL，下次访问直接访问新的URL 临时重定向区：不会记忆重定向后的URL，下次访问仍要先访问旧的URL，再访问新的 代理服务器和内容分发网络 代理服务器 代理服务器也叫万维网缓存。代理服务器可以将最近请求过的资源的副本缓存在自己的存储空间 工作流程： 浏览器先与代理服务器建立TCP连接，向代理服务器发送HTTP请求 代理服务器收到HTTP请求后，检查本地缓存，如果有指定资源的副本就直接返回 否则向源服务器发送HTTP请求 源服务器向代理服务器返回指定的资源 代理服务器收到该资源后，自己存储一份副本，然后返回给客户端 什么是正向代理，什么是反向代理 正向代理是代理客户端，可以用来屏蔽客户端IP地址和避免网络浏览限制，以及阻止访问某些内容和缓存响应结果提高访问速度 反向代理是代理服务端，可以用来保护服务器，隐藏真实IP。以及负载均衡 CDN 内容缓存和分发： CDN在全球多个节点上缓存静态内容（如图像、CSS、JavaScript 文件），将内容分发到离用户最近的节点，以减少延迟并加快加载速度。 负载分担： 通过将请求分发到多个缓存节点，CDN 可以减少源服务器的负载，从而提高整体系统的性能和可用性。 流量管理： CDN可以处理大量的并发请求，尤其在高流量情况下，帮助减轻原始服务器的压力。 CDN不依赖用户在浏览器中配置代理服务器，而是依赖DNS将不同的HTTP请求定向到不同的代理服务器上 负载均衡 负载均衡（Server Load Balancer）是将访问流量根据转发策略分发到后端多台云服务器（ECS实例）的流量分发控制服务。负载均衡扩展了应用的服务能力，增强了应用的可用性 负载均衡算法： 普通轮询：请求依次分配给服务器 加权轮询：根据权重比分配给服务器 IP哈希：根据客户端IP地址的哈希值来确认分配的服务器 URL哈希：根据请求的URL的哈希值来确认分配的服务器 最短响应时间：按照后端服务器的响应时间来分配，响应时间短的优先分配 最短连接：新请求会发送到并发连接最少的服务节点 HTTP的发展 HTTP/1.x HTTP/1.0和HTTP1.1的主要区别： 长连接：HTTP1.1默认的行为是长连接。HTTP1.0也支持长连接，但是默认是短链接 请求管道化：HTTP1.1支持请求管道化，在一个持久连接上可以同时发送多个请求。而HTTP1.0不支持，请求和响应必须是串行的。但是HTTP1.1仍然要求服务器按顺序返回响应报文 host字段：HTTP1.0没有host字段。HTTP1.1有，可以一个物理服务器承载多个域名或者站点 HTTP/2.0 HTTP/1.x存在的问题： 线头阻塞问题：服务器需要按序处理请求和返回响应报文，需要缓存多个请求，占用更多资源 TCP并发连接数限制：利用多个TCP连接，并发访问服务器会消耗大量服务器资源 没有报文首部压缩方案：HTTP报文首部很多，但每次请求首部的变化通常不大 明文传输不安全：HTTP依赖传输层TLS协议才能实现加密传输 HTTP1.1和HTTP2.0的主要区别： 基于流的多路复用：HTTP/2引入了流的概念，每一对HTTP请求报文和响应报文被视为同一个流，在同一个TCP连接上实现了流的多路复用，不同流中的帧可以交错地发送给对方 二进制格式的帧和首部压缩：HTTP/2将HTTP/1的纯文本格式改成了二进制格式，提高了传输效率。并且用HPACK算法压缩了首部信息 服务器主动推送；比如客户端向服务器请求HTML文件时，会将相关的CSS文件也推送过来 增强安全性：主流浏览器公开宣布只支持加密的HTTP/2，并且HTTP/2对TLS的安全性做了进一步加强，比如HTTP/2通过黑名单机制禁用了几百种不再安全的加密算法和对TLS进行了扩展，开发了应用层协商协议ALPN HTTP/3.0 HTTP2.0存在的问题： 线头阻塞问题没有完全解决：会有TCP队头阻塞的问题，tcp是基于字节流的，必须要解决粘包问题，因此如果有一个steam丢包必须要重传，直到全部的steam收到 TCP建立连接的延迟问题：HTTP基于TCP实现，因此要先进行三次握手，有较大延迟 网络迁移需要重新连接：一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WiFi HTTP/3：HTTP/3就将传输层从TCP替换成了 UDP，并且UDP协议在应用层上实现了QUIC协议，来保证数据的可靠传输 QUIC协议的特点： 无队头阻塞：QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响 建立连接快：因为 QUIC 内部包含 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果 连接迁移：，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"HTML文档的概述","slug":"HTML文档的概述","date":"2025-01-15T05:32:13.000Z","updated":"2025-01-15T05:44:03.251Z","comments":true,"path":"posts/HTML文档的概述.html","permalink":"https://www.cdfy.top/posts/HTML%E6%96%87%E6%A1%A3%E7%9A%84%E6%A6%82%E8%BF%B0.html","excerpt":"","text":"超文本标记语言HTML是制作万维网页面的标准语言，目前版本HTML5.0 HTML使用标记标签来描述网页文档，HTML标签是由尖括号包围的关键词，通常是成对出现的，例如和，其中第一个是开始标签，第二个是结束标签 HTML标签的组成如下： 1&lt;tag-name [[attribute-name[= arrribute-value]]...]&gt;(文本内容)&lt;/tag-name&gt; 从开始标签道结束标签的所有代码称为HTML元素 完整的HTML文档如下： 为了控制文档的呈现方式，通常会使用层叠样式表(CSS) CSS (Cascading Style Sheets，层叠样式表），是一种用来为结构化文档（如 HTML 文档或 XML 应用）添加样式（字体、间距和颜色等）的计算机语言，CSS 文件扩展名为 .css HTML文档分为静态文档、动态文档、活动文档三种： 静态HTML文档：不会根据浏览器发来的数据而改变 动态HTML文档：在浏览器访问服务器的时候才创建，当浏览器的请求到达的时候，服务器将URL映射到一个应用程序，由应用程序根据请求中的数据创建一个HTML文档 活动HTML文档：把创建HTML的任务交给浏览器执行。服务器返回给浏览器的文档中包含脚本程序，浏览器执行脚本后，得到活动HTML文档","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"统一资源定位符URL","slug":"统一资源定位符URL","date":"2025-01-15T05:14:06.000Z","updated":"2025-01-15T05:25:12.661Z","comments":true,"path":"posts/统一资源定位符URL.html","permalink":"https://www.cdfy.top/posts/%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%AE%9A%E4%BD%8D%E7%AC%A6URL.html","excerpt":"","text":"URI 本质上是一个字符串，这个字符串的作用是唯一地标记资源的位置或者名字 1http://www.chrono.com:8080/11-1?uid=1234&amp;name=mario&amp;referer=xxx scheme + 😕/ + host:port + path + [?query] + [#fragment] path: / + [目录名] + / + ... + 文件名 ,path中第一个/是web服务器配置文件中的根，不是操作系统的根 第一个多出的部分是协议名之后、主机名之前的身份信息“user:passwd@”，表示登录主机时的用户名和密码，但现在已经不推荐使用这种形式了（RFC7230），因为它把敏感信息以明文形式暴露出来，存在严重的安全隐患 第二个多出的部分是查询参数后的片段标识符“#fragment”,它是 URI 所定位的资源内部的一个“锚点”或者说是“标签”，浏览器可以在获取资源后直接跳转到它指示的位置。但片段标识符仅能由浏览器这样的客户端使用，服务器是看不到的。也就是说，浏览器永远不会把带“#fragment”的 URI 发送给服务器，服务器也永远不会用这种方式去处理资源的片段","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"网络传输场景问题","slug":"网络传输场景问题","date":"2025-01-15T04:51:42.000Z","updated":"2025-01-15T05:06:40.403Z","comments":true,"path":"posts/网络传输场景问题.html","permalink":"https://www.cdfy.top/posts/%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E5%9C%BA%E6%99%AF%E9%97%AE%E9%A2%98.html","excerpt":"","text":"如何浏览器没有显示页面有哪些原因 先确实是服务端的问题还是客户端的问题。如果客户端可以访问其他网站，如果可以说明客户端网络没问题 如果客户端网络没问题，就抓包确认DNS是否解析出了IP地址，如果没有解析出来说明域名写错了 如果IP解析出来了，再抓包确认TCP是否完成了3次握手，需要在server端通过ps确认server进程是否启动，以及通过netstate命令确认是否监听了端口 如果TCP完成了3次握手查看返回的状态码 404：检查输入的url是否正确 500：服务器有问题，需要去服务器排查日志 200：可以在浏览器按F12输出前端控制台，看看前端代码是不是有问题 如果网络没问题，可以通过ping去确认网络延迟是否正常，如果耗时很长，可以排查服务器流量是不是很大，导致超过了带宽上限。如果网络正常可以排查接口是否正常，有可能是慢SQL导致的 服务器ping不通但是http可以请求成功，会出现吗？ 会的。因为ping是ICMP协议，http是TCP协议，有可能服务器的防火墙禁止ICMP协议，但是TCP协议没有被禁止 客户端TCP连接一个不存在的IP地址会发生什么 如果访问的IP地址在局域网内，客户端的内核在发ARP请求的时候，广播会询问这个IP是否存在，由于不存在所以收不到ARP回应，这时候就会卡在ARP协议，SYN报文发不出去 如果访问的IP地址不在局域网内，客户端会先将SYN报文发送到路由器，然后路由器会继续转发，由于IP不存在，该SYN报文会消亡。接着客户端会发生超时重传，到达最大重传次数后客户端连接会释放 客户端TCP连接一个存在的IP地址但是端口不存在会发生什么 服务端在收到SYN报文后，会返回一个RST报文，客户端收到RST报文后会断开连接 客户端UDP连接一个存在的IP地址但是端口不存在会发生什么 UDP没有RST报文，因此服务端会返回ICMP报文，报告端口不可达","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"键入网址场景问题","slug":"键入网址场景问题","date":"2025-01-14T14:29:30.000Z","updated":"2025-01-15T03:41:02.023Z","comments":true,"path":"posts/键入网址场景问题.html","permalink":"https://www.cdfy.top/posts/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E5%9C%BA%E6%99%AF%E9%97%AE%E9%A2%98.html","excerpt":"","text":"输入网址后，期间发生了什么 浏览器会先解析URL，解析出域名、资源路径、端口等信息，然后构造HTTP请求报文 域名解析，将域名解析成IP地址。会先查系统缓存是否有域名信息，如果有返回IP地址。如果没有再去查看本地系统hosts文件有没有域名信息，如果有就返回。如果没有再去本地DNS服务器查看。如果仍然没有就分别去根域名服务器-&gt;顶级域名服务器-&gt;权威域名服务器询问，最后返回IP 进行TCP三次握手建立连接，第一次握手会填上SYN标记位，同时填上源端口和目标端口 到网络层会加上IP头，填上目标IP地址和源IP地址 到数据链路层通过ARP协议获取到路由器的MAC地址，然后加上MAC头，填上目标MAC地址和源MAC地址 到物理层直接把数据包发送给路由器，路由器再通过下一条找到目标服务器，然后目标服务器收到SYN报文后，响应第二次握手 当双方都完成三次握手后，如果是http协议客户端就会将http请求发送给服务端；如果是https还需要ssl四次握手 目标服务器收到http请求后，就返回http响应消息，浏览器会对消息进行解析渲染，呈现给用户 DNS是如何解析的，是属于哪一层的协议 DNS是属于应用层的协议 会先查系统缓存是否有域名信息，如果有返回IP地址。如果没有再去查看本地系统hosts文件有没有域名信息，如果有就返回。如果没有再去本地DNS服务器查看。如果仍然没有就分别去根域名服务器-&gt;顶级域名服务器-&gt;权威域名服务器询问，最后返回IP保存到本地DNS服务器，然后本地DNS服务器将IP保存到本地缓存，并将查询结果返回给客户端 DNS解析用到了什么协议 UDP协议，因为UDP协议传输快，如果要保证可靠可以在应用层实现一个超时重传机制 输入域名如何知道端口 http的默认端口是80，https的默认端口是443，或者指定端口（比如:8080） 客户端向服务端的IP地址发送数据，服务端如何确定把消息传给哪个应用 每个传输层（如TCP和UDP）都使用不同的端口号来区分应用程序，服务端通过监听特殊的端口号来接受来自客户端的数据 现在很多网站都要求使用https，我们输入一个http网站，网站是如何实现由http调到https的 涉及服务器的配置，以下是nginx服务器端的配置方法来实现重定向 12345server&#123; listen 80 server_name example.com return 301 https:&#125; 服务器网关收到http请求后，会返回给客户端一个响应，状态码为301（永久重定向） 浏览器收到重定向响应后，自动向服务器发送一个https请求","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"网络分层模型","slug":"网络分层模型","date":"2025-01-14T13:35:06.000Z","updated":"2025-01-15T03:41:16.811Z","comments":true,"path":"posts/网络分层模型.html","permalink":"https://www.cdfy.top/posts/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82%E6%A8%A1%E5%9E%8B.html","excerpt":"","text":"OSI七层协议 应用层：与软件应用程序直接通信，如HTTP、HTTPS协议 表示层：提供各种应用层的编码和转换功能，如数据转换、压缩、加密等。 会话层：控制计算机之间建立会话连接 传输层：端到端通信，如TCP、UDP协议 网络层：逻辑寻址和交换功能处理数据包路由，比如IP、ICMP、ARP协议 数据链路层：节点到节点的传输，通过MAC地址标识网络上的设备 物理层：定义了数据连接的物理规格，比如光纤电缆等 TCP/IP网络模型 应用层：与软件应用程序直接通信，如HTTP、HTTPS协议 传输层：端到端通信，如TCP、UDP协议 网络层：负载主机寻找、打包和路由功能，比如IP、ICMP、ARP协议。IP负责寻址和路由，ARP负责获取MAC地址，ICMP负责提供诊断功能并报告错误 网络接口层：为网络层提供链路级别传输的服务，负责在以太网、WiFi这样的底层网络上传输原始数据包，工作在网卡这个层次，通过MAC地址来标识网络上的设备 TCP和IP分别在哪一层 TCP协议在传输层，IP协议在网络层 网络为什么要分层 为了降低耦合，上层不用关系下层的实现，只关心下层提供的接口服务，有利于排查网络问题，能更精细地定位到哪一层 不会产生关联性，不会因为某一层的改变影响到其他，比如http从1.1升级到2.0，不会对传输层和网络层有影响。以及IPv4协议升级到IPv6也不会对应用层和传输层有影响","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"最长回文字串——马拉车算法","slug":"最长回文字串——马拉车算法","date":"2025-01-14T11:28:20.000Z","updated":"2025-01-25T09:48:02.369Z","comments":true,"path":"posts/最长回文字串——马拉车算法.html","permalink":"https://www.cdfy.top/posts/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%97%E4%B8%B2%E2%80%94%E2%80%94%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95.html","excerpt":"","text":"Manacher算法是一个用来查找一个字符串中的最长回文子串(不是最长回文序列)的线性算法。它的优点就是把时间复杂度为O(n^2)的暴力算法优化到了O(n) 本质是对中心扩展算法的优化！ 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution &#123;public: string longestPalindrome(string s) &#123; string str = &quot;&quot;; str += &#x27;$&#x27;; for (auto ch : s) &#123; str += &#x27;#&#x27;; str += ch; &#125; str += &#x27;#&#x27;; int n = str.size(); vector&lt;int&gt; d(n + 1, 1); int l = 1, r = 1; int mx = 0; int p = 0; for (int i = 2; i &lt; str.size(); i++) &#123; if (i &lt;= r) &#123; d[i] = min(d[l + r - i], r - i + 1); &#125; while (str[i + d[i]] == str[i - d[i]]) &#123; d[i]++; &#125; if (d[i] &gt; mx) &#123; mx = d[i]; p = i; &#125; if (i + d[i] - 1 &gt; r) &#123; r = i + d[i] - 1; l = i - d[i] + 1; &#125; &#125; string ans = &quot;&quot;; // #a#b#b#a# for (int i = p - mx + 1; mx - 1 &gt;= 1; i++) &#123; if (str[i] != &#x27;#&#x27;) &#123; mx--; ans += str[i]; &#125; &#125; return ans; &#125;&#125;;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"cookie、session、token、jwt的区别","slug":"cookie、session、token、jwt的区别","date":"2025-01-14T08:49:52.000Z","updated":"2025-01-31T09:27:58.990Z","comments":true,"path":"posts/cookie、session、token、jwt的区别.html","permalink":"https://www.cdfy.top/posts/cookie%E3%80%81session%E3%80%81token%E3%80%81jwt%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"cookie、session、token、jwt的误区纠正","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"TCP流量控制和拥塞控制的区别","slug":"TCP流量控制和拥塞控制的区别","date":"2025-01-14T03:35:36.000Z","updated":"2025-01-15T03:41:16.787Z","comments":true,"path":"posts/TCP流量控制和拥塞控制的区别.html","permalink":"https://www.cdfy.top/posts/TCP%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E5%92%8C%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"流量控制：端到端的控制，目的是放在发送方发送的数据过快，导致接收方处理不过来，通过滑动窗口实现。接收方在ACK报文中告诉自己的接受窗口的大小，这样就告诉了发送方可接受的最大数据量 拥塞控制：网络层面的控制，目的是放在过多的数据包同时在网络中传输，导致网络拥塞。主要通过慢启动、拥塞避免算法、超时重传、快速重传、快速恢复算法实现","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"TCP和UDP的区别","slug":"TCP和UDP的区别","date":"2025-01-14T03:24:33.000Z","updated":"2025-01-15T03:41:16.796Z","comments":true,"path":"posts/TCP和UDP的区别.html","permalink":"https://www.cdfy.top/posts/TCP%E5%92%8CUDP%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"连接：TCP是面向连接，需要3次握手。UDP不需要 可靠性：TCP会通过超时重传、流量控制、拥塞控制来保证传输的可靠。UDP没有这些保证可靠性 传输方式：TCP的传输是以字节流的形式，没有边界，会有粘包问题。UDP的传输是一个包一个包发送，有边界 TCP优劣势：保证数据的可靠，但是实时性没有UDP好 UDP优劣势：实时性和速度好，但是不可靠","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"http和https有什么区别","slug":"http和https有什么区别","date":"2025-01-14T03:14:48.000Z","updated":"2025-01-15T03:41:16.828Z","comments":true,"path":"posts/http和https有什么区别.html","permalink":"https://www.cdfy.top/posts/http%E5%92%8Chttps%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"安全性：http是明文传输，数据在传输过程中不加密，容易被窃听和篡改。https通过SSL/TLS来对数据加密 建立链接：http只需要进行TCP三次握手即可建立链接，而https还需要进行SSL/TLS的四次握手 端口号：http默认端口号是80，https是443 证书：https需要通过CA机构申请数字证书来验证服务器的身份","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"epoll的ET和LT模式","slug":"epoll的ET和LT模式","date":"2025-01-14T03:05:25.000Z","updated":"2025-01-31T09:29:29.028Z","comments":true,"path":"posts/epoll的ET和LT模式.html","permalink":"https://www.cdfy.top/posts/epoll%E7%9A%84ET%E5%92%8CLT%E6%A8%A1%E5%BC%8F.html","excerpt":"","text":"epoll的ET和LT模式","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"进程间通信","slug":"进程间通信","date":"2025-01-14T02:40:22.000Z","updated":"2025-01-15T03:41:16.796Z","comments":true,"path":"posts/进程间通信.html","permalink":"https://www.cdfy.top/posts/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1.html","excerpt":"","text":"管道 匿名管道「|」 ps auxf | grep mysql 上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁 命名管道(mkfifo) mkfifo myPipe myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思 12ls -lprw-r--r--. 1 root root 0 Jul 17 02:45 myPipe 接下来，我们往 myPipe 这个管道写入数据 12echo &quot;hello&quot; &gt; myPipe // 将数据写进管道 // 阻塞... 因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出 12cat &lt; myPipe // 读取管道里的数据hello 优缺点： 优点：自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了 缺点：通信方式效率低，不适合进程间频繁地交换数据 原理 匿名管道的创建，需要通过下面这个系统调用 1int pipe(int fd[2]) 这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 fd[0]，另一个是管道的写入端描述符 fd[1]。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中 所谓的管道，就是内核里面的一串缓存。我们可以使用 fork 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个 fd[0] 与 fd[1]，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了 管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是： 父进程关闭读取的 fd[0]，只保留写入的 fd[1]； 子进程关闭写入的 fd[1]，只保留读取的 fd[0] 到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。 在 shell 里面执行 A | B 命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell 消息队列 消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核中的消息链表（内核是共享的），消息队列的消息体可以是用户自定义的数据类型。在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），当接收方接受数据时，也要与发送方的数据类型一样 缺点： 通信不及时，因为每次数据的写入和读取都需要经过用户态和内核态的拷贝过程 不适合大数据的传输，因为内核中的消息体都有一个最大长度的限制，同时所有队列包含的消息体也是有上限的 共享内存 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，大大提高了进程间通信的速度 优缺点： 优点：不需要陷入内核态或者系统调用，也不需要拷贝数据 缺点：多进程竞争同一个资源会造成数据的错乱 信号量 对于共享内存的多进程竞争资源，而造成数据错乱的问题。信号量可以解决 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据 信号量表示资源的数据，有两种操作： P操作：这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行 V操作：这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程 总的来说，操作后：如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行 P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的 共享和互斥的实现方式： 如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为1 如果要实现多进程同步的方式，我们可以初始化信号量为0 信号 信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别 在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号： 运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如 Ctrl+C 产生SIGINT信号，表示终止该进程 Ctrl+Z 产生SIGTSTP信号，表示停止该进程，但还未结束 如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如： kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式 执行默认操作： Linux对每种信号都做了默认操作，比如列表中的SIGTERM信号，就是终止进程的意思 捕捉信号：我们可以定义信号是一个信号处理函数，当信号发生的时候就执行对应的函数 忽略信号：当我们不希望处理信号的时候就可以忽略，但有两个是不能捕捉和忽略的，分别是SIGKILL和SEGSTOP，分别表示任何时候中断或者结束某一进程 Socket socket函数 int socket(int domain, int type, int protocal) socket参数意义： domain：用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机 type：参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字 protocal：参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可 根据创建 socket 类型的不同，通信的方式也就不同： 实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM 实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM 实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket 针对 TCP 协议通信的 socket 编程模型 bind：服务端用于将把用于通信的地址和端口绑定到 socket 上 这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket 针对 UDP 协议通信的 socket 编程模型 UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind 针对本地进程间通信的 socket 编程模型 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"进程上下文切换","slug":"进程上下文切换","date":"2025-01-14T02:14:54.000Z","updated":"2025-01-15T03:41:16.811Z","comments":true,"path":"posts/进程上下文切换.html","permalink":"https://www.cdfy.top/posts/%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.html","excerpt":"","text":"进程由哪些部分组成？进程上下文又由哪些部分组成？ 进程的组成 进程控制块（Program control block）（灵魂） 建立进程——建立PCB 撤销PCB——销毁进程 程序（躯体） 代码（code） 数据（data） 堆和栈（stack和heap）（栈：保存返回点、参数、返回值、局部变量堆：动态变量） 进程的地址空间 内核空间1G，用户空间3G 一般来说进程的地址空间指的是用户空间 进程详细的组成部分 进程的上下文： 物理实体（代码和数据，在地址空间） 支持进程运行的环境（PCB、内核栈、reg） 具体来说： 进程的程序块、数据块、运行时的堆和用户栈等组成的用户空间信息是用户级上下文，也就是地址空间 寄存器（reg）是硬件上下文（寄存器上下文），即进程的现场信息 PCB、内核栈等内核信息是系统级上下文 进程上下文切换： 总的来说，下降进程的上下文保存，上升进程中曾经被保存的上下文重新放到被执行的环境中。 在进程上下文切换过程中，OS把换下进程的寄存器上下文保存到系统级上下文（理论上在PCB，实际上PCB很小因此保存在内核栈中，通过stack指针找到） 用户级上下文和系统级上下文一起构成了一个进程的整个存储器映像 何时发生进程上下文切换？ 下降进程自身造成切换/外界强制下降进程和上升进程切换 注意，要和CPU上下文区分开，CPU的上下文切换分为几种场景：进程上下文切换、线程上下文切换、中断上下文切换 系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。 系统调用过程通常称为特权模式切换，而不是进程上下文切换，进行的是线程上下文切换 下降进程的现场和断点保存在哪里？是PCB吗？ 现场就是寄存器，断点就是PC寄存器。前面已说，理论上在PCB，实际上在内核栈 用户栈和内核栈（中断栈） 每个进程（线程）两个栈： tip：因为上下文切换是由中断驱动的，所以内核栈也叫中断栈。不过IA32将内核栈和中断栈分开，ARM体系结构两者完全一样 CPU硬件的中断响应 基本流程 关中断（“中断允许位”自动清0）：使CPU处于禁止中断状态，以防止新中断破坏SP、断点(PC)、程序状态字（PSW）等 保存断点和中断状态：将用户栈指针、断点、程序状态字（PSW）保存到内核栈 SP(SS:ESP) PC(CS:EIP) PSW,在IA-32中是EFLAGS寄存器 为什么要先保存SP? 总的来说，SP只有一个且SP首先发生变化 因为下降进程，它的硬件上下文要保存到PCB或是内核栈中，既然要保存到内核栈，SP就必须由本来用户态时指向用户栈，而改为指向内核栈，这说明SP首先发生变化，故而在将硬件上下文保存到内核栈时，首先要保存SP。之所以知道内核栈的位置，以linux的PCB，即task_struct为例，PCB中有指向本进程内核栈的指针，可以通过PCB找到内核栈 识别中断事件，得到“中断类型号”，根据此号，到中断向量表中读取对应的中断服务程序的入口地址 中断向量表 具体流程: 中断发生前： 中断发生时： 总结 shell进程和hello进程的例子 进程切换必须由操作系统接管控制权 shell里面运行一个hello程序 进程切换还需要改变当前进程空间 模式切换：CPU还是在同一进程中运行或在在中断上下文时，因此还需要改变进程空间 保存当前进程的硬件上下文，对Linux系统而言，硬件上下文大部分（SP/PC/PSW等）保存在struct thread_struct thread中，通用寄存器（eax/ebx）保存在内核栈 修改当前进程的PCB, 比如将其运行状态由运行态改为就绪或者等待，并将该PCB加入相关队列 调度另外一个进程 修改被调度进程的PCB, 状态改为运行（系统上下文） 将“当前进程”的存储管理数据改为被调度进程的存储管理（页表、TLB）（用户级上下文） 恢复新进程的硬件上下文，让PC指向新进程代码","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Redis缓存场景","slug":"Redis缓存场景","date":"2025-01-13T16:26:49.000Z","updated":"2025-01-18T16:47:28.974Z","comments":true,"path":"posts/Redis缓存场景.html","permalink":"https://www.cdfy.top/posts/Redis%E7%BC%93%E5%AD%98%E5%9C%BA%E6%99%AF.html","excerpt":"","text":"介绍旁路缓存和缓存异常的场景 旁路缓存(Cache-Aside) Cache Aside Pattern 中服务端需要同时维系 db 和 cache，并且是以 db 的结果为准 读策略： 从缓存中读取数据；如果缓存命中，则直接返回数据；如果缓存不命中，则从数据库中查询数据；查询到数据后，将数据写入到缓存中，并且返回给用户 写策略： 更新数据库Mysql中的记录,然后删除Redis中的缓存记录 场景： 举个例子，假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致 为什么「先更新数据库再删除缓存」不会有数据不一致的问题？ 假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中 最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。 从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，但是在实际中，这个问题出现的概率并不高 因为缓存的写入通常要远远快于数据库的写入 Cache Aside 策略适合读多写少的场景，不适合写多的场景 缓存穿透 用户访问的数据既不在缓存中，也不在数据库中 解决： 回写特殊值：缓存未命中且数据库也没有，在Redis缓存中设置一个特殊值表示数据不存在。会消耗内存 布隆过滤器：由初始值都为0的位图数组和N个哈希函数组成 流程： 采用N个哈希函数运算得到N个哈希值 将这N个哈希值对位图数组长度取模，得到每个哈希值在数组中的位置 在N个对应位置设置成1 查询的时候，只要对于位置的值全是1就表示存在。因此过滤器查询到这个数据，数据库不一定存在。如果查询不到数据库一定不存在 限流策略：采取令牌桶算法或者漏桶算法，对这些数据进行限流 缓存击穿 缓存中的某个热点数据过期 解决： 设置热点数据的热度时间窗口，在这个时间内如果数据被频繁访问，将缓存时间延长 使用互斥锁或分布式锁，只允许一个线程去查询数据，避免多个线程同时查询数据库压力过大 热点数据缓存永不过期 异步更新缓存，减少对数据库的直接访问，并且不会阻塞请求的响应 缓存雪崩 大量缓存数据在同一时间过期或者Redis宕机 大量缓存数据在同一时间过期的解决： 设置缓存过期的随机过期时间 使用互斥锁或分布式锁，只允许一个线程去查询数据，避免多个线程同时查询数据库压力过大 数据预热，提前将热点数据加载到缓存 后台更新缓存，业务不再复制更新缓存，也不设置有效期，而让缓存“永久有效”，将更新缓存的工作交给后台线程定时更新 数据库优化，提升数据库的性能，增加数据库的容量，以应对大量请求导致的数据库压力 Redis宕机的解决： 服务熔断或者限流策略：暂停业务对缓存的访问，如果Redis宕机则直接返回错误不访问数据库。但是这样做会导致业务无法正常工作。也可以启动限流策略，只接受少量部分的请求 提供缓存本身的可用性：通过主从节点的构建Redis缓存高可靠集群","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"Redis分布式锁","slug":"Redis分布式锁","date":"2025-01-13T15:05:51.000Z","updated":"2025-01-18T16:10:22.037Z","comments":true,"path":"posts/Redis分布式锁.html","permalink":"https://www.cdfy.top/posts/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html","excerpt":"","text":"什么是分布式锁 分布式锁是实现分布式系统之间共享资源的一种方式 Redis实现分布式锁的要点 加锁： 12345set lock_key owner nx px n /* 不能用setnx，因为setnx不能带过期参数 px n 表示设置过期时间是n秒 */ 解锁： 先判断owner是否为加锁客户端，是的话才能将lock_key删除 采用lua脚本让两个操作变成一个原子操作： 123456// 先判断owner是否为加锁客户端if redis.call(&quot;get&quot;, KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;, KEYS[1]) // 将lock_key删除else return 0end 为什么需要owner 存在服务A释放掉服务B的锁的可能： 比如服务A获取了锁，由于业务流程比较长，耗时久，导致锁过期。这时候服务B获取了锁，准备去执行，这个时候服务A恢复了过来并做完了业务，就会释放锁，但是业务B还在执行。 lua一定能保证原子性？ lua本身不具有原子性，上面提到的用lua脚本保证原子性是因为Redis是单线程的，一个流程放进lua来执行，相当于是打包在一起，Redis执行他的流程不会被其他请求打断，所以保证了原子性 Redis分布式锁优缺点 优点： 性能高效：选择缓存实现 实现方便：Redis提供了setnx方法 避免单点故障：Redis是跨集群部署 缺点： 超时时间不好设置 Redis主从复制的数据是异步复制的，这样导致分布式锁不可靠：Redis主节点获取到锁后，没有同步到其他节点，在主节点宕机后，此时新的节点依然可以获取到锁，所以多个应用服务获取到了锁 Redis分布式锁的超时时间怎么设置 基于续约的方式设置超时时间。先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间， 比如Redisson的看门狗机制。 当然也会设置一个最大续约次数，避免因为服务异常导致无限续约，锁得不到释放 Redisson的看门狗机制 看门狗机制是Redission提供的一种自动延期机制，这个机制使得Redission提供的分布式锁是可以自动续期的 1private long lockWatchdogTimeout = 30 * 1000; //看门狗机制提供的默认超时时间是30*1000毫秒，也就是30秒 123public boolean tryLock(long waitTime, TimeUnit unit) throws InterruptedException &#123; return tryLock(waitTime, -1, unit);&#125; 在Redis中，锁的waiiTime表示等待获取锁的时间，而leaseTime表示锁的持有时间。 当一个线程或进程尝试获取锁时，如果锁已被其他线程或进程持有，则会等待一段时间（waitTime）后再次尝试获取锁。 如果在这段时间内锁被释放，则当前线程或进程可以成功获取锁，否则需要等待下一次尝试。 一旦锁被某个线程或进程获取成功，该线程或进程拥有锁的持有权，持有时间为leaseTime 看门狗流程： 在获取锁的时候，不能指定leaseTime或者只能将leaseTime设置为-1，这样才能开启看门狗机制。 在tryLockInnerAsync方法里尝试获取锁，如果获取锁成功调用scheduleExpirationRenewal执行看门狗机制 在scheduleExpirationRenewal中比较重要的方法就是renewExpiration，当线程第一次获取到锁（也就是不是重入的情况），那么就会调用renewExpiration方法开启看门狗机制 在renewExpiration会为当前锁添加一个延迟任务task，这个延迟任务会在10s后执行，执行的任务就是将锁的有效期刷新为30s（这是看门狗机制的默认锁释放时间） 并且在任务最后还会继续递归调用renewExpiration 看门狗的作用，考虑以下三种情况： 如果没有设置锁的过期时间，单靠逻辑来释放锁，就会出现获取锁的节点宕机时，锁没有释放，造成死锁 如果设置了某个过期时间，在没有宕机的情况下，线程发生了阻塞，就会导致锁过期自动释放，带来一些其他的问题 如果设置了看门狗，在没有宕机时，如果发生了阻塞，那么看门狗就能一直给线程续时间；如果宕机了，看门狗不起作用，过了有效期之后就会自动释放掉锁，不会造成死锁 底层源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160private Long tryAcquire(long waitTime, long leaseTime, TimeUnit unit, long threadId) &#123; return get(tryAcquireAsync(waitTime, leaseTime, unit, threadId));&#125;private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId) &#123; if (leaseTime != -1L) &#123; return this.tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; else &#123; //如果获取锁失败，返回的结果是这个key的剩余有效期 RFuture&lt;Long&gt; ttlRemainingFuture = this.tryLockInnerAsync(waitTime, this.commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); //上面获取锁回调成功之后，执行这代码块的内容 ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123; //不存在异常 if (e == null) &#123; //剩余有效期为null if (ttlRemaining == null) &#123; //这个函数是解决最长等待有效期的问题 this.scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture; &#125;&#125;&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); return evalWriteAsync(getName(), LongCodec.INSTANCE, command, // 锁不存在，则往redis中设置锁信息 &quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + // 锁存在 &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;, Collections.singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125;private static final ConcurrentMap&lt;String, ExpirationEntry&gt; EXPIRATION_RENEWAL_MAP = new ConcurrentHashMap&lt;&gt;();private void scheduleExpirationRenewal(long threadId) &#123; ExpirationEntry entry = new ExpirationEntry(); //这里EntryName是指锁的名称 ExpirationEntry oldEntry = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.putIfAbsent(this.getEntryName(), entry); if (oldEntry != null) &#123; //重入 //将线程ID加入 oldEntry.addThreadId(threadId); &#125; else &#123; //将线程ID加入 entry.addThreadId(threadId); //续约 this.renewExpiration(); &#125;&#125;private void renewExpiration() &#123; //先从map里得到这个ExpirationEntry ExpirationEntry ee = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName()); if (ee != null) &#123; //这个是一个延迟任务 Timeout task = this.commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123; //延迟任务内容 public void run(Timeout timeout) throws Exception &#123; //拿出ExpirationEntry ExpirationEntry ent = (ExpirationEntry)RedissonLock.EXPIRATION_RENEWAL_MAP.get(RedissonLock.this.getEntryName()); if (ent != null) &#123; //从ExpirationEntry拿出线程ID Long threadId = ent.getFirstThreadId(); if (threadId != null) &#123; //调用renewExpirationAsync方法刷新最长等待时间 RFuture&lt;Boolean&gt; future = RedissonLock.this.renewExpirationAsync(threadId); future.onComplete((res, e) -&gt; &#123; if (e != null) &#123; RedissonLock.log.error(&quot;Can&#x27;t update lock &quot; + RedissonLock.this.getName() + &quot; expiration&quot;, e); &#125; else &#123; if (res) &#123; //renewExpirationAsync方法执行成功之后，进行递归调用，调用自己本身函数 //那么就可以实现这样的效果 //首先第一次进行这个函数，设置了一个延迟任务，在10s后执行 //10s后，执行延迟任务的内容，刷新有效期成功，那么就会再新建一个延迟任务，刷新最长等待有效期 //这样这个最长等待时间就会一直续费 RedissonLock.this.renewExpiration(); &#125; &#125; &#125;); &#125; &#125; &#125; &#125;, this.internalLockLeaseTime / 3L, //这是锁自动释放时间，因为没传，所以是看门狗时间=30*1000,也就是10s TimeUnit.MILLISECONDS); //时间单位 ee.setTimeout(task); //给当前ExpirationEntry设置延迟任务 &#125;&#125;// 刷新等待时间protected RFuture&lt;Boolean&gt; renewExpirationAsync(long threadId) &#123; return evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end; &quot; + &quot;return 0;&quot;, Collections.singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125;//最后，在释放锁的时候，就会关闭所有的延迟任务public RFuture&lt;Void&gt; unlockAsync(long threadId) &#123; RPromise&lt;Void&gt; result = new RedissonPromise(); RFuture&lt;Boolean&gt; future = this.unlockInnerAsync(threadId); future.onComplete((opStatus, e) -&gt; &#123; //取消锁更新任务 this.cancelExpirationRenewal(threadId); if (e != null) &#123; result.tryFailure(e); &#125; else if (opStatus == null) &#123; IllegalMonitorStateException cause = new IllegalMonitorStateException(&quot;attempt to unlock lock, not locked by current thread by node id: &quot; + this.id + &quot; thread-id: &quot; + threadId); result.tryFailure(cause); &#125; else &#123; result.trySuccess((Object)null); &#125; &#125;); return result;&#125;void cancelExpirationRenewal(Long threadId) &#123; //获得当前这把锁的任务 ExpirationEntry task = (ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName()); if (task != null) &#123; //当前锁的延迟任务不为空，且线程id不为空 if (threadId != null) &#123; //先把线程ID去掉 task.removeThreadId(threadId); &#125; if (threadId == null || task.hasNoThreads()) &#123; //然后取出延迟任务 Timeout timeout = task.getTimeout(); if (timeout != null) &#123; //把延迟任务取消掉 timeout.cancel(); &#125; //再把ExpirationEntry移除出map EXPIRATION_RENEWAL_MAP.remove(this.getEntryName()); &#125; &#125;&#125; Redis如何解决集群情况下分布式锁的可靠性 采用Redlock（红锁）：让客户端和多个独立的Redis节点依次请求加锁，如果客户端能和半数以上的节点成功完成加锁操作，那么我们任务客户端成功获取到了分布式锁，否则获取失败 流程： 客户端获取到当前时间T1 客户端依次向N个Redis节点执行加锁操作，加锁操作使用set命令，带上nx，px和客户端的唯一标识。如果某个节点发生了故障，为了保证Redlock能继续运行，需要给 加锁操作设置一个超时时间（远小于锁的过期时间） 一旦客户端从超过半数的Redis节点上获取到了锁，就再次获取当前时间T2 如果T2 - T1 &lt; 锁的过期时间，否则获取失败 可以发现，需要满足两个条件： 客户端从超过半数的Redis节点上获取到了锁 如果T2 - T1 &lt; 锁的过期时间","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"Redis - 数据库","slug":"Redis-数据库","permalink":"https://www.cdfy.top/tags/Redis-%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Hello World","slug":"hello-world","date":"2025-01-13T13:40:58.000Z","updated":"2025-01-15T03:38:14.074Z","comments":true,"path":"posts/hello-world.html","permalink":"https://www.cdfy.top/posts/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Redis过期删除策略和内存淘汰策略","slug":"Redis过期删除策略和内存淘汰策略","date":"2025-01-13T12:44:29.000Z","updated":"2025-01-18T16:10:21.269Z","comments":true,"path":"posts/Redis过期删除策略和内存淘汰策略.html","permalink":"https://www.cdfy.top/posts/Redis%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.html","excerpt":"","text":"过期删除策略 设置过期时间 只对key设置 1234expire key n // key在n秒后过期pexpire key n // key在n毫秒后过期expireat key n // key在时间戳n秒的时刻过期pexpireat key n // key在时间戳n毫秒的时刻过期 创建key的时候设置 123set key value ex n // 创建key，并且key在n秒后过期set key value px n // 创建key，并且key在n毫秒后过期set key n value // 创建key，并且key在时间戳n秒的时刻过期 查看某个key的存活时间 1ttl key 判定key是否过期 1234typedef struct redisDb &#123; dict *dict; /* 数据库键空间，存放着所有的键值对 */ dict *expires; /* 键的过期时间 */ .... &#125; redisDb; 过期字典数据结构： key 是一个指针，指向某个键对象 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间 判断策略： 字典实际上是哈希表，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找 当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中： 如果不在，则正常读取键值； 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。 过期键删除策略 定时删除：给key创建过期时间的同时创建一个定时器，在过期时间来临的时候进行主动删除。好处是删除及时使得内存空间释放，坏处是定时器占用CPU时间 惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该key。好处是占用CPU时间少，坏处是容易造成内存泄漏 定期删除：每隔一段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。平衡了CPU和内存占用 Redis采用的是最后两种，惰性删除和定期删除组合使用 Redis定期删除的流程 从过期字典中随机抽取 20 个 key 检查这 20 个 key 是否过期，并删除已过期的 key 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查 内存淘汰策略 有哪些内存淘汰策略 noevction：不淘汰任何数据，如果运行内存超过了最大设置内存，会不允许写入 volatile：针对过期键 lru：淘汰最久未访问到的数据 lfu：淘汰使用频率最少的数据 random：随机淘汰 ttl：淘汰最久的过期键 allkeys：针对所有键 lru：淘汰最久未访问到的数据 lfu：淘汰使用频率最少的数据 random：随机淘汰 Redis的LRU算法 LRU，最近最久未使用算法：记录了每个key的最近访问时间，每次淘汰最久这个时间的key，但是redis的lru不是标准的，做了优化 优化： 标准lru需要维护双链表，开销很大，所以redis采用的是近似LRU算法 具体的是每次随机采样n个key，默认值是5，然后按照时间戳淘汰最久的那个。如果淘汰后内存还是不足继续随机采样淘汰。在3.0之后，redis LRU还维护了淘汰池，池中的数据按照访问时间进行排序。第一次随机选取的key都会放入池中，每次淘汰池中最久访问的key。 随后每次选取的key只有空闲时间（指的是没有访问到的时候）大于池中空间时间最小的key，才能放入其中。当池子装满了，需要新的key放入的时候，就将池子中最大的key淘汰 Redis的LFU算法 LRU 算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染 所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些 LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下： 123456typedef struct redisObject &#123; ... // 24 bits， 用于记录对象的访问信息 unsigned lru:24; ... &#125; robj; Redis对象头中的lru字段，在LRU算法下和LFU算法下使用方式并不相同: 在 LRU 算法中，Redis对象头的24bits的lru字段是用来记录key的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的lru字段记录的值，来比较最后一次key的访问时间长，从而淘汰最久未被使用的key 在 LFU 算法中，Redis对象头的24bits的lru字段被分成两段来存储，高16bit存储ldt(Last Decrement Time)，低8bit存储logc(Logistic Counter) lfu字段： ldt:用来记录key的访问时间戳； logc:用来记录key的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的key的logc初始值为5 logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 logc 会随时间推移而衰减的。 在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大 （ldt的作用），那么衰减的值就越大，这样实现的 LFU 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。 对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"Redis持久化","slug":"Redis持久化","date":"2025-01-13T11:27:00.000Z","updated":"2025-01-18T16:27:45.035Z","comments":true,"path":"posts/Redis持久化.html","permalink":"https://www.cdfy.top/posts/Redis%E6%8C%81%E4%B9%85%E5%8C%96.html","excerpt":"","text":"Redis的持久化方式有哪些 Redis持久化有两种方式：RDB（Redis DataBase）和AOF（Append Only File） RDB：RDB文件是一个经过压缩的二进制文件 AOF：AOF则是以追加的方式记录Redis执行的每一条写命令 Redis重启时加载持久化文件 RDB和AOF的区别 文件类型：RDB生成的是二进制文件（快照），AOF生成的是文本文件（追加日志） 安全性：缓存宕机时，RDB容易丢失较多的数据，AOF根据策略决定（默认的everysec可以保证最多有一秒的损失） 文件恢复速度：由于RDB是二进制文件，恢复比AOF快 操作的开销：每一次RDB保存都是一次全量保存，操作比较重，通常至少5分钟保存一次。而AOF的刷盘是追加操作，操作比较轻，通常设置为每一秒进行一次刷盘 RDB和AOF选哪种比较好 从业务需要来看，如果我们可以接受分钟级别的丢失，可以选择RDB。如果我们尽量让数据安全，可以考虑AOF混合持久化， 从持久化理论来看，始终开启快照是一个推荐，这也是官方默认开启RDB而不开启AOF 什么是AOF混合持久化 使用RDB持久化函数，将内存数据写入到新的AOF文件中（数据格式也是RDB） 而重写期间新的命令追加到新的AOF中（数据格式是AOF） 新的AOF文件包含RDB格式和AOF格式的数据 RDB的触发时机 调用save和bgsave命令 根据我们的配置周期决定 redis关闭前 主从复制第二阶段：主服务器全量复制RDB文件发送给从服务器 客户点执行清空命令FLUSHALL save和bgsave的区别 save：会阻塞主进程，客户端无法连接redis，等SAVE完成后，主进程才开始工作，客户端可以连接 bgsave：是fork一个save的子进程，在执行save过程中，不影响主进程，客户端可以正常链接redis，等子进程fork执行save完成后，通知主进程，子进程关闭。bgsave采取的是写时复制。 子进程写数据到临时的RDB文件，写完之后替换旧的RDB文件 AOF的触发时机 Redis关闭的时候 每一次事件循环的时候 通过配置指令关闭AOF的时候 AOF重写流程 子进程读取Redis DB中的数据以字符串命令的格式（也可以看作AOF格式）写入到新AOF中 如果有新数据，由主进程将数据写入到AOF重写缓冲区（aof_rewrite_buf） 当子进程完成重写操作后，主进程通过管道将AOF重写缓冲区数据传输给子进程，子进程追加到AOF文件中 AOF的不足 额外CPU的开销： 如果有新数据，由主进程将数据写入到AOF重写缓冲区 进程通过管道将AOF重写缓冲区数据传输给子进程 子进程追加到AOF文件中 额外内存的开销： 在重写的时候，Redis不仅将新的操作记录在原有的AOF缓冲区，还记录在AOF重写缓冲区 额外的磁盘开销： 在重写的时候，AOF缓冲需要刷入旧的AOF日志，AOF重写缓冲也需要刷入新的AOF日志，导致在重写的时候多了一份数据 但是Redis在7.0做了优化？下一个问答 Redis7.0对AOF做了哪些优化 原来的AOF重写缓存被移除，采用 MP-AOF（Multi Part AOF），即多部件AOF。将原来的一个AOF变成了多个AOF，由manifest（追踪管理AOF文件）来管理。重写的时候还是fork一个子进程来对Base AOF重写 Base AOF：重写之前的命令 Incr AOF：追加新的命令 AOF缓冲区和AOF重写缓冲区的区别 AOF缓冲区:是正常使用AOF作为数据落地中间地带，所有的数据先到AOF缓冲区再到AOF文件中。 AOF重写缓冲区：是AOF重写时，redis还要继续接收数据，这个数据就写到AOF重写缓冲区，当AOF重写ok时，主进程在把AOF重写缓冲区的数据写到AOF缓冲区，最后fsync到AOF文件中","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"Redis线程模型","slug":"Redis线程模型","date":"2025-01-13T10:52:47.000Z","updated":"2025-01-18T16:09:23.189Z","comments":true,"path":"posts/Redis线程模型.html","permalink":"https://www.cdfy.top/posts/Redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.html","excerpt":"","text":"Redis线程是单线程还是多线程 Redis核心处理一直都是单线程，但是其他处理模块也会有一些多线程、多进程的功能 网络I/O解包从6.0开始是多线程 某些异步流程从4.0开始用的是多进程，比如UNLIKE、FLUSHALL ASYNC等非阻塞的删除操作 Redis为什么用单线程做核心处理 首先如果引用多线程，主要是希望利用多核的性能，但是Redis是内存k-v存储，一般不会很慢。真正影响Redis性能的是网络I/O 其次多线程的上下文切换、同步机制开销等成本，会影响Redis的性能 Redis单线程性能如何 性能很好，普通机器1s10多万的读性能，几万的写性能 redis-benchmark测试命令： 1redis-benchmark -h 127.0.0.1 -p 6379 -t set,get -n 10000 -q 为什么Redis单线程性能还这么快 基于内存操作：Redis是内存k-v存储 高效的数据结构：依赖String、List、Hash等高效的数据结构 采用单线程：没有多线程上下文切换、锁竞争等问题 I/O多路复用：Redis的瓶颈在I/O而不是CPU，多路复用同时监听多个socket，根据socket上的事件来选择对应的处理器进行处理 Redis6.0引入多线程是什么 Redis的瓶颈在I/O而不是CPU，但随着互联网的发展，请求量巨大的时候单线程在同步读写I/O的时间（读写客户端socket的I/O），单核CPU也可能处理不过来。 因此针对核心处理流程中的解包、发包这两个CPU耗时操作，进行了多线程优化 Redis6.0多线程是默认关闭的，如果需要开启可以在redis.conf中修改。这么做的目的是首先为了兼容以前的，因为很多人认为Redis是单线程。其次是多线程不是必要的，大部分情况下够用","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"从Java线程池到阻塞队列","slug":"从Java线程池到阻塞队列","date":"2025-01-13T10:12:26.000Z","updated":"2025-01-18T11:57:52.399Z","comments":true,"path":"posts/从Java线程池到阻塞队列.html","permalink":"https://www.cdfy.top/posts/%E4%BB%8EJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%B0%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97.html","excerpt":"","text":"为什么要用线程池 降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁造成的消耗 提高响应速度：当任务到达时，任务可以不需要等到线程创建就能立即执行 方便管理线程：线程是稀缺资源，如果无条件地创建，不仅会消耗资源，还会降低线程的稳定性，使用线程池可以统一分配、调优和监考 线程池的核心参数 默认线程工厂（省略参数）创建线程池： ThreadPoolExecutor继承自AbstractExecutorService，AbstractExecutorService实现了ExecutorService接口 123456public class Client &#123; public static void main(String[] args) &#123; ThreadPoolExecutor Pool = new ThreadPoolExecutor(8, 8, 2, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(4),new ThreadPoolExecutor.AbortPolicy()); &#125;&#125; corePoolSize：核心线程的数量 maximumPoolSize：线程池能创建的最大线程个数 keepAliveTime：空闲线程存活时间 unit：时间单位 workQueue：用于保存任务的阻塞队列 threadFactory：创建线程的工程类 hadler：饱和策略 自定义线程工厂创建线程池： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ThreadPool &#123; private static ExecutorService pool; public static void main(String[] args) &#123; pool = new ThreadPoolExecutor(2, 4, 1000, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5), /* ThreadFactory接口 ThreadFactory接口很简单，源码如下： public interface ThreadFactory &#123; Thread newThread(Runnable r); &#125; */ //自定义线程工厂 new ThreadFactory() &#123; public Thread newThread(Runnable r) &#123; System.out.println(&quot;线程&quot;+r.hashCode()+&quot;创建&quot;); //线程命名 Thread th = new Thread(r,&quot;threadPool&quot; + r.hashCode()); return th; &#125; &#125;, new ThreadPoolExecutor.CallerRunsPolicy()); for(int i = 0;i &lt; 10; i++) &#123; pool.execute(new ThreadTask()); &#125; &#125;&#125;public class ThreadTask implements Runnable&#123; public void run() &#123; //输出执行线程的名称 System.out.println(&quot;ThreadName:&quot; + hread.currentThread().getName()); &#125;&#125;/* 线程118352462创建 线程1550089733创建 线程865113938创建 ThreadName:threadPool1550089733 ThreadName:threadPool118352462 线程1442407170创建 ThreadName:threadPool1550089733 ThreadName:threadPool1550089733 ThreadName:threadPool1550089733 ThreadName:threadPool865113938 ThreadName:threadPool865113938 ThreadName:threadPool118352462 ThreadName:threadPool1550089733 ThreadName:threadPool1442407170/* 常见线程池的区别以及特点 创建方法： 12345public class Client &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); &#125;&#125; tip: 到这里可以看到只有ThreadPoolExecutor类和ExecutorService类被使用，没有ThreadPool类 newCachedThreadPool： 特点：newCachedThreadPool创建一个可缓存的线程池，如果当前线程池的长度超过了处理的需要，它可以灵活的回收空闲的线程，当需要添加的时候可以灵活的添加 缺点：maximumPoolSize被设置为Inter.MAX_VALUE，可能会造成OOM newFixedThreadPool： 特点：创建一个定长的线程池，可控制线程最大并发数，超出的任务会在线程中等待 缺点：线程数量是固定的，但是阻塞队列是LinkedBlockingQueue，是无界队列，也可能会造成OOM newScheduledThreadPool： 特点：创建一个固定长度的线程，而且支持定时的以及周期性的任务执行，类似Timer 缺点：底层封装了PriorityQueue，同样是无界队列，可能会造成OOM newSingleThreadExecutor： 特点：单线程化的线程池，它会用唯一的工作线程来执行任务。如果这个线程因为异常结束，那么会有一个新的线程来替代它。它必须保证前一项任务完成才能执行后一项。阻塞队列是LinkedBlockingQueue，因此是无界队列，会有OOM的风险 缺点：因为是单线程，高并发下有压力 为什么我们不用Executors默认创建线程池的方法，而直接自己手动去调用ThreadPoolExecutor去创建线程池 Executors 返回的线程池对象的弊端如下： newFixedThreadPool 和 newSingleThreadPool: LinkedBlockingQueue无界队列，允许的请求队列长度为 Integer.MAX_VALUE(无界队列)，可能会堆积大量的请求，从而导致 OOM newCachedThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM newScheduledThreadPool：同样使用无界队列（底层是PriorityQueue），也会堆积大量请求导致OOM 线程池的饱和策略有哪些 ThreadPoolExecutor.AbortPolicy：抛出RejectedExecutionException来拒绝任务的处理 ThreadPoolExecutor.CallerRunsPolicy：调用提交任务的线程运行任务（比如A提交线程，A运行任务）。但是会降低新任务提交速度，影响程序的整体性能 ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉 ThreadPoolExecutor.DiscardOldestPolicy：丢弃掉最早的未处理的任务 线程池原理 判断线程池的核心线程数是不是已满，如果不是则创建一个新的工作线程来执行任务。 如果核心线程数已满，则将提交的任务放在保存任务的阻塞队列中。 如果工作任务队列满了，则创建一个新的线程来执行任务，直到数量到达maximumPoolSize 最后如果达到线程池最大线程数，则采取对应的饱和策略 线程池中execute()和submit()方法有什么区别 相同点： 都可以提交任务到线程池中 不同点： 接受参数：execute只能执行Runnable类型的任务，submit可以执行Runnable和Callable类型的任务 返回值：submit方法可以返回持有计算结果的Future对象，而execute没有 异常处理：submit可以方便处理异常 Java中Executor、Executors和ExecuteService的区别 Executor: 是一个接口，定义了execute方法 123public interface Executor &#123; void execute(Runnable command);&#125; ExecuteService： 是一个接口，继承了Executor。相比Executor，定义了更多的方法，以及可以作为创建的线程池的返回类型 1ExecutorService executor = Executors.newFixedThreadPool(5); Executors: 是一个工具类，继承了Executor，而且集成了很多创建线程池相关的方法，比如可以调用newFixedThreadPool(10)（返回类型是ExecuteService） 1234567891011public class Client &#123; public static void main(String[] args) &#123; Executors.newFixedThreadPool(10).submit(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()); &#125;).start(); &#125; &#125;); &#125;&#125; Executor是最基本的接口，只定义了一个execute方法 ExecuteService是一个高级的接口，实现了Executor并进行了扩展,比如实现了submit方法，以及可以创建固定类型的线程池。这个接口的目的是方便我们使用底层不同的线程池，类似List接口，屏蔽底层差异 Executors是一个工具类，使用这个工具类可以方便的创建线程。让我们可以不用手动地指定线程池的各个参数，比如Executors.newFixedThreadPool(10) 线程池有哪些状态 Running:正常状态，可以接受其他线程 Shutdown：不接受新的任务提交，但是会继续处理等待队列中的任务 Stop：不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程 Tidying：所有的任务都销毁，workerCount（线程数量）为0，线程池在向Tidying状态转换时，会执行钩子方法terminated() Terminated：terminated()方法介绍后，就会变成这个 如何合理分配线程池大小——线程池应对IO密集型和CPU密集型的策略 CPU密集型：也叫计算密集型，其处理器占用率高，也许在某段时间内保持100%占用率。线程配置数大概和CPU核数相当，这样可以使得每个线程在执行任务 IO密集型：大部分的状况是CPU在等I/O (硬盘/内存) 的读/写操作，但CPU的使用率不高。大部分线程在阻塞，故需要多配置线程数，2 * cpu核数 线程池如何实现动态修改 线程池提供了部分setter方法可以设置线程池的参数： 修改线程数，最大线程数，空闲线程停留时间，拒绝策略等 可以将线程池的配置参数放入配置中心，然后直接在配置中心修改 什么时候需要修改？ 需要监考报警策略，获取线程池状态指标，当指标判定为异常后再报警 分析指标原因，评估策略，然后通过上述线程池提供的接口进行修改 既然线程池中使用了阻塞队列，那么什么是阻塞队列，阻塞队列有哪些 阻塞队列支持两个阻塞的插入和删除操作 支持阻塞的插入put方法：当队列满的时候，队列会阻塞插入元素的线程，直到队列不满 支持阻塞的移除take方法：当队列为空的时候，队列会阻塞移除元素的线程，直到队列不为空 阻塞队列： ArrayBlockingQueue：底层使用数组结构，创建时必须指定大小，是有界的 LinkedBlockingQueue：底层使用链表结构，创建时默认大小是Inter.MAX_VALUE，因此是无界的。也可以指定大小成为有界 PriorityBlockingQueue：一个支持优先级排列的队列，可重写自定义类的compareTo方法来指定排序规则 DelayQueue：一个使用优先级队列实现的无界阻塞队列，使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，表示指定多久才能从队列中获得元素 SynchronousQueue：一个不存储元素的队列，每一次put必须等待一个take操作，否则不能添加元素。适用于传递性场景 LinkedTransferQueue：一个由链表结构组成的无界队列，设计了一种生产者和消费者之间传递的机制，称为”transfer“。当生产者调用transfer（e）方法时，它会阻塞直到一个消费者接收该元素 LinkedBlockingDeque：一个由链表结构组成的双端队列 ArrayBlockingQueue和LinkedBlockingQueue的区别 底层实现：ArrayBlockingQueue基于数组，LinkedBlockingQueue基于链表 是否有界：ArrayBlockingQueue有界，LinkedBlockingQueue创建时可以指定大小，默认是Integer.MAX_VALUE，无界 锁是否分离：ArrayBlockingQueue中的锁不分离，生产者和消费者使用同一把锁。LinkedBlockingQueue的锁分离，生产者使用的是putLock，消费者使用的是takeLock，这样可以防止生产者和消费者之间竞争锁 内存占用：ArrayBlockingQueue需要提前分配内存，LinkedBlockingQueue是动态分配内存，会不断占用空间 ArrayBlockingQueue底层源码 属性 12345678final Object[] items; //队列的底层为数组，是个循环数组int takeIndex; //从队列中取元素的索引，用于take、poll、removeint putIndex; //向队列中存放元素的索引，用于put、offer、addint count; //队列中的元素数final ReentrantLock lock; //队列中的锁机制，可重入锁private final Condition notEmpty; //notEmpty条件对象，由lock创建private final Condition notFull; //notFull条件对象，由lock创建transient Itrs itrs = null; //迭代器对象 添加方法 add(E e)（非阻塞方法） 1234567891011121314151617181920212223242526272829303132/*调用了offer(e)方法，成功，返回true，失败，抛出IllegalStateException异常*/ public boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException(&quot;Queue full&quot;); &#125;/** * 在当前put位置插入元素、前进和信号 * Call only when holding lock. 只有在持有锁资源时才调用该方法 */ private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //将队列数组初始化 items[putIndex] = x; //将元素添加到数组里 if (++putIndex == items.length) //如果将要插入的元素索引等于数组的长度，将存放元素的索引重新置为0 putIndex = 0; count++; notEmpty.signal(); //使用条件对象notEmpty通知，唤醒当前等待的线程 &#125; /** * Throws NullPointerException if argument is null. *如果参数为null，则抛出NullPointerException的异常 * @param v the element */ private static void checkNotNull(Object v) &#123; if (v == null) throw new NullPointerException(); &#125; put(E e)（阻塞方法） 12345678910111213141516171819/** * 将指定的元素插入到此队列的末尾，然后等待 * for space to become available if the queue is full. * * @throws InterruptedException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; */ public void put(E e) throws InterruptedException &#123; checkNotNull(e); //判断元素是否为null final ReentrantLock lock = this.lock; //初始化重入锁 lock.lockInterruptibly(); //加锁，以保证在调用put方法时只有一个线程 try &#123; while (count == items.length) //当队列满了，阻塞当前线程，并加入到条件对象notFull的等待队列里面 notFull.await(); //线程阻塞并被挂起，同时释放锁资源 enqueue(e); //调用enqueue方法 &#125; finally &#123; lock.unlock(); //释放锁，让其他线程可以调用put方法 &#125; &#125; offer(E e)（添加方法的具体实现） 123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); //检查队列中的元素是否为空。在这里不允许为空 final ReentrantLock lock = this.lock; //引入重入锁 lock.lock(); //加锁，保证调用offer时只有一个线程 try &#123; if (count == items.length) //如果当前元素的个数等于队列数组的长度，说明队列是满的，添加失败 return false; else &#123;//否则队列不满，调用enqueue(e)方法添加元素，返回true enqueue(e); return true; &#125; &#125; finally &#123;//最后，释放锁，让其他线程可以调用offer方法 lock.unlock(); &#125; &#125; 删除方法 poll()（非阻塞方法） 123456789public E poll() &#123; final ReentrantLock lock = this.lock; //引入重用锁 lock.lock(); //加锁，以保证当前只有一个线程 try &#123;//如果队列为空，则返回null；否则，调用dequeue方法 return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); //释放锁资源，让其他线程可以调用poll方法 &#125; &#125; take()（阻塞方法） 1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly();//加锁，以保证在调用take()方法时只有一个线程 try &#123; while (count == 0) //当队列中元素个数为1，即队列为空时 notEmpty.await(); //阻塞当前线程，并加入到条件对象notEmpty的等待队列里 return dequeue(); //调用dequeue()方法 &#125; finally &#123; lock.unlock(); //释放锁，让其他线程可以调用take()方法 &#125;&#125; remove(Object obj)（删除指定元素） 1234567891011121314151617181920212223242526/* 从队列中删除指定的元素。如果该元素存在，则将该元素从队列中删除，返回true；如果不存在，则返回false*/ public boolean remove(Object o) &#123; if (o == null) return false;//如果指定删除的元素为null，则返回false final Object[] items = this.items; //阻塞队列数组 final ReentrantLock lock = this.lock; //重入锁 lock.lock(); //加锁，以此保证在调用该remove方法时只有一个线程 try &#123; if (count &gt; 0) &#123;//如果队列不为空 final int putIndex = this.putIndex; //往队列中即将要存储的元素的下标 int i = takeIndex; //从队列即将要取出元素的下标//循环遍历阻塞队列中的元素，如果在队列中找到了要删除的元素，则将该元素删除，返回true;否则，返回false。 do &#123; if (o.equals(items[i])) &#123; // removeAt(i); return true; &#125; if (++i == items.length) i = 0; &#125; while (i != putIndex);//结束条件为当前元素索引==最后将要存入队列中的元素的下标 &#125; return false; &#125; finally &#123; lock.unlock();//释放锁资源，让其他线程可以调用remove(e)方法 &#125; &#125; deque()（poll、take的具体实现） 12345678910111213141516171819/** * Extracts element at current take position, advances, and signals.提取元素当前的位置、进展和信号 * Call only when holding lock.在持有锁时才调用 */ private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items;//阻塞队列数组 @SuppressWarnings(&quot;unchecked&quot;) E x = (E) items[takeIndex];//用变量x记录当前要取出的元素 items[takeIndex] = null;//将该元素置为null if (++takeIndex == items.length)//判断是否是最后一个元素 takeIndex = 0; //如果是，将取元素索引置为0，从头开始取 count--;//元素个数-1 if (itrs != null) //迭代遍历队列， itrs.elementDequeued(); notFull.signal();// 使用条件对象notFull通知，比如使用put方法放数据的时候队列已满，被阻塞。这个时候消费了一条数据，队列没满了，就需要调用signal进行通知 return x; &#125; LinkedBlockingQueue底层源码 属性 1234567891011121314151617static class Node&lt;E&gt; &#123; E item; //元素 Node&lt;E&gt; next;//next指针 Node(E x) &#123; //有参构造函数 item = x; &#125; private final int capacity; //容量，默认为 Integer.MAX_VALUE private final AtomicInteger count = new AtomicInteger(); //队列中元素的数量 transient Node&lt;E&gt; head; //头节点 private transient Node&lt;E&gt; last; //尾节点 private final ReentrantLock takeLock = new ReentrantLock(); //拿锁 private final Condition notEmpty = takeLock.newCondition(); //拿锁的条件，队列不为空 private final ReentrantLock putLock = new ReentrantLock(); //放锁 private final Condition notFull = putLock.newCondition(); //放锁的条件 &#125; 添加方法 add(E e)（非阻塞方法） 1234public boolean add(E e) &#123; addLast(e); return true;&#125; put(E e)（阻塞方法） 12345678910111213141516171819202122232425262728public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException();//判断添加的元素是否为null，如果为Null，抛出NullPointerException异常 int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); //构造新的结点 final ReentrantLock putLock = this.putLock; //放锁 final AtomicInteger count = this.count; //元素的个数 putLock.lockInterruptibly(); //放锁加锁，保证在调用put方法的时候只有1个线程 try &#123; while (count.get() == capacity) &#123;//如果队列为满 notFull.await();//阻塞并挂起当前线程 &#125; enqueue(node);//将元素添加到链表的尾部 c = count.getAndIncrement(); //元素个数+1 if (c + 1 &lt; capacity) //如果队列的容量还没有满 notFull.signal(); //在notFull对象上唤醒正在等待的1个线程，表示队列中还有元素可以消费 &#125; finally &#123; putLock.unlock(); //释放放锁，让其他线程可以调用该put方法 &#125; if (c == 0)//由于存在放锁和拿锁，这里可能拿锁一直在消费数据，count会变化。这里的if条件表示如果队列中还有1条数据 signalNotEmpty();//在拿锁的条件对象notEmpty上唤醒正在等待的1个线程，表示队列里还有1条数据，可以进行消费 &#125; //enqueue(Node&lt;E&gt; node)（上面方法用到） private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node; &#125; offer(E e)（添加方法的具体实现，分为offerFirst和OfferLast） 1234567891011121314151617181920212223public boolean offerFirst(E e) &#123; if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; return linkFirst(node); &#125; finally &#123; lock.unlock(); &#125;&#125;public boolean offerLast(E e) &#123; if (e == null) throw new NullPointerException(); Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; return linkLast(node); &#125; finally &#123; lock.unlock(); &#125;&#125; 删除方法 poll()（非阻塞方法） 12345678910111213141516171819202122public E poll() &#123; final AtomicInteger count = this.count; //队列中元素的个数 if (count.get() == 0) //判断该队列是否为空 return null; //如果为空，返回null E x = null; //定义要返回的元素的变量名，初始化为Null int c = -1; final ReentrantLock takeLock = this.takeLock;//拿锁 takeLock.lock();//拿锁加锁，以保证在调用poll()线程的时候只有1个线程 try &#123; if (count.get() &gt; 0) &#123;//判断队列是否为空。如果不为空 x = dequeue();//删除头节点 c = count.getAndDecrement();//元素个数-1 if (c &gt; 1)//如果队列中还有元素 notEmpty.signal();//在拿锁的条件对象notEmpty上唤醒正在等待的线程，表示队列里还有数据，可以再次消费 &#125; &#125; finally &#123; takeLock.unlock();//释放拿锁资源，让其他线程可以调用该poll()方法 &#125; if (c == capacity)//由于存在放锁和拿锁，这里可能放锁一直在添加数据，count会变化。这里的if条件表示如果队列中还可以再插入数据 signalNotFull();//在放锁的条件对象notFull上唤醒正在等待的1个线程，表示队列里还能再次添加数据 return x;//返回删除的元素 &#125; take()（阻塞方法） 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; //队列中元素的个数 final ReentrantLock takeLock = this.takeLock; //拿锁 takeLock.lockInterruptibly(); //拿锁加锁，以保证在调用take()方法的时候只有一个线程 try &#123; while (count.get() == 0) &#123; //如果队列为空 notEmpty.await(); //则将当前线程阻塞并挂起 &#125; x = dequeue(); //否则，删除头节点 c = count.getAndDecrement(); //元素个数-1 if (c &gt; 1) //判断队列中是否还有元素 notEmpty.signal(); //如果有，在拿锁的条件对象notEmpty上唤醒正在等待的线程，表示队列里还有数据，可以再次消费 &#125; finally &#123; takeLock.unlock(); //释放拿锁，以保证其他线程可以调用take()方法 &#125; if (c == capacity) //表示如果队列中还可以再插入数据 signalNotFull(); //在放锁的条件对象notFull上唤醒正在等待的1个线程，表示队列里还能再次添加数据 return x; //返回删除的那个元素&#125; remove(Object o)（删除指定元素） 1234567891011121314151617181920212223242526272829public boolean remove(Object o) &#123; if (o == null) return false; //如果要删除的元素为null，返回false fullyLock(); //remove操作要移动的位置不固定，2个锁都需要加锁 try &#123; for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) &#123; if (o.equals(p.item)) &#123;//判断在队列中是否能找到要删除的对象 unlink(p, trail);//修改节点的链接信息，同时调用notFull的signal方法 ，唤醒等待的线程 return true; &#125; &#125; return false;//如果没有找到，返回false &#125; finally &#123; fullyUnlock();//2个锁解锁 &#125;&#125;//remove()方法中的加锁方法void fullyLock() &#123; putLock.lock(); takeLock.lock();&#125;//remove()方法中的解锁方法void fullyUnlock() &#123; takeLock.unlock(); putLock.unlock();&#125; deque()（poll、take的具体实现） 1234567891011private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Redis数据结构和数据类型","slug":"Redis数据结构和数据类型","date":"2025-01-13T04:36:49.000Z","updated":"2025-01-24T09:22:17.209Z","comments":true,"path":"posts/Redis数据结构和数据类型.html","permalink":"https://www.cdfy.top/posts/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html","excerpt":"","text":"基本结构 在Redis中有一个核心的对象叫做redisObject ，是用来表示所有的key和value的，用redisObject结构体来表示String、Hash、List、Set、ZSet五种数据类型 key和value指向的是redisObject对象 type：标识该对象用的是什么类型（String、List) encoding：编码方式 Redis数据结构 SDS 属性： len：记录了字符串长度，因此获取字符串长度的时候时间复杂度O(1) alloc：分配给字符数组的空间长度。这样在修改字符串的时候，只需要alloc-len来判断剩余空间大小，可以用来判断空间是否满足修改条件，如果不满足就会将SDS扩容。因此不会出现C语言的缓冲区溢出问题 flags：用来表示不同类型的SDS，表示len和alloc的类型不同，进而保存的SDS分配给字节数组的大小不同 buf[]：字节数组，用来保存实际数据。不仅可以保存文本数据，还可以保存二进制数据 Redis底层由C语言实现，那么SDS与C语言字符串对比： O(1)获得字符串长度：因为SDS有len属性 二进制安全：SDS不仅可以保存文本数据，还能保存二进制数据。SDS的使用len属性来判断是否遍历完成，不会管'\\0'的字符 不会发生缓冲区溢出：通过alloc-len来判断剩余空间大小，可以用来判断空间是否满足修改条件，如果不满足就会将SDS扩容。因此不会出现C语言的缓冲区溢出问题 扩容机制： 如果所需的SDS长度小于1MB,则翻倍 + 1 如果所需的SDS长度超过1MB,最后的扩容大小应该是newlen + 1MB + 1 Ziplist（压缩列表） ziplist构成： zlbytes：整个压缩列表占用内存字节数 zltail：压缩表尾部节点距离起始地址多少个字节，也就是列表尾的偏移量 zllen：entry节点的个数 entry：存储数据的部分 zlend：压缩列表的结束点，固定在0xFF entry构成： prevlen：前一个节点的长度，目的是实现从后往前遍历 encoding：记录当前节点实际的类型和长度，类型主要是字符串和整数 data：记录当前节点的实际存储数据，类型和长度由encoding决定 encdoing构成： 如果当前数据是整数，需要1字节 如果当前的数据是字符串，会根据需要使用1、2、5字节的空间 连续更新问题： 压缩列表新增某一个元素或者修改某一个元素，如果空间不够，压缩列表占用的内存空间需要重新分配。当更新的元素较大，会导致后续的prevlen也都要重新分配，从而引起连锁更新的问题 quicklist 在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现 quicklist就是双向链表+ziplist的组合，quicklist链表中的每一个节点是一个压缩列表 解决连锁更新：通过控制链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越小，连锁更新带来的影响就越小，从而性能提升 dictht（哈希表） 属性： dictEntry **table：数组的每一个元素是指向哈希表节点的指针 size：哈希表大小 sizemask：掩码，用于计算索引值 used：哈希表已有的entry个数 哈希冲突： 当两个key不同，但是索引值相同，就会发生冲突 哈希冲突解决（拉链法）： 被分配到同一个哈希桶上的多个节点用一个单项链表连接起来 但是也有缺点，当链表长度过长的时候，查询效率很低 rehash解决链表长度过长： 给哈希表2分配空间，一般比哈希表1大一倍 将哈希表1数据迁移到哈希表2 迁移完成后，哈希表1的空间释放，并把哈希表2设置为哈希表1，然后在新哈希表2创建出一个空白的哈希表，为下次rehash做准备 渐进式rehash解决rehash迁徙过程耗时久： 给哈希表2分配空间，一般比哈希表1大一倍 在rehash期间，每次哈希表元素新增、删除、查找的时候，Redis会执行对应的操作外，还会将哈希表1中索引位置上的所有dictEntry迁移到哈希表2。查找，更新操作会在两个哈希表上进行。redis会先尝试在 ht[0] 中寻找目标键值对，如果没有找到则会在 ht[1] 再次寻找。但是新增操作就不一样了，新增key只会在新的哈希表 ht[1] 上进行，为的是确保 ht[0] 中的已经被清空的单向链表不会新增元素。在 rehash 被触发后，即使没有收到新请求，Redis 也会定时执行一次 rehash 操作，而且，每次执行时长不会超过 1ms，以免对其他任务造成影响 迁移完成后，哈希表1的空间释放，并把哈希表2设置为哈希表1，然后在新哈希表2创建出一个空白的哈希表，为下次rehash做准备 rehash触发条件： 负载因子 = 哈希表已保存的节点数量 / 哈希表大小 当负载因子大于等于1，并且redis没有进行RDB快照和AOF重写的时候，进行rehash 当负载因子大于等于5，说明哈希冲突非常严重，不管也没用RDB快照和AOF重写，都会强制执行rehash intset（整数集合） 属性： encoding：编码方式，比如 INTSET_ENC_INT16，那么contents就是一个int16_t类型的数组 length：集合包含的元素数量 contents：虽然被声明为 int8_t 类型，但是实际上是由保存的数据大小由encoding决定 整数集合升级规则： 当我们将一个新元素加入集合中，如果新元素的类型(int32_t)比现有元素的类型(int16_t)都要长，需要扩宽contents数组的大小。比如现在有3个类型为int16_t的元素，每个都是16位长度，然后往整数集合里面加入一个新元素65535，这个新元素类型用int32_t保存，然后对contents扩容，会在原本的空间的大小之上多出80位（4 * 32 - 3 * 16 = 80），这样就能保证可以存下4个int32_t的元素 扩容完 contents 数组空间大小后，需要将之前的三个元素转换为 int32_t 类型，并将转换后的元素放置到正确的位上面，并且需要维持底层数组的有序性不变：从后往前依次填充，最后再把65535这个元素放到数组末尾 整数集合升级优点： 如果让一个数组保存int16_t、int32_t、int64_t的元素，最好的方式就是用int64_t类型，但是会造成空间的浪费。 整数升级保证了我们只需要int64_t类型的元素再进行扩容，因此可以节约资源内存 最后，整数集合不支持降级 zskiplist（跳表） zskiplist属性： 跳表的头尾节点head，tail（指向zskiplistNode） 跳表的长度length 跳表的最大层数level zskiplistNode属性： ele：SDS结构存储数据 score：节点的分数，浮点型 backward：指向上一个节点的回退指针，支持从表尾向表头遍历，也就是ZREVRANGE命令 level：是个zskiplistLevel数组，zskiplistLevel包含了两个字段，一个是forward，指向下一层能调到哪个节点，span记录了距离下个节点的步数。数据结构就表示每个节点是个多层结构 跳表节点层数设置： 跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN) Redis在创建节点的时候，会生成范围为[0, 1]的随机数，如果这个随机数小于0.25（相当于概率25%），那么层数就增加一层。然后继续生成下一个随机数，直到随机数的结构大于0.25就结束 这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64 为什么用跳表而不用平衡树？ 从内存占用上，跳表比平衡树更灵活：平衡树每个节点包含2个指针，跳表每个节点包含的指针数目为1/（1-p），在redis中p=0.25，平均每个节点包含1.33个指针，内存占用更少 在做范围查询的时候，跳表比平衡树操作更简单：在平衡树中我们找到特定范围的最小值后，还需要以中序遍历的顺序寻找其他不超过大值的节点，所以中序遍历不容易实现。而跳表就很简单，只需要找到最小值后，对第一层的节点进行若干步的遍历即可 在算法实现难度上，跳表更简单。平衡树的插入和删除操作可能引发子树的调整，子树逻辑复杂。而跳表的插入和删除只需要修改相邻的节点，操作简单又迅速 listpack listpack entry构成： encoding：定于元素的编码类型，会对不同长度的整数和字符串进行编码 data：实际存放的数据 len：encdong+data的总长度 将prevlen改成len之后能不能从后往前遍历？ 答案是可以。lpDecodeBacklen函数已经实现了 Redis数据对象 String 字符串对象的内部编码（encoding）有 3 种 ：int、raw和embstr： int：如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型表示，那么这个字符串对象会被保存在redisObject对象的prt中，同时将encoding设置成int embstr(Embedded string 嵌入式字符串)：如果一个字符串对象保存的是字符串，并且这个字符串对象小于等于32字节。那么字符串对象将用SDS表示，同时encoding设置成embstr raw：如果一个字符串对象保存的是字符串，并且这个字符串对象大于32字节。那么字符串对象将用SDS表示，同时encoding设置成raw embstr和raw的区别： embstr和raw都会用SDS来保存值。 embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS 而raw编码会调用两次内存分配函数分别分配redisObject和SDS embstr相比raw好处： embstr编码创建字符串对象只用调用一次内存分配函数，而raw编码需要两次 释放embstr编码的字符串对象同样也只需要调用一次内存释放函数 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存空间，可以更好的利用cpu缓存提升性能 embstr的缺点： 如果字符串的长度需要重新分配空间时，整个redisObject和sds都需要重新分配空间，所以embstr编码的字符串对象实际上是只读的。redis没有为embstr编码的字符串对象编写任何修改的程序。当我们对embstr编码的字符串对象执行修改的命令，实际上是先将编码从embstr转换成raw，再做修改 List 3.2版本之前是双向链表和压缩列表： 如果列表中的元素小于512个，列表每个元素的值都小于64字节，redis会用ziplist存储 否则用双向链表 3.2版本之后： 统一用quicklist 7.0版本之后，统一用listpack Hash 如果哈希类型元素个数小于512个，并且所有值小于64字节，Redis会用ziplist（7.0版本开始采用listpack）底层数据结构 否则用哈希表 Set 如果集合中的元素都是整数且元素个数小于512使用整数集合 否则用哈希表 Zset 如果有序集合元素小于128个，并且每个元素大小小于64字节，使用ziplist（7.0版本开始采用listpack） 否则用skiplist","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"}]},{"title":"JVM","slug":"JVM","date":"2025-01-12T06:22:32.000Z","updated":"2025-01-23T07:37:31.912Z","comments":true,"path":"posts/JVM.html","permalink":"https://www.cdfy.top/posts/JVM.html","excerpt":"","text":"The Java Virtual Machine (JVM) is a crucial component of the Java programming language. It is an abstract computing machine that enables a computer to run Java programs. The JVM is platform-independent, meaning it can run on any device or operating system that has a compatible JVM implementation 总的来说，分为五部分：程序计数器，虚拟机栈，本地方法栈，方法区，堆 程序计数器 什么是程序计数器 程序计数器：是线程私有的，记录当前虚拟机正在执行的线程指令地址。首先实现了代码的基本控制流程，比如顺序、选择、循环等，其次是因为记录了当前线程指令地址，在当前线程下次被切换回来时，可以知道它上次执行到的位置 虚拟机栈 虚拟机栈是什么 虚拟机栈：由很多栈帧组成（一个方法有一个栈帧），每个栈帧包含：局部变量表、操作数栈、动态链接、返回地址等信息 局部变量表：存储当前方法参数和当前方法内部 的局部变量。局部变量表的最小容量用变量槽来表示，其中64位长度的long和double会占用两个变量槽。如果执行的是实例方法，那么当前第0个变量槽存放的是用于传递方法所属对象实例的引用，在方法中可以用“this”来访问。此外，还通过变量槽复用达到减少内存空间的使用，比如当前PC计数器超出的这个变量的作用域，那么这个变量的变量槽就可以被复用 操作数栈：为当前方法运行提供了一个临时计算过程结果的存储 动态链接：在运行期间部分符号引用转变为直接引用，为了支持java多态 返回地址： 遇到方法返回的字节码指令 出现了异常，有异常处理则交给异常处理器，否则抛异常 本地方法栈 本地方法栈是什么 先介绍虚拟机栈，然后：类似虚拟机栈，本地方法栈为java虚拟机提供native方法的服务。native方法一般是由C/C++编写 方法区 方法区： 首先它是虚拟机规范的抽象概念。 他是所有线程共享的内存区域，在hotspot jkd1.8之前，方法区的实现是永久代。而在jdk 1.8，采用的是元空间 对于永久代和元空间主要有以下两个区别： 永久代位于java虚拟机内，元空间位于本地内存。因此永久代受限于JVM可用内存，但是元空间使用的是直接内存，受本地内存的限制，因此内存溢出的可能性更小 永久代本身是面向堆来设计的，所以存储在永久代的对象不是内存连续的，所以需要额外的存储信息和额外的对象查找机制来定位对象，所以比较麻烦。（最开始使用永久代是为了进行一定程度的代码复用） 那么方法区到底存储了什么东西？ 在类加载的第一个阶段，会将类的类型信息加载进入方法区（包括类签名、属性、方法） 运行时常量池：常量池，存储了符号引用和部分直接引用，字面量等信息，运行时常量池主要负责动态解析符号引用，将符号引用转换为直接引用，以及字节码生成的字面量。以及还有一些字符串常量池，在jdk1.8之前字符串常量池在永久代中，1.8时在堆中。因此对于某些方法，比如intern方法，如果目标字符串在字符串常量池中存在，就返回其引用，否则创建并返回其在字符串常量池中的引用，那么在1.8时，由于字符串常量池在堆中，即使字符串常量池中没有对应的字符串对象，也只会创建一个指向堆中的该字符串对象的引用 既然提到了类加载机制，不妨谈谈类加载机制？ 类加载机制是将javac编译产生的.class对象中的二进制数据读入到方法区中的常量池，然后在堆区创建一个此类的class对象，通过这个class对象可以访问到方法区中的类信息 分为加载、链接（验证、准备、解析）、初始化这几个步骤 加载： 通过类的全限定名（包名 + 类型名）获取此类的二进制流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个该类的Class对象，作为方法区类信息的访问入口,方法区中的是klacc 验证： 确保class文件的字节流所包含的class类信息符合虚拟机规范 文件格式验证：字节流是否符合标准 元数据验证：验证数据是否合理，比如所有类应该有父类 字节码验证：验证字节码是否会危害虚拟机，因此java具有安全性 符号引用验证（发生在解析阶段，因此链接不仅仅是准备阶段前）：检查常量池中引用的外部类是否存在，可以正常访问 准备：为类变量分配内存并设置类变量初始值的阶段（局部变量不存在准备阶段，不能被赋值就不能被使用）。如果是final修饰，意味者在Class文件中，该字段的属性表中存在Constantvalue属性，此时初值设置为代码里写的。如果不是，就设置成零值，等到初始化阶段再赋值 解析：虚拟机将常量池的符号引用转化为直接引用 初始化：开始执行类中的java代码，调用类构造器 java中的klass和class jvm加载的字节码，也就是.class文件，被加载到方法区里面，叫Kclass，是一个C++对象，含有类的信息、虚方法表等 JVM在加载了字节码后，在堆里创建的Class对象，这个对象和方法区的Kclass相互指向，也就是说我们可以通过Kclass找到这个对象 我们new 一个对象，对象头里面会有一个指针，指向方法区的Kclass new Object().getClass()流程， 对象头里面的指针–&gt;方法区kClass–&gt;堆Class对象 反射也是拿到堆里的Class对象 所有我们比较两个对象类型是否相等，实际上就是比较两个Class对象是否一样 JVM可以通过Class中的Kclass指针找到真正的Klass，然后再用这个Klass创建一个真正的对象 类加载器有哪些？ 首先类加载器是属于JVM规范，是抽象概念 在规范中类加载器分为Bootstrap ClassLoader和Other，也就是启动类加载器和非启动类加载器 在hotspot实现中，bootstrap classloader是C/C++实现（加载&lt;java_home&gt;/lib），无法作为对象被程序引用。other类包括：extension classloader（加载&lt;java_home&gt;/lib/ext），applicaition classloader（加载&lt;java_home&gt;/java.CLASSPATH）, user classloader（任意来源）。非bootstrap classloader（other类）都采用java来实现，都继承自java.lang.classloader，都可以作为对象被引用。除了user classloader，其他都只能从本地文件中获取字节码来加载，而user classloader可以获取任意来源的字节码。除了bootstrap classloader，其余类加载器后续加载流程都一样，因为都继承了java.lang.classloader, 在底层源码中逻辑都一样并且defineClass方法存在final修饰符，表示无法被重写 类加载模型主要是什么？ 在默认情况下，一个限定名的类只会被一个类加载器加载，这样的话在程序中它就是唯一的，因此需要双亲委派模型 一个类加载器收到一个类的加载请求时，会先给他的父亲类去请求，这样最终一直请求到bootstrap classloader，然后再从上到下，如果父亲类加载器不能被加载，则委派给儿子类，如果没有可以被加载的，则会报ClassNotFoundException错误。越核心的类库会越被上层的类加载器加载，而某限定名的类一旦被加载过了，此后就不会被加载，这样就能有效避免类加载混乱 但是双亲委派模型由于存在设计缺陷，因此也有可能被打破： 因为java类加载器在加载第一个类的时候，这个类所引用的其他类也是由于这个类加载器去加载。这样的话，比如jdbc是没办法实现的，因此需要打破双亲委派模型 打破的情况： 自定义类重写java.lang.loadClass方法，以实现自己的类加载逻辑 OSGi SPI 哪些框架破坏了双亲委派模型？ Tomcat Springboot OSGi 堆 堆的基本结构 堆存放对象实例，可以分为新生代和老年代。新生代又分为伊甸园、from区、to区 也是虚拟机中管理内存的最大一块，被线程共享，物理上不连续（因此速度相比慢，由于cache命中率低），逻辑上连续 堆也可以通过参数-Xms -Xmx设置堆的最小容量和最大容量 同时也是GC的主要地方 详细解释一下GC 为什么要GC? GC就是垃圾回收，java提供的GC可以自动监测对象是否超过作用域从而达到自动回收内存的目的，防止内存占用过多导致内存溢出 可以作为GC roots的对象有哪些？ 虚拟机栈中引用的对象，例如方法堆栈中的参数，局部变量，临时变量等 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中Native方法引用的对象 Java虚拟机内部的引用对象，比如基本数据类型对应的Class对象、线程等 什么情况下会被回收？ 当对象不存活的时候会被回收，判断对象存活与否有两种： 第一点是引用计数法，给对象添加一个引用计数器。当一个对象被引用，计数器就加1，当一个对象被取消引用，就-1。计数器为0的对象是会被回收的。但是有弊端：循环引用造成对象不可能会被回收 第二点是可达性分析，以GC roots为起点，从这些节点向下搜索，通过引用链看能不能找到 如何可达性分析？ 不同的引用类型，主要体现的是对象不同的可达性（reachable）状态和对垃圾收集的影响 分为强引用、软引用、弱引用、虚引用 强引用：只要还有强引用指向该对象，就说明还存活 软引用：只有当JVM内存不足时，才会回收软引用的对象 弱引用：不管内存够不够，都会回收只有弱引用的对象 虚引用：等于没有被引用，在任何时候都可能被回收，目的是为了在对象被垃圾回收时起到一个通知作用 GC根据作用域划分： Minor GC：只是回收新生代 Major GC: 只是回收老年代 Full GC: 整堆回收 Mixed GC: 收集整个新生代和部分老年代的垃圾（目前只有G1 GC会有这种行为） 堆分配策略： 首先大部分情况分配在伊甸园区，如果伊甸园内存不足，触发Minor GC，当然大对象直接进入老年代。接着长期存活的对象进入老年代（在新生代存活时间超过一定阈值的对象，每经过一次Minor GC 都会增长一次年龄） 此外，还有一些机制保证GC: 动态年龄判定以及空间分配担保 动态年龄判定：当Survivor区中相同年龄对象的总和大于Survivor空间的一半时，则年龄大于或等于该年龄的对象可以直接进入老年区，不用直接达到阈值 空间分配担保：在发生Minor GC之前，虚拟机要看老年代最大可用的连续空间是否大于新生代所有的对象空间，如果是，则Minor GC是安全的，否则虚拟机会看老年代最大的连续空间是否大于历次晋升到老年代的平均大小，如果大则担保成功，触发Minor GC。否则，触发Full GC 四大回收算法 标记清除算法：将需要回收的对象标记，然后清除。缺点是会产生内存碎片 复制算法：为了解决内存碎片问题。将内存分为相同大小的两块，每次只使用其中的一块，当其中一块用完了则复制到另一块，并且这一块全部回收。缺点是内存占用大 标记整理算法：和标记清除算法一样，但是不同的是后续不是直接清理，而是让所以存活的对象移动到同一端 分代收集算法：严格来说不是一套理论，而是综合以上三种算法根据不同情况选择不同的回收算法。一般来说，新生代使用复制算法，老年代使用标记清除算法或者标记整理算法 为什么需要Survivor 区？ 如何没有Survivor区，那么会直接进入Old区，这样会导致Old区很快被填满，但是由于虽然一次Minor GC没有回收，但也不会存活几次。因此放在Survivor区可以减少Major GC的发生。当存活年龄达到16次时再进入Old区 Survivor 区为什么需要两个？ 因为一个的话由于标记清除会导致内存碎片问题，但是两个区域的话，将Eden区和From区复制到To区，第二次GC时再交换From和To的职责，将Edge和To区复制到From区。这样永远有一个Survivor区是空的，另一个非空的是无碎片的。为什么不继续分多一点？因为再细分下去，每一块的Survivor的空间会更小，两块综合考虑更好 那么有哪些垃圾回收器？ 主要可以分为四类垃圾收集器： 串行垃圾收集器： serial gc:单线程垃圾收集器，使用时必须先stop the world（进入一个安全点，其他用户线程均阻塞），然后直到他收集结束。采取标记复制算法。通常在单核cpu或较小的应用中去使用 serial old gc:serial gc的老年代版本，单线程垃圾回收，采取标记整理算法 吞吐量优先的垃圾回收器： Parallel gc：并行垃圾回收器.工作在新生代，采用标记复制算法，多线程垃圾回收算法，线程数量与CPU核数相关。以吞吐量优先意味着总的时间花费少 Parallel old gc：并行垃圾回收器.区别在于工作在老年代 响应时间优先 CMS GC：并发垃圾收集器，工作在老年代，如果并发失败，会退化成serial old。采用的是并发标记清除算法 当触发垃圾回收机制时，有以下4个阶段： 1. 初始标记：短暂地stop the world，标记直接与gc roots能直接关联的对象 2. 并发标记：从gc roots开始进行可达性分析，标记存活对象，用户线程不需要暂停，不需要stop the world。由三色标记算法保证 3. 重新标记：由于并发标记阶段可能引用发生了变化，发生错标、漏标，因此需要stop the world来重新标记 4. 并发清理：清理未标记对象，用户线程不需要暂停 整个过程消耗时间最长的是并发标记和并发清除阶段，这两个阶段垃圾收集线程可以和用户线程一起工作。 优点是并发收集，停顿时间短 缺点是标记清除算法，会导致大量内存碎片以及会产生浮动垃圾，因为并发清理阶段还有用户线程在运行，就会产生新的垃圾 ParNew GC:与之配合，工作在新生代，基于复制算法的垃圾回收器 同时注重吞吐量和低延迟的G1垃圾收集器，JDK9默认 G1将堆分为相同大小的分区，每个分区大小是2的幂次方。有4种不同类型的分区，eden，survivor，old，humongous 整体上是标记整理算法，两个区域之间采取的是标记复制算法 整体分为以下几个步骤： 1. 初始标记。暂停其他线程，记录直接与gc roots相连的对象 2. 并发标记。从gc roots开始进行可达性分析，找出要回收的对象，耗时较长，不过可以与用户程序同时执行。 3. 最终标记。需要对其他线程做短暂的暂停，用于处理并发标记阶段对象出现引用变化的区域 4. 筛选回收。对整个分区的回收价值和成本进行排序，然后根据用户所期望的停顿时间来制作回收计划。把回收的分区的存活对象复制到空的分区中，再清理掉整个旧的分区的全部空间。因此也需要stop the world 三色标记算法？ 整个标记过程： 将标记对象分为三种颜色： 白色——该对象没有被标记过（垃圾） 灰色——对象已经被标记过，但他的属性没有被标记完 黑色——对象已经被标记过，他的属性也标记完了 初始时，所有对象都在白色集合里面，然后从gc roots开始进行可达性分析，将gc roots直接引用的对象移动到灰色集合，然后再从灰色集合中根据属性不断再取出新的标记对象，放到灰色集合里面，然后将本对象放到黑色集合里面。如此反复直到没有灰色对象 优点：用于垃圾回收，将stw升级为并发标记。然后避免重复标记，提高了效率 存在的问题： 由于并发标记阶段对象引用发生变化，所以会出现多标和错标的情况（这里的标是标记为黑色或者灰色的意思） 浮动垃圾(多标)：将原本应该被清除的对象，误标记为存活对象。后果是垃圾回收不彻底，不过影响不大，可以在下个周期被回收 对象消失(漏标)：将原本应该存活的对象，误标记为需要清理的对象。后果很严重，影响程序运行，是不可容忍的 漏标必须要同时满足以下两个条件： 赋值器插入了一条或者多条从黑色对象到白色对象的新引用 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用 因此漏标问题一定要解决，对于不同的垃圾回收器处理策略也不一样 增量更新：增量更新破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用时，就将这个新加入的引用记录下来，待并发标记完成后，重新对这种新增的引用记录进行扫描 原始快照 stab：原始快照破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，也是将这个记录下来，并发标记完成后，对该记录进行重新扫描 HotSpot 虚拟机中，不管是新增还是删除，这种记录的操作都是通过写屏障实现的。我们可以将写屏障理解为 JVM 对引用修改操作的一层 AOP，注意它与内存屏障是两个不同的东西 cms：写屏障+增量更新 g1：写屏障+原始快照 stab zgc：读屏障 为什么G1用SATB？CMS用增量更新？ 增量更新：黑色对象新增一条指向白色对象的引用，那么要进行深入扫描白色对象及它的引用对象。 原始快照：灰色对象删除了一条指向白色对象的引用，实际上就产生了浮动垃圾，好处是不需要像 CMS 那样 remark，再走一遍 root trace 这种相当耗时的流程 SATB相对增量更新效率会高(当然SATB可能造成更多的浮动垃圾)，因为不需要在重新标记阶段再次深度扫描被删除引用对象。而CMS对增量引用的根对象会做深度扫描，G1因为很多对象都位于不同的region，CMS就一块老年代区域，重新深度扫描对象的话G1的代价会比CMS高，所以G1选择SATB不深度扫描对象，只是简单标记，等到下一轮GC再深度扫描 什么是跨代引用？ java中不同代存在引用，比如新生代引用老年代 问题：比如在minor gc时，存在老年代指向新生代的引用，但是由于是minor gc，将会产生漏标问题 解决：minor gc时，将整个老年代的对象也加入扫描范围，但是这样做效率太低，因此引入记忆集的数据结构 记忆集是在新生代开辟一个空间来存储一个集合，用来存放老年代对新生代的引用，因此在minor gc时不需要扫描整个老年代，只需要扫描新生代+记忆集。在hotspot中采用一种卡表的方式实现。卡表是使用一个字节数组实现，每个元素对应着其标识的卡页 full gc触发条件？ System.gc() 主动 老年代空间不足 空间分配担保失败 jdk1.7及之前的永久代空间不足","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cdfy.top/tags/JVM/"}]},{"title":"Java常用设计模式","slug":"Java常用设计模式","date":"2025-01-11T12:19:31.000Z","updated":"2025-01-25T07:28:06.706Z","comments":true,"path":"posts/Java常用设计模式.html","permalink":"https://www.cdfy.top/posts/Java%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html","excerpt":"","text":"单例模式 单例模式就是: 在程序运行期间, 某些类有且最多只有一个实例对象 饿汉模式(静态常量) 饥饿模式又称为饿汉模式, 指的是JVM在加载类的时候就完成类对象的创建 123456789101112//饿汉式(静态常量)public class Singleton1 &#123; //构造器私有化，外部不能new private Singleton1() &#123;&#125; //本类创建对象实例 private final static Singleton1 instance = new Singleton1(); //提供一个公有的静态方法，返回对象实例 public static Singleton1 getInstance() &#123; return instance; &#125;&#125; 优点：JVM层面的线程安全。JVM在加载这个类的时候就会对它进行初始化, 因此JVM层面包证了线程安全 缺点：造成空间的浪费 饿汉模式（静态代码块） 1234567891011121314//饿汉式(静态代码块)public class Singleton2 &#123; //构造器私有化，外部不能new private Singleton2() &#123;&#125; //本类创建对象实例 private static Singleton2 instance; static &#123; instance = new Singleton2(); &#125; //提供一个公有的静态方法，返回对象实例 public static Singleton2 getInstance() &#123; return instance; &#125;&#125; 这种方式和上面的方式其实类似，只不过将类实例化的过程放在了静态代码块中，也是在类装载的时候，就执行静态代码块中的代码，初始化类的实例。优缺点和上面是一样的。 饿汉模式（枚举） 1234//枚举public enum Singleton8 &#123; INSTANCE&#125; 枚举类实现单例模式是极力推荐的单例实现模式，因为枚举类型是线程安全的(枚举类也是在JVM层面保证的线程安全)，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。 懒汉模式（线程不安全，不可用） 真正需要的时候再完成类对象的创建 123456789101112//懒汉式(线程不安全)public class Singleton3 &#123; private static Singleton3 instance; private Singleton3() &#123;&#125; //提供一个静态的公有方法，当使用到该方法时，才去创建instance 即懒汉式 public static Singleton3 getInstance() &#123; if (instance == null)&#123; instance = new Singleton3(); &#125; return instance; &#125;&#125; 优点：节省空间 缺点：线程不安全 懒汉模式（线程安全，同步方法，不推荐用） 通过synchronized关键字对获取实例的方法进行同步限制, 实现了线程安全 12345678910111213//懒汉式(线程安全)public class Singleton4 &#123; private static Singleton4 instance; private Singleton4() &#123;&#125; //提供一个静态的公有方法，当使用到该方法时，才去创建instance 即懒汉式 public static synchronized Singleton4 getInstance() &#123; if (instance == null)&#123; instance = new Singleton4(); &#125; return instance; &#125;&#125; 优点：线程安全 缺点：对所有线程的访问都会进行同步操作, 有很严重的性能问题 懒汉模式（线程不安全，同步代码块，不可用） 1234567891011121314//懒汉式(线程安全, 同步代码块)public class Singleton5 &#123; private static Singleton5 instance; private Singleton5()&#123;&#125;; //提供一个静态的公有方法，当使用到该方法时，才去创建instance 即懒汉式 public static Singleton5 getInstance() &#123; if (instance == null)&#123; synchronized(Singleton5.class)&#123; instance = new Singleton5(); &#125; &#125; return instance; &#125;&#125; 这种同步并不能起到线程同步的作用。跟第3种实现方式遇到的情形一致，假如一个线程进入了if (instance == null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例 懒汉模式（线程安全，双重检查, 推荐用） 双重检查锁(Double Checked Locking, 简称DCL)模式 1234567891011121314151617//双重检查public class Singleton6 &#123; private Singleton6() &#123;&#125; private static volatile Singleton6 instance; public static Singleton6 getInstance() &#123; //第一次判断，如果instance不为null，不进入抢锁阶段，直接返回实际 if (instance == null)&#123; synchronized(Singleton5.class)&#123; //抢到锁之后再次判断是否为空 if (instance == null)&#123; instance = new Singleton6(); &#125; &#125; &#125; return instance; &#125;&#125; 在多处理器的共享内存、或者编译器的优化下, DCL模式并不一定线程 —— 可能 (注意: 只是可能出现) 会发生指令的重排序, 出现半个对象的问题 Java中创建一个对象的过程并不是原子性操作，可能会发生指令的重排序（先把这个实例的引用指向地址，再对成员初始化）, 出现半个对象的问题 因此要用volatile关键字修饰instance变量 半对象问题：当一个线程进来的时候，判断对象是否为空？肯定为空，因为还没创建呢，往下执行，拿到锁，继续往下执行，再次判断是否为空？为空，往下执行，在new对象的时候，对象有个半初始化的一个状态，在执行完new的时候，分配了一块空间，成员变量是引用类型那么它的值为null，就在此时，invokespecial和astore 1发生了指令重排序，直接将instance指向了初始化一半还没有调用构造方法的内存空间，这时候第二个线程进来了，判断对象为空吗？不为空，为啥？因为它指向了一个半初始化的一个对象嘛！既然不为空，我就直接返回了这个初始化一半的对象 懒汉式（线程安全，静态内部类，推荐用） 1234567891011//静态内部类public class Singleton7 &#123; private Singleton7() &#123;&#125; //提供一个静态的公有方法，当使用到该方法时，才去创建instance 即懒汉式 private static class SingletonInstance &#123; private static final Singleton7 INSTANCE = new Singleton7(); &#125; public static Singleton7 getInstance() &#123; return SingletonInstance.INSTANCE; &#125;&#125; JVM在加载外部类的过程中, 是不会加载静态内部类的, 只有内部类(SingletonHolder)的属性/方法被调用时才会被加载, 并初始化其静态属性(instance) 优点：避免了线程不安全，利用静态内部类特点实现延迟加载，效率高 破坏单例模式 除枚举方式外, 其他方法都会通过反射的方式破坏单例 反射是通过调用构造方法生成新的对象, 可以在构造方法中进行判断 —— 若已有实例, 则阻止生成新的实例, 12345private Singleton() throws Exception &#123; if (instance != null) &#123; throw new Exception(&quot;Singleton already initialized, 此类是单例类, 不允许生成新对象, 请通过getInstance()获取本类对象&quot;); &#125;&#125; 如果单例类实现了序列化接口Serializable, 就可以通过反序列化破坏单例。可以不实现序列化接口, 或者重写反序列化方法readResolve(), 反序列化时直接返回相关单例对象 1234// 反序列化时直接返回当前实例public Object readResolve() &#123; return instance;&#125; Object#clone()方法也会破坏单例, 即使你没有实现Cloneable接口 —— 因为clone()方法是Object类中的。可以重写clone()方法, 并在其中抛出异常信息“Can not create clone of Singleton class” 工厂模式 简单工厂模式 简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 Factory: 工厂角色 负责根据不同的参数创建不同的实例。 IProduct: 抽象产品角色 所有产品实例的接口，负责描述所有产品实例的行为。 Product(A B ..): 具象产品角色，所有产品的实例，实现了抽象产品定义的代码 示例: 平台做一个机票代购业务，对接了两个供应商A、B，用户选择完机票后，平台拿着机票去供应商下单。下单时根据机票由那个供应商提供去相应的供应商去下单。 定义一个下单接口 123456public interface IVender &#123; /** * 供应商下单方法 */ void order();&#125; 分别实现A、B供应商的下单方法 123456789101112131415public class VendorA implements IVender &#123; @Override public void order() &#123; // 业务逻辑处理 System.out.println(&quot;A供应商下单成功,下单时间&quot; + new Date()); &#125;&#125;public class VendorB implements IVender &#123; @Override public void order() &#123; // 业务逻辑处理 System.out.println(&quot;B供应商下单成功，下单时间：&quot; + new Date()); &#125;&#125; 接着定义一个工厂类，根据传入的不同参数请求，分别创建不同的供应商实例并返回，若碰到无效的参数，则抛出异常 12345678910111213public class VendorFactory &#123; public static IVender createVendor(String type) &#123; switch (type) &#123; case &quot;A&quot;: return new VendorA(); case &quot;B&quot;: return new VendorB(); default: throw new RuntimeException(&quot;供应商不存在&quot;); &#125; &#125;&#125; 最后，由我们客户端进行调用 1234567public class Client &#123; public static void main(String[] args) &#123; String type = &quot;A&quot;; IVender iVender = VendorFactory.createVendor(type); iVender.order(); &#125;&#125; 缺点：缺点在于不符合开闭原则，每次添加新产品就需要修改工厂类。在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展维护，并且工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。 工厂方法模式 工厂方法模式将工厂抽象化，并定义一个创建对象的接口。每增加新产品，只需增加该产品以及对应的具体实现工厂类，由具体工厂类决定要实例化的产品是哪个，将对象的创建与实例化延迟到子类，这样工厂的设计就符合“开闭原则”了，扩展时不必去修改原来的代码。 缺点：但缺点在于，每增加一个产品都需要增加一个具体产品类和实现工厂类，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。 抽象产品 1234// 工厂方法的抽象产品public interface Interviewer &#123; void askQuestion();&#125; 具体产品 1234567891011121314// 具体产品public class Developer implements Interviewer&#123; @Override public void askQuestion() &#123; System.out.println(&quot;询问设计模式相关的问题&quot;); &#125;&#125;public class CommunityExecutive implements Interviewer&#123; @Override public void askQuestion() &#123; System.out.println(&quot;询问社区建设相关的问题&quot;); &#125;&#125; 抽象工厂 123456789//抽象工厂类public abstract class HiringManager &#123; // 抽象工厂方法 protected abstract Interviewer makeInterviewer(); public void takeInterviewer() &#123; Interviewer interviewer = makeInterviewer(); //创建具体的 interviewer.askQuestion(); &#125;&#125; 具体工厂（决定要实例化的产品是哪个） 123456789101112131415// 实现工厂类public class DevelopmentManager extends HiringManager&#123; @Override protected Interviewer makeInterviewer() &#123; return new Developer(); &#125;&#125;public class MarketingManager extends HiringManager&#123; @Override protected Interviewer makeInterviewer() &#123; return new CommunityExecutive(); &#125;&#125; 策略模式 策略模式定义了一系列的算法，并将每一个算法封装起来，使每个算法可以相互替代，使算法本身和使用算法的客户端分割开来，相互独立 策略接口角色IStrategy：用来约束一系列具体的策略算法，策略上下文角色ConcreteStrategy使用此策略接口来调用具体的策略所实现的算法 12345//策略接口public interface IStrategy &#123; //定义的抽象算法方法 来约束具体的算法实现方法 public void algorithmMethod();&#125; 具体策略实现角色ConcreteStrategy：具体的策略实现，即具体的算法实现 12345678 // 具体的策略实现public class ConcreteStrategy implements IStrategy &#123; //具体的算法实现 @Override public void algorithmMethod() &#123; System.out.println(&quot;this is ConcreteStrategy method...&quot;); &#125;&#125; 策略上下文角色StrategyContext：策略上下文，负责具体的策略实现交互，通常策略上下文对象会持有一个真正的策略实现对象，策略上下文还可以让具体的策略实现从其中获取相关数据，回调策略上下文对象的方法。 12345678910111213141516/** * 策略上下文 */public class StrategyContext &#123; //持有一个策略实现的引用 private IStrategy strategy; //使用构造器注入具体的策略类 public StrategyContext(IStrategy strategy) &#123; this.strategy = strategy; &#125; public void contextMethod()&#123; //调用策略实现的方法 strategy.algorithmMethod(); &#125;&#125; 外部客户端 1234567891011//外部客户端public class Client &#123; public static void main(String[] args) &#123; //1.创建具体测策略实现 IStrategy strategy = new ConcreteStrategy(); //2.在创建策略上下文的同时，将具体的策略实现对象注入到策略上下文当中 StrategyContext ctx = new StrategyContext(strategy); //3.调用上下文对象的方法来完成对具体策略实现的回调 ctx.contextMethod(); &#125;&#125; 缺点： 客户端必须了解所有的策略，清楚它们的不同： 如果由客户端来决定使用何种算法，那客户端必须知道所有的策略，清楚各个策略的功能和不同，这样才能做出正确的选择，但是这暴露了策略的具体实现 增加了对象的数量： 由于策略模式将每个具体的算法都单独封装为一个策略类，如果可选的策略有很多的话，那对象的数量也会很多 只适合偏平的算法结构： 由于策略模式的各个策略实现是平等的关系（可相互替换），实际上就构成了一个扁平的算法结构。即一个策略接口下面有多个平等的策略实现（多个策略实现是兄弟关系），并且运行时只能有一个算法被使用。这就限制了算法的使用层级，且不能被嵌套 本质： 分离算法，选择实现。如果没有上下文，策略模式就回到了最基本的接口和实现了，只要是面向接口编程，就能够享受到面向接口编程带来的好处，通过一个统一的策略接口来封装和分离各个具体的策略实现，无需关系具体的策略实现。貌似没有上下文什么事，但是如果没有上下文的话，客户端就必须直接和具体的策略实现进行交互了，尤其是需要提供一些公共功能或者是存储一些状态的时候，会大大增加客户端使用的难度；引入上下文之后，这部分工作可以由上下文来完成，客户端只需要和上下文进行交互就可以了。这样可以让策略模式更具有整体性，客户端也更加的简单 代理模式 前言：代理(Proxy)模式是一种结构型设计模式，提供了对目标对象另外的访问方式；即通过代理对象访问目标对象。 代理模式大致有三种角色： Real Subject：真实类，也就是被代理类、委托类。用来真正完成业务服务功能； Proxy：代理类，将自身的请求用 Real Subject 对应的功能来实现，代理类对象并不真正的去实现其业务功能； Subject：定义 RealSubject 和 Proxy 角色都应该实现的接口。 静态代理 静态代理需要先定义接口，被代理对象与代理对象一起实现相同的接口，然后通过调用相同的方法来调用目标对象的方法。 优点：静态代理模式在不改变目标对象的前提下，实现了对目标对象的功能扩展。 缺点：静态代理实现了目标对象的所有方法，一旦目标接口增加方法，代理对象和目标对象都要进行相应的修改，增加维护成本。 动态代理 JDK代理 原理：JDK动态代理对象不需要实现接口，但是目标对象必须实现接口。代理对象会实现与目标类一样的方法，并将方法调用转发给目标对象 样例：有一天公司增加了业务，出售的商品越来越多，售后也需要更上。但是公司发现原来的代理商，还要再培训才能完成全部的业务，于是就找了另外的动态代理商B 。 代理商B 承诺无缝对接公司所有的业务，不管新增什么业务，均不需要额外的培训即可完成 公司增加了维修业务 12345678910111213141516//接口添加方法public interface TVCompany &#123; /** * 生产电视机 * @return 电视机 */ public TV produceTV(); /** * 维修电视机 * @param tv 电视机 * @return 电视机 */ public TV repair(TV tv);&#125; 工厂也得把维修业务搞起来 1234567891011121314//新增目标类public class TVFactory implements TVCompany &#123; @Override public TV produceTV() &#123; System.out.println(&quot;TV factory produce TV...&quot;); return new TV(&quot;小米电视机&quot;,&quot;北京&quot;); &#125; @Override public TV repair(TV tv) &#123; System.out.println(&quot;tv is repair finished...&quot;); return new TV(&quot;小米电视机&quot;,&quot;北京&quot;); &#125;&#125; B代理商 全面代理公司所有的业务。使用Proxy.newProxyInstance方法生成代理对象，实现InvocationHandler中的 invoke方法，在invoke方法中通过反射调用代理类的方法，并提供增强方法 1234567891011121314151617181920212223242526//新增代理类public class TVProxyFactory &#123; private Object target; public TVProxyFactory(Object o)&#123; this.target = o; &#125; /* ClassLoader loader：指定当前目标对象使用类加载器，获取加载器的方法是固定的。 Class&lt;?&gt;[] interfaces：目标对象实现的接口的类型，使用泛型方式确认类型。 InvocationHandler h：事件处理，执行目标对象的方法时，会触发事件处理器的方法，会把当前执行目标对象的方法作为参数传入。 */ public Object getProxy()&#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;TV proxy find factory for tv.... &quot;); Object invoke = method.invoke(target, args); return invoke; &#125; &#125;); &#125;&#125; 客户端调用 12345678public class TVConsumer &#123; public static void main(String[] args) &#123; TVCompany target = new TVFactory(); TVCompany tvCompany = (TVCompany) new TVProxyFactory(target).getProxy(); TV tv = tvCompany.produceTV(); tvCompany.repair(tv); &#125;&#125; 缺点：JDK 动态代理有一个最致命的问题是它只能代理实现了某个接口的实现类（因为java是单继承，使用Proxy类的静态方法newProxyInstance生成的新的代理类继承Proxy）。需要被代理对象的类实现了某些接口，生成的代理类也会实现相应的接口。代理类和目标类都实现了接口，是平级关系，并且代理类也只能代理接口中实现的方法，要是实现类中有自己私有的方法，而接口中没有的话，该方法不能进行代理调用 事务失效场景：内部调用，当类内部的方法调用另一个带有 @Transactional 注解的方法时，这个调用不会通过 Spring 的代理对象进行，而是直接通过 this 引用，因此 Spring 无法拦截并应用事务。Spring AOP 代理机制只能拦截通过代理对象进行的方法调用，而不能拦截类内部的直接方法调用 解决： 其中一种解决方法是在类内部通过 Spring 容器获取当前对象的代理实例，然后通过代理对象调用目标方法，从而让事务生效 12345678910111213141516171819@Servicepublic class TransactionService &#123; @Autowired private ApplicationContext context; @Transactional public void publicMethod() &#123; // 从 Spring 容器中获取代理对象 TransactionService proxy = context.getBean(TransactionService.class); proxy.internalMethod(); // 通过代理对象调用方法，事务生效 &#125; @Transactional public void internalMethod() &#123; // 事务在这里生效 &#125;&#125; Cglib代理 Cglib代理可以称为子类代理，是在内存中构建一个子类对象，从而实现对目标对象功能的扩展。它不要求目标类实现接口中的方法，而是基于字节码生成技术，生成目标类的子类作为代理类，并重写父类的方法和增强逻辑 Cglib通过Enhancer 来生成代理类，通过实现MethodInterceptor接口，并实现其中的intercept方法，在此方法中可以添加增强方法，并可以利用反射Method或者MethodProxy继承类 来调用原方法 123456789101112131415161718192021public class TVProxyCglib implements MethodInterceptor &#123; //给目标对象创建一个代理对象 public Object getProxyInstance(Class c)&#123; //1.工具类 Enhancer enhancer = new Enhancer(); //2.设置父类 enhancer.setSuperclass(c); //3.设置回调函数，调用方法的时候先调用intercept（拦截器）方法，执行我们定义的方法的增强链（也就是设置） enhancer.setCallback(this); //4.创建子类（代理对象） return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;TVProxyFactory enhancement.....&quot;); Object object = methodProxy.invokeSuper(o, objects); return object; &#125;&#125; 新代理的B工厂 1234567891011public class TVFactoryB &#123; public TV produceTVB() &#123; System.out.println(&quot;tv factory B producing tv.... &quot;); return new TV(&quot;华为电视机&quot;, &quot;南京&quot;); &#125; public TV repairB(TV tv) &#123; System.out.println(&quot;tv B is repair finished.... &quot;); return tv; &#125;&#125; C代理可以直接和公司合作，也可以和工厂打交道。并且可以代理任何工厂的产品。 123456789101112public class TVConsumer &#123; public static void main(String[] args) &#123; TVCompany tvCompany = (TVCompany) new TVProxyCglib().getProxyInstance(TVFactory.class); TV tv = tvCompany.produceTV(); tvCompany.repair(tv); System.out.println(&quot;==============================&quot;); TVFactoryB tvFactoryB = (TVFactoryB) new TVProxyCglib().getProxyInstance(TVFactoryB.class); TV tv = tvFactoryB.produceTVB(); tvFactoryB.repairB(tv); &#125;&#125; 打印结果 1234567891011TVProxyFactory enhancement.....TV factory produce TV...TVProxyFactory enhancement.....tv is repair finished...==============================TVProxyFactory enhancement.....tv factory B producing tv.... TVProxyFactory enhancement.....tv B is repair finished.... Process finished with exit code 0 Spring AOP使用代理 Spring中AOP的实现有JDK和Cglib两种，如下图： 如果目标对象需要实现接口，则使用JDK代理 如果目标对象不需要实现接口，则使用Cglib代理 总结 静态代理：需要代理类和目标类都实现接口的方法，从而达到代理增强其功能 JDK动态代理：需要代理类实现某个接口，使用Proxy.newProxyInstance方法生成代理类，并实现InvocationHandler中的invoke方法，实现增强功能 Cglib动态代理：无需代理类实现接口，使用Cblib中的Enhancer来生成代理对象子类，并实现MethodInterceptor中的intercept方法，在此方法中可以实现增强功能 模板方法模式 核心思想是：父类定义骨架，子类实现某些细节 为了防止子类重写父类的骨架方法，可以在父类中对骨架方法使用final。对于需要子类实现的抽象方法，一般声明为protected，使得这些方法对外部客户端不可见 父类定义骨架 1234567891011121314151617public abstract class AbstractSetting &#123; public final String getSetting(String key) &#123; //从缓存读取 String value = lookupCache(key); if (value == null) &#123; // 在缓存中未找到,从数据库读取 value = readFromDatabase(key); // 放入缓存 putIntoCache(key, value); &#125; return value; &#125; protected abstract String lookupCache(String key); protected abstract void putIntoCache(String key, String value);&#125; 子类实现某些细节 1234567891011121314151617public class RedisSetting extends AbstractSetting &#123; private RedisClient client = RedisClient.create(&quot;redis://localhost:6379&quot;); protected String lookupCache(String key) &#123; try (StatefulRedisConnection&lt;String, String&gt; connection = client.connect()) &#123; RedisCommands&lt;String, String&gt; commands = connection.sync(); return commands.get(key); &#125; &#125; protected void putIntoCache(String key, String value) &#123; try (StatefulRedisConnection&lt;String, String&gt; connection = client.connect()) &#123; RedisCommands&lt;String, String&gt; commands = connection.sync(); commands.set(key, value); &#125; &#125;&#125; 客户端调用 123AbstractSetting setting = new RedisSetting();System.out.println(&quot;autosave = &quot; + setting.getSetting(&quot;autosave&quot;));System.out.println(&quot;autosave = &quot; + setting.getSetting(&quot;autosave&quot;)); 观察者模式 基本理解 观察者（Observer）模式的定义：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式 优点： 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则 目标与观察者之间建立了一套触发机制 缺点： 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率 观察者模式的结构： 抽象主题（subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的方法 具体主题（Concrete subject）角色：也叫具体目标类，实现了抽象目标类的方法，当具体主题的内部状态发生变化的时候，通知所有注册过的观察者对象 抽象观察者（Observer）角色：它是一个抽象类或者接口，它包含了一个更新自己的抽象方法，当接受到具体主题的更改通知时被调用 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态 示例： Observer 12345// 抽象观察者public interface Observer &#123; //更新的方法 void update(String messages);&#125; WexinUser 123456789101112131415161718//具体观察者类 实现更新的方法public class WexinUser implements Observer &#123; //用户名 private String name; public WexinUser(String name) &#123; this.name = name; &#125; public WexinUser() &#123; &#125; @Override public void update(String messages) &#123; System.out.println(name + &quot;--&gt;&quot; + messages); &#125;&#125; Subject 1234567891011//抽象主题类public interface Subject &#123; //增加订阅者 public void attach(Observer observer); //删除订阅者 public void remove(Observer observer); //通知订阅者更新消息 public void notify(String messages);&#125; SubscriptionSubject 123456789101112131415//具体主题(具体被观察者)public class SubscriptionSubject implements Subject &#123; //存储订阅公众号的微信用户 private List&lt;Observer&gt; weixinUserList = new ArrayList&lt;Observer&gt;(); @Override public void attach(Observer observer) &#123; weixinUserList.add(observer); &#125; @Override public void remove(Observer observer) &#123; weixinUserList.remove(observer); &#125;&#125; Client 123456789101112131415161718public class Client &#123; public static void main(String[] args) &#123; SubscriptionSubject subject = new SubscriptionSubject(); //创建微信用户 WexinUser user1 = new WexinUser(&quot;张三&quot;); WexinUser user2 = new WexinUser(&quot;李四&quot;); WexinUser user3 = new WexinUser(&quot;王五&quot;); //订阅公众号 subject.attach(user1); subject.attach(user2); subject.attach(user3); //通过订阅用户 subject.notify(&quot;您关注的公众号更新啦~~~&quot;); &#125;&#125; JDK源码解析 在 Java 中，通过 java.util.Observable 类和 java.util.Observer 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例 Observable类（抽象被观察者） Observable 类是抽象目标类（被观察者），它有一个 Vector 集合成员变量，用于保存所有要通知的观察者对象，下面来介绍它最重要的3个方法 void addObserver(Observer o) 方法：用于将新的观察者对象添加到集合中 void notifyObservers(Object arg) 方法：调用集合中的所有观察者对象的 update方法，通知它们数据发生改变。通常越晚加入集合的观察者越先得到通知 void setChange() 方法：用来设置一个 boolean 类型的内部标志，注明目标对象发生了变化。当它为true时，notifyObservers() 才会通知观察者 Observer 接口（抽象观察者） Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 update 方法，进行相应的工作 示例： 警擦（观察者）抓小偷（被观察者），当小偷偷东西的时警擦会被通知 Thief(被观察者) 123456789101112131415161718192021222324252627//小偷类 继承Observable接口import java.util.Observable;public class Thief extends Observable &#123; private String name; public Thief(String name) &#123; this.name = name; &#125; public Thief() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void steal() &#123; System.out.println(&quot;emmm我正在悄悄偷东西&quot;); super.setChanged();//默认为true super.notifyObservers(); &#125;&#125; Policemen(观察者) 1234567891011121314151617181920212223242526import java.util.Observable;import java.util.Observer;public class Policeman implements Observer &#123; private String name; public Policeman(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Policeman() &#123; &#125; @Override public void update(Observable o, Object arg) &#123; System.out.println(&quot;警察：&quot; + ((Thief) o).getName() + &quot;我抓住你了！！！&quot;); &#125;&#125; Client 1234567891011121314151617public class Client &#123; public static void main(String[] args) &#123; //小偷（被观察者） Thief thief = new Thief(&quot;法外狂徒格雷福斯&quot;); //警察（观察者） Policeman policeman = new Policeman(&quot;凯瑟琳女警&quot;); //警察观察小偷 thief.addObserver(policeman); //小偷行窃 thief.steal(); &#125;&#125;/* 打印结果： emmm我正在悄悄偷东西 警察：法外狂徒格雷福斯我抓住你了！！！*/","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cdfy.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"HashTable和HashMap的区别","slug":"HashTable和HashMap的区别","date":"2025-01-11T07:00:25.000Z","updated":"2025-01-24T10:22:33.589Z","comments":true,"path":"posts/HashTable和HashMap的区别.html","permalink":"https://www.cdfy.top/posts/HashTable%E5%92%8CHashMap%E7%9A%84%E5%8C%BA%E5%88%AB.html","excerpt":"","text":"区别 1、HashMap是线程不安全的，HashTable是线程安全的 HashMap：Fail-fast 机制。表示快速失败，在集合遍历过程中，一旦发现容器中的数据被修改了，会立刻抛出ConcurrentModificationException异常，从而导致遍历失败，像这种情况：定义一个Map集合，使用Iterator迭代器进行数据遍历，在遍历过程中，对集合数据做变更时，就会发生Fail-fast。java.util包下的集合类都是快速失败机制的, 常见的的使用Fail-fast方式遍历的容器有HashMap和ArrayList等。 HashTable：公开的方法比如get都使用了synchronized描述符。而遍历视图比如keySet都使用了Collections.synchronizedXXX进行了同步包装。并且是锁住全局的 Fail-fast底层实现：迭代器在遍历集合的过程，会维护一个modCount变量。如果在遍历过程modCount发生变化，在迭代器使用hasNext/next遍历下一个元素的时候，都会检测modCount是否为expectedModCount的值，如果不是抛出异常。 2、 由于线程安全，HashTable效率比不上HashMap 3、HashMap允许键为NULL，值为NULL。HashTable都不允许 HashMap是支持null键和null值的，而HashTable在遇到null时，会抛出NullPointerException异常。这并不是因为HashTable有什么特殊的实现层面的原因导致不能支持null键和null值，这仅仅是因为HashMap在实现时对null做了特殊处理，将null的hashCode值定为了0，从而将其存放在哈希表的第0个bucket中。 4、HashMap默认初始化数组大小是16，HashTable是11。HashMap扩容是扩大两倍，HashTable是两倍+1 5、HashMap不能直接使用hashCode计算下标，而是使用hashCode重新计算Hash值，再计算下标。HashTable使用的是hashCode计算下标（取mod）","categories":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]}],"categories":[{"name":"Kafka","slug":"Kafka","permalink":"https://www.cdfy.top/categories/Kafka/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/categories/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/categories/Redis/"},{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/categories/Java/"},{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/categories/%E7%AE%97%E6%B3%95/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/categories/MySQL/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/categories/SpringBoot/"},{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://www.cdfy.top/tags/Kafka/"},{"name":"Java","slug":"Java","permalink":"https://www.cdfy.top/tags/Java/"},{"name":"工程应用","slug":"工程应用","permalink":"https://www.cdfy.top/tags/%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8/"},{"name":"数据库","slug":"数据库","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","permalink":"https://www.cdfy.top/tags/Redis/"},{"name":"多线程","slug":"多线程","permalink":"https://www.cdfy.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"数据结构","slug":"数据结构","permalink":"https://www.cdfy.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"https://www.cdfy.top/tags/%E7%AE%97%E6%B3%95/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.cdfy.top/tags/MySQL/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.cdfy.top/tags/SpringBoot/"},{"name":"SSM","slug":"SSM","permalink":"https://www.cdfy.top/tags/SSM/"},{"name":"JVM","slug":"JVM","permalink":"https://www.cdfy.top/tags/JVM/"},{"name":"操作系统","slug":"操作系统","permalink":"https://www.cdfy.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"锁","slug":"锁","permalink":"https://www.cdfy.top/tags/%E9%94%81/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://www.cdfy.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Redis - 数据库","slug":"Redis-数据库","permalink":"https://www.cdfy.top/tags/Redis-%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"设计模式","slug":"设计模式","permalink":"https://www.cdfy.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}